// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`Global Roles Stack 1`] = `
Object {
  "Description": "test;",
  "Mappings": Object {
    "ServiceprincipalMap": Object {
      "af-south-1": Object {
        "ssm": "ssm.af-south-1.amazonaws.com",
      },
      "ap-east-1": Object {
        "ssm": "ssm.ap-east-1.amazonaws.com",
      },
      "ap-northeast-1": Object {
        "ssm": "ssm.amazonaws.com",
      },
      "ap-northeast-2": Object {
        "ssm": "ssm.amazonaws.com",
      },
      "ap-northeast-3": Object {
        "ssm": "ssm.amazonaws.com",
      },
      "ap-south-1": Object {
        "ssm": "ssm.amazonaws.com",
      },
      "ap-southeast-1": Object {
        "ssm": "ssm.amazonaws.com",
      },
      "ap-southeast-2": Object {
        "ssm": "ssm.amazonaws.com",
      },
      "ap-southeast-3": Object {
        "ssm": "ssm.ap-southeast-3.amazonaws.com",
      },
      "ca-central-1": Object {
        "ssm": "ssm.amazonaws.com",
      },
      "cn-north-1": Object {
        "ssm": "ssm.amazonaws.com",
      },
      "cn-northwest-1": Object {
        "ssm": "ssm.amazonaws.com",
      },
      "eu-central-1": Object {
        "ssm": "ssm.amazonaws.com",
      },
      "eu-north-1": Object {
        "ssm": "ssm.amazonaws.com",
      },
      "eu-south-1": Object {
        "ssm": "ssm.eu-south-1.amazonaws.com",
      },
      "eu-south-2": Object {
        "ssm": "ssm.eu-south-2.amazonaws.com",
      },
      "eu-west-1": Object {
        "ssm": "ssm.amazonaws.com",
      },
      "eu-west-2": Object {
        "ssm": "ssm.amazonaws.com",
      },
      "eu-west-3": Object {
        "ssm": "ssm.amazonaws.com",
      },
      "me-south-1": Object {
        "ssm": "ssm.me-south-1.amazonaws.com",
      },
      "sa-east-1": Object {
        "ssm": "ssm.amazonaws.com",
      },
      "us-east-1": Object {
        "ssm": "ssm.amazonaws.com",
      },
      "us-east-2": Object {
        "ssm": "ssm.amazonaws.com",
      },
      "us-gov-east-1": Object {
        "ssm": "ssm.amazonaws.com",
      },
      "us-gov-west-1": Object {
        "ssm": "ssm.amazonaws.com",
      },
      "us-iso-east-1": Object {
        "ssm": "ssm.amazonaws.com",
      },
      "us-iso-west-1": Object {
        "ssm": "ssm.us-iso-west-1.amazonaws.com",
      },
      "us-isob-east-1": Object {
        "ssm": "ssm.amazonaws.com",
      },
      "us-west-1": Object {
        "ssm": "ssm.amazonaws.com",
      },
      "us-west-2": Object {
        "ssm": "ssm.amazonaws.com",
      },
    },
  },
  "Parameters": Object {
    "SecHubAdminAccount": Object {
      "AllowedPattern": "\\\\d{12}",
      "Description": "Admin account number",
      "Type": "String",
    },
  },
  "Resources": Object {
    "OrchestratorMemberRoleMemberAccountRoleBE9AD9D5": Object {
      "Metadata": Object {
        "cfn_nag": Object {
          "rules_to_suppress": Array [
            Object {
              "id": "W11",
              "reason": "Resource * is required due to the administrative nature of the solution.",
            },
            Object {
              "id": "W28",
              "reason": "Static names chosen intentionally to provide integration in cross-account permissions",
            },
          ],
        },
      },
      "Properties": Object {
        "AssumeRolePolicyDocument": Object {
          "Statement": Array [
            Object {
              "Action": "sts:AssumeRole",
              "Effect": "Allow",
              "Principal": Object {
                "AWS": Object {
                  "Fn::Join": Array [
                    "",
                    Array [
                      "arn:",
                      Object {
                        "Ref": "AWS::Partition",
                      },
                      ":iam::",
                      Object {
                        "Ref": "SecHubAdminAccount",
                      },
                      ":role/SO0111-SHARR-Orchestrator-Admin",
                    ],
                  ],
                },
              },
            },
            Object {
              "Action": "sts:AssumeRole",
              "Effect": "Allow",
              "Principal": Object {
                "Service": Object {
                  "Fn::FindInMap": Array [
                    "ServiceprincipalMap",
                    Object {
                      "Ref": "AWS::Region",
                    },
                    "ssm",
                  ],
                },
              },
            },
          ],
          "Version": "2012-10-17",
        },
        "Policies": Array [
          Object {
            "PolicyDocument": Object {
              "Statement": Array [
                Object {
                  "Action": Array [
                    "iam:PassRole",
                    "iam:GetRole",
                  ],
                  "Effect": "Allow",
                  "Resource": Object {
                    "Fn::Join": Array [
                      "",
                      Array [
                        "arn:",
                        Object {
                          "Ref": "AWS::Partition",
                        },
                        ":iam::",
                        Object {
                          "Ref": "AWS::AccountId",
                        },
                        ":role/SO0111-*",
                      ],
                    ],
                  },
                },
                Object {
                  "Action": "ssm:StartAutomationExecution",
                  "Effect": "Allow",
                  "Resource": Array [
                    Object {
                      "Fn::Join": Array [
                        "",
                        Array [
                          "arn:",
                          Object {
                            "Ref": "AWS::Partition",
                          },
                          ":ssm:*:",
                          Object {
                            "Ref": "AWS::AccountId",
                          },
                          ":document/SHARR-*",
                        ],
                      ],
                    },
                    Object {
                      "Fn::Join": Array [
                        "",
                        Array [
                          "arn:",
                          Object {
                            "Ref": "AWS::Partition",
                          },
                          ":ssm:*:",
                          Object {
                            "Ref": "AWS::AccountId",
                          },
                          ":automation-definition/*",
                        ],
                      ],
                    },
                    Object {
                      "Fn::Join": Array [
                        "",
                        Array [
                          "arn:",
                          Object {
                            "Ref": "AWS::Partition",
                          },
                          ":ssm:*::automation-definition/*",
                        ],
                      ],
                    },
                    Object {
                      "Fn::Join": Array [
                        "",
                        Array [
                          "arn:",
                          Object {
                            "Ref": "AWS::Partition",
                          },
                          ":ssm:*:",
                          Object {
                            "Ref": "AWS::AccountId",
                          },
                          ":automation-execution/*",
                        ],
                      ],
                    },
                  ],
                },
                Object {
                  "Action": Array [
                    "ssm:DescribeAutomationExecutions",
                    "ssm:GetAutomationExecution",
                  ],
                  "Effect": "Allow",
                  "Resource": "*",
                },
                Object {
                  "Action": "ssm:DescribeDocument",
                  "Effect": "Allow",
                  "Resource": Object {
                    "Fn::Join": Array [
                      "",
                      Array [
                        "arn:",
                        Object {
                          "Ref": "AWS::Partition",
                        },
                        ":ssm:*:*:document/*",
                      ],
                    ],
                  },
                },
                Object {
                  "Action": Array [
                    "ssm:GetParameters",
                    "ssm:GetParameter",
                  ],
                  "Effect": "Allow",
                  "Resource": Object {
                    "Fn::Join": Array [
                      "",
                      Array [
                        "arn:",
                        Object {
                          "Ref": "AWS::Partition",
                        },
                        ":ssm:*:*:parameter/Solutions/SO0111/*",
                      ],
                    ],
                  },
                },
                Object {
                  "Action": "config:DescribeConfigRules",
                  "Effect": "Allow",
                  "Resource": "*",
                },
                Object {
                  "Action": Array [
                    "cloudwatch:PutMetricData",
                    "securityhub:BatchUpdateFindings",
                  ],
                  "Effect": "Allow",
                  "Resource": "*",
                },
              ],
              "Version": "2012-10-17",
            },
            "PolicyName": "member_orchestrator",
          },
        ],
        "RoleName": "SO0111-SHARR-Orchestrator-Member",
      },
      "Type": "AWS::IAM::Role",
    },
  },
}
`;

exports[`Regional Documents 1`] = `
Object {
  "Description": "test;",
  "Resources": Object {
    "SHARRConfigureS3BucketPublicAccessBlock": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "description:  |
  ### Document Name - AWSConfigRemediation-ConfigureS3BucketPublicAccessBlock

  ## What does this document do?
  This document is used to create or modify the PublicAccessBlock configuration for an Amazon S3 bucket.

  ## Input Parameters
  * BucketName: (Required) Name of the S3 bucket (not the ARN).
  * RestrictPublicBuckets: (Optional) Specifies whether Amazon S3 should restrict public bucket policies for this bucket. Setting this element to TRUE restricts access to this bucket to only AWS services and authorized users within this account if the bucket has a public policy.
    * Default: \\"true\\"
  * BlockPublicAcls: (Optional) Specifies whether Amazon S3 should block public access control lists (ACLs) for this bucket and objects in this bucket.
    * Default: \\"true\\"
  * IgnorePublicAcls: (Optional) Specifies whether Amazon S3 should ignore public ACLs for this bucket and objects in this bucket. Setting this element to TRUE causes Amazon S3 to ignore all public ACLs on this bucket and objects in this bucket.
    * Default: \\"true\\"
  * BlockPublicPolicy: (Optional) Specifies whether Amazon S3 should block public bucket policies for this bucket. Setting this element to TRUE causes Amazon S3 to reject calls to PUT Bucket policy if the specified bucket policy allows public access.
    * Default: \\"true\\"
  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.

  ## Output Parameters
  * GetBucketPublicAccessBlock.Output - JSON formatted response from the GetPublicAccessBlock API call

  ## Note: this is a local copy of the AWS-owned document to enable support in aws-cn and aws-us-gov partitions.
schemaVersion: \\"0.3\\"
assumeRole: \\"{{ AutomationAssumeRole }}\\"
outputs:
  - GetBucketPublicAccessBlock.Output
parameters:
  BucketName:
    type: String
    description: (Required) The bucket name (not the ARN).
    allowedPattern: (?=^.{3,63}$)(?!^(\\\\d+\\\\.)+\\\\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\\\\-]*[a-z0-9])\\\\.)*([a-z0-9]|[a-z0-9][a-z0-9\\\\-]*[a-z0-9])$)
  RestrictPublicBuckets:
    type: Boolean
    description: (Optional) Specifies whether Amazon S3 should restrict public bucket policies for this bucket. Setting this element to TRUE restricts access to this bucket to only AWS services and authorized users within this account if the bucket has a public policy.
    default: true
    allowedValues:
      - true
      - false
  BlockPublicAcls:
    type: Boolean
    description: (Optional) Specifies whether Amazon S3 should block public access control lists (ACLs) for this bucket and objects in this bucket.
    default: true
    allowedValues:
      - true
      - false
  IgnorePublicAcls:
    type: Boolean
    description: (Optional) Specifies whether Amazon S3 should ignore public ACLs for this bucket and objects in this bucket. Setting this element to TRUE causes Amazon S3 to ignore all public ACLs on this bucket and objects in this bucket.
    default: true
    allowedValues:
      - true
      - false
  BlockPublicPolicy:
    type: Boolean
    description: (Optional) Specifies whether Amazon S3 should block public bucket policies for this bucket. Setting this element to TRUE causes Amazon S3 to reject calls to PUT Bucket policy if the specified bucket policy allows public access.
    default: true
    allowedValues:
      - true
      - false
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
mainSteps:
  - name: PutBucketPublicAccessBlock
    action: \\"aws:executeAwsApi\\"
    description: |
      ## PutBucketPublicAccessBlock
      Creates or modifies the PublicAccessBlock configuration for a S3 Bucket.
    isEnd: false
    inputs:
      Service: s3
      Api: PutPublicAccessBlock
      Bucket: \\"{{BucketName}}\\"
      PublicAccessBlockConfiguration:
        RestrictPublicBuckets: \\"{{ RestrictPublicBuckets }}\\"
        BlockPublicAcls: \\"{{ BlockPublicAcls }}\\"
        IgnorePublicAcls: \\"{{ IgnorePublicAcls }}\\"
        BlockPublicPolicy: \\"{{ BlockPublicPolicy }}\\"
    isCritical: true
    maxAttempts: 2
    timeoutSeconds: 600
  - name: GetBucketPublicAccessBlock
    action: \\"aws:executeScript\\"
    description: |
      ## GetBucketPublicAccessBlock
      Retrieves the S3 PublicAccessBlock configuration for a S3 Bucket.
      ## Outputs
      * Output: JSON formatted response from the GetPublicAccessBlock API call.
    timeoutSeconds: 600
    isCritical: true
    isEnd: true
    inputs:
      Runtime: python3.8
      Handler: validate_s3_bucket_publicaccessblock
      InputPayload:
        Bucket: \\"{{BucketName}}\\"
        RestrictPublicBuckets: \\"{{ RestrictPublicBuckets }}\\"
        BlockPublicAcls: \\"{{ BlockPublicAcls }}\\"
        IgnorePublicAcls: \\"{{ IgnorePublicAcls }}\\"
        BlockPublicPolicy: \\"{{ BlockPublicPolicy }}\\"
      Script: |-
        import boto3

        def validate_s3_bucket_publicaccessblock(event, context):
          s3_client = boto3.client(\\"s3\\")
          bucket = event[\\"Bucket\\"]
          restrict_public_buckets = event[\\"RestrictPublicBuckets\\"]
          block_public_acls = event[\\"BlockPublicAcls\\"]
          ignore_public_acls = event[\\"IgnorePublicAcls\\"]
          block_public_policy = event[\\"BlockPublicPolicy\\"]

          output = s3_client.get_public_access_block(Bucket=bucket)
          updated_block_acl = output[\\"PublicAccessBlockConfiguration\\"][\\"BlockPublicAcls\\"]
          updated_ignore_acl = output[\\"PublicAccessBlockConfiguration\\"][\\"IgnorePublicAcls\\"]
          updated_block_policy = output[\\"PublicAccessBlockConfiguration\\"][\\"BlockPublicPolicy\\"]
          updated_restrict_buckets = output[\\"PublicAccessBlockConfiguration\\"][\\"RestrictPublicBuckets\\"]

          if updated_block_acl == block_public_acls and updated_ignore_acl == ignore_public_acls \\\\
          and updated_block_policy == block_public_policy and updated_restrict_buckets == restrict_public_buckets:
            return {
              \\"output\\":
                {
                  \\"message\\": \\"Bucket public access block configuration successfully set.\\",
                  \\"configuration\\": output[\\"PublicAccessBlockConfiguration\\"]
                }
            }
          else:
              info = \\"CONFIGURATION VALUES DO NOT MATCH WITH PARAMETERS PROVIDED VALUES RestrictPublicBuckets: {}, BlockPublicAcls: {}, IgnorePublicAcls: {}, BlockPublicPolicy: {}\\".format(
                        restrict_public_buckets,
                        block_public_acls,
                        ignore_public_acls,
                        block_public_policy
                      )
              raise Exception(info)
    outputs:
      - Name: Output
        Selector: $.Payload.output
        Type: StringMap

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-ConfigureS3BucketPublicAccessBlock",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARRConfigureS3PublicAccessBlock": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "description: |
  ### Document Name - AWSConfigRemediation-ConfigureS3PublicAccessBlock

  ## What does this document do?
  This document is used to create or modify the S3 [PublicAccessBlock](https://docs.aws.amazon.com/AmazonS3/latest/dev/access-control-block-public-access.html#access-control-block-public-access-options) configuration for an AWS account.

  ## Input Parameters
  * AccountId: (Required) Account ID of the account for which the S3 Account Public Access Block is to be configured.
  * RestrictPublicBuckets: (Optional) Specifies whether Amazon S3 should restrict public bucket policies for buckets in this account. Setting this element to TRUE restricts access to buckets with public policies to only AWS services and authorized users within this account.
    * Default: \\"true\\"
  * BlockPublicAcls: (Optional) Specifies whether Amazon S3 should block public access control lists (ACLs) for buckets in this account.
    * Default: \\"true\\"
  * IgnorePublicAcls: (Optional) Specifies whether Amazon S3 should ignore public ACLs for buckets in this account. Setting this element to TRUE causes Amazon S3 to ignore all public ACLs on buckets in this account and any objects that they contain.
    * Default: \\"true\\"
  * BlockPublicPolicy: (Optional) Specifies whether Amazon S3 should block public bucket policies for buckets in this account. Setting this element to TRUE causes Amazon S3 to reject calls to PUT Bucket policy if the specified bucket policy allows public access.
    * Default: \\"true\\"
  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.

  ## Output Parameters
  * GetPublicAccessBlock.Output - JSON formatted response from the GetPublicAccessBlock API call.

schemaVersion: \\"0.3\\"
assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AccountId:
    type: String
    description: (Required) The account ID for the AWS account whose PublicAccessBlock configuration you want to set.
    allowedPattern: ^\\\\d{12}$
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  RestrictPublicBuckets:
    type: Boolean
    description: (Optional) Specifies whether Amazon S3 should restrict public bucket policies for buckets in this account. Setting this element to TRUE restricts access to buckets with public policies to only AWS services and authorized users within this account.
    default: true
  BlockPublicAcls:
    type: Boolean
    description: (Optional) Specifies whether Amazon S3 should block public access control lists (ACLs) for buckets in this account.
    default: true
  IgnorePublicAcls:
    type: Boolean
    description: (Optional) Specifies whether Amazon S3 should ignore public ACLs for buckets in this account. Setting this element to TRUE causes Amazon S3 to ignore all public ACLs on buckets in this account and any objects that they contain.
    default: true
  BlockPublicPolicy:
    type: Boolean
    description: (Optional) Specifies whether Amazon S3 should block public bucket policies for buckets in this account. Setting this element to TRUE causes Amazon S3 to reject calls to PUT Bucket policy if the specified bucket policy allows public access.
    default: true
outputs:
  - GetPublicAccessBlock.Output
mainSteps:
  -
    name: PutAccountPublicAccessBlock
    action: \\"aws:executeAwsApi\\"
    description: |
      ## PutAccountPublicAccessBlock
      Creates or modifies the S3 PublicAccessBlock configuration for an AWS account.
    timeoutSeconds: 600
    isEnd: false
    inputs:
      Service: s3control
      Api: PutPublicAccessBlock
      AccountId: \\"{{ AccountId }}\\"
      PublicAccessBlockConfiguration:
        RestrictPublicBuckets: \\"{{ RestrictPublicBuckets }}\\"
        BlockPublicAcls: \\"{{ BlockPublicAcls }}\\"
        IgnorePublicAcls: \\"{{ IgnorePublicAcls }}\\"
        BlockPublicPolicy: \\"{{ BlockPublicPolicy }}\\"
    outputs:
      - Name: PutAccountPublicAccessBlockResponse
        Selector: $
        Type: StringMap
  -
    name: GetPublicAccessBlock
    action: \\"aws:executeScript\\"
    description: |
      ## GetPublicAccessBlock
      Retrieves the S3 PublicAccessBlock configuration for an AWS account.
      ## Outputs
      * Output: JSON formatted response from the GetPublicAccessBlock API call.
    timeoutSeconds: 600
    isEnd: true
    inputs:
      Runtime: python3.8
      Handler: handler
      InputPayload:
        AccountId: \\"{{ AccountId }}\\"
        RestrictPublicBuckets: \\"{{ RestrictPublicBuckets }}\\"
        BlockPublicAcls: \\"{{ BlockPublicAcls }}\\"
        IgnorePublicAcls: \\"{{ IgnorePublicAcls }}\\"
        BlockPublicPolicy: \\"{{ BlockPublicPolicy }}\\"
      Script: |-
        import boto3
        from time import sleep

        def verify_s3_public_access_block(account_id, restrict_public_buckets, block_public_acls, ignore_public_acls, block_public_policy):
           s3control_client = boto3.client('s3control')
           wait_time = 30
           max_time = 480
           retry_count = 1
           max_retries = max_time/wait_time
           while retry_count <= max_retries:
               sleep(wait_time)
               retry_count = retry_count + 1
               get_public_access_response = s3control_client.get_public_access_block(AccountId=account_id)
               updated_block_acl = get_public_access_response['PublicAccessBlockConfiguration']['BlockPublicAcls']
               updated_ignore_acl = get_public_access_response['PublicAccessBlockConfiguration']['IgnorePublicAcls']
               updated_block_policy = get_public_access_response['PublicAccessBlockConfiguration']['BlockPublicPolicy']
               updated_restrict_buckets = get_public_access_response['PublicAccessBlockConfiguration']['RestrictPublicBuckets']
               if updated_block_acl == block_public_acls and updated_ignore_acl == ignore_public_acls \\\\
                         and updated_block_policy == block_public_policy and updated_restrict_buckets == restrict_public_buckets:
                           return {
                               \\"output\\": {
                                   \\"message\\": \\"Verification successful. S3 Public Access Block Updated.\\",
                                   \\"HTTPResponse\\": get_public_access_response[\\"PublicAccessBlockConfiguration\\"]
                               },
                           }
           raise Exception(
                 \\"VERFICATION FAILED. S3 GetPublicAccessBlock CONFIGURATION VALUES \\"
                 \\"DO NOT MATCH WITH PARAMETERS PROVIDED VALUES \\"
                 \\"RestrictPublicBuckets: {}, BlockPublicAcls: {}, IgnorePublicAcls: {}, BlockPublicPolicy: {}\\"
                 .format(updated_restrict_buckets, updated_block_acl, updated_ignore_acl, updated_block_policy)
           )

        def handler(event, context):
          account_id = event[\\"AccountId\\"]
          restrict_public_buckets = event[\\"RestrictPublicBuckets\\"]
          block_public_acls = event[\\"BlockPublicAcls\\"]
          ignore_public_acls = event[\\"IgnorePublicAcls\\"]
          block_public_policy = event[\\"BlockPublicPolicy\\"]
          return verify_s3_public_access_block(account_id, restrict_public_buckets, block_public_acls, ignore_public_acls, block_public_policy)

    outputs:
      - Name: Output
        Selector: $.Payload.output
        Type: StringMap
",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-ConfigureS3PublicAccessBlock",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARRCreateAccessLoggingBucket": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "description: |
  ### Document Name - SHARR-CreateAccessLoggingBucket
  
  ## What does this document do?
  Creates an S3 bucket for access logging.
  
  ## Input Parameters
  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  * BucketName: (Required) Name of the bucket to create

schemaVersion: \\"0.3\\"
assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  BucketName:
    type: String
    description: (Required) The bucket name (not the ARN).
    allowedPattern: (?=^.{3,63}$)(?!^(\\\\d+\\\\.)+\\\\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\\\\-]*[a-z0-9])\\\\.)*([a-z0-9]|[a-z0-9][a-z0-9\\\\-]*[a-z0-9])$)
outputs:
  - CreateAccessLoggingBucket.Output

mainSteps:
  - 
    name: CreateAccessLoggingBucket
    action: 'aws:executeScript'
    inputs:
      InputPayload:       
        BucketName: '{{BucketName}}'
        AWS_REGION: '{{global:REGION}}'
      Runtime: python3.8
      Handler: create_logging_bucket
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.    #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0/                                        #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    #
        #  sions and limitations under the License.                                   #
        ###############################################################################
        
        import boto3
        from botocore.exceptions import ClientError
        from botocore.config import Config
        
        def connect_to_s3(boto_config):
            return boto3.client('s3', config=boto_config)
        
        def create_logging_bucket(event, context):
            boto_config = Config(
                retries ={
                  'mode': 'standard'
                }
            )
            s3 = connect_to_s3(boto_config)
        
            try:
                kwargs = {
                    'Bucket': event['BucketName'],
                    'GrantWrite': 'uri=http://acs.amazonaws.com/groups/s3/LogDelivery',
                    'GrantReadACP': 'uri=http://acs.amazonaws.com/groups/s3/LogDelivery'
                }
                if event['AWS_REGION'] != 'us-east-1':
                    kwargs['CreateBucketConfiguration'] = {
                        'LocationConstraint': event['AWS_REGION']
                    }
        
                s3.create_bucket(**kwargs)
        
                s3.put_bucket_encryption(
                    Bucket=event['BucketName'],
                    ServerSideEncryptionConfiguration={
                        'Rules': [
                            {
                                'ApplyServerSideEncryptionByDefault': {
                                    'SSEAlgorithm': 'AES256'
                                }
                            }
                        ]
                    }
                )
                return {
                    \\"output\\": {
                        \\"Message\\": f'Bucket {event[\\"BucketName\\"]} created'
                    }
                }
            except ClientError as error:
                if error.response['Error']['Code'] != 'BucketAlreadyExists' and \\\\
                    error.response['Error']['Code'] != 'BucketAlreadyOwnedByYou':
                    exit(str(error))
                else:
                    return {
                        \\"output\\": {
                            \\"Message\\": f'Bucket {event[\\"BucketName\\"]} already exists'
                        }
                    }
            except Exception as e:
                print(e)
                exit(str(e))
        
    outputs:
      - Name: Output
        Selector: $.Payload.output
        Type: StringMap

    isEnd: true

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-CreateAccessLoggingBucket",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARRCreateCloudTrailMultiRegionTrail": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "description: |
  ### Document Name - SHARR-CreateCloudTrailMultiRegionTrail
  ## What does this document do?
  Creates a multi-region trail with KMS encryption and enables CloudTrail
  Note: this remediation will create a NEW trail.
  
  ## Input Parameters
  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  * KMSKeyArn (from SSM): Arn of the KMS key to be used to encrypt data

  ## Security Standards / Controls
  * AFSBP v1.0.0:   CloudTrail.1
  * CIS v1.2.0:     2.1
  * PCI:            CloudTrail.2

schemaVersion: \\"0.3\\"
assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  KMSKeyArn:
    type: String
    default: >-
      {{ssm:/Solutions/SO0111/CMK_REMEDIATION_ARN}}
    description: The ARN of the KMS key created by SHARR for this remediation
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):kms:(?:[a-z]{2}(?:-gov)?-[a-z]+-\\\\d):\\\\d{12}:(?:(?:alias/[A-Za-z0-9/-_])|(?:key/(?i:[0-9a-f]{8}-(?:[0-9a-f]{4}-){3}[0-9a-f]{12})))$'
  AWSPartition:
    type: String
    default: 'aws'
    description: 'Partition for creation of ARNs.'
    allowedValues:
      - aws
      - aws-cn
      - aws-us-gov

outputs:
  - Remediation.Output

mainSteps:
  - 
    name: CreateLoggingBucket
    action: 'aws:executeScript'
    outputs:
      - Name: LoggingBucketName
        Selector: $.Payload.logging_bucket
        Type: String
    inputs:
      InputPayload: 
        account: '{{global:ACCOUNT_ID}}'
        region: '{{global:REGION}}'
        kms_key_arn: '{{KMSKeyArn}}'        
      Runtime: python3.8
      Handler: create_logging_bucket
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.    #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0/                                        #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    #
        #  sions and limitations under the License.                                   #
        ###############################################################################
        
        import boto3
        from botocore.config import Config
        from botocore.exceptions import ClientError
        
        ERROR_CREATING_BUCKET = 'Error creating bucket '
        
        def connect_to_s3(boto_config):
            return boto3.client('s3', config=boto_config)
        
        def create_logging_bucket(event, context):
        
            boto_config = Config(
                retries ={
                    'mode': 'standard'
                }
            )
            s3 = connect_to_s3(boto_config)
        
            kms_key_arn = event['kms_key_arn']
            aws_account = event['account']
            aws_region = event['region']
            bucket_name = 'so0111-access-logs-' + aws_region + '-' + aws_account
        
            if create_bucket(s3, bucket_name, aws_region) == 'bucket_exists':
                return {\\"logging_bucket\\": bucket_name}
            encrypt_bucket(s3, bucket_name, kms_key_arn)
            put_access_block(s3, bucket_name)
            put_bucket_acl(s3, bucket_name)
        
            return {\\"logging_bucket\\": bucket_name}
        
        def create_bucket(s3, bucket_name, aws_region):
            try:
                kwargs = {
                    'Bucket': bucket_name,
                    'ACL': 'private'
                }
                if aws_region != 'us-east-1':
                    kwargs['CreateBucketConfiguration'] = {
                        'LocationConstraint': aws_region
                    }
        
                s3.create_bucket(**kwargs)
        
            except ClientError as ex:
                exception_type = ex.response['Error']['Code']
                # bucket already exists - return
                if exception_type in [\\"BucketAlreadyExists\\", \\"BucketAlreadyOwnedByYou\\"]:
                    print('Bucket ' + bucket_name + ' already exists')
                    return 'bucket_exists'
                else:
                    print(ex)
                    exit(ERROR_CREATING_BUCKET + bucket_name)
            except Exception as e:
                print(e)
                exit(ERROR_CREATING_BUCKET + bucket_name)
        
        def encrypt_bucket(s3, bucket_name, kms_key_arn):
            try:
                s3.put_bucket_encryption(
                    Bucket=bucket_name,
                    ServerSideEncryptionConfiguration={
                        'Rules': [
                            {
                                'ApplyServerSideEncryptionByDefault': {
                                    'SSEAlgorithm': 'aws:kms',
                                    'KMSMasterKeyID': kms_key_arn.split('key/')[1]
                                }
                            }
                        ]
                    }
                )
            except Exception as e:
                exit('Error encrypting bucket ' + bucket_name + ': ' + str(e))
        
        def put_access_block(s3, bucket_name):
            try:
                s3.put_public_access_block(
                    Bucket=bucket_name,
                    PublicAccessBlockConfiguration={
                        'BlockPublicAcls': True,
                        'IgnorePublicAcls': True,
                        'BlockPublicPolicy': True,
                        'RestrictPublicBuckets': True
                    }
                )
            except Exception as e:
                exit('Error setting public access block for bucket ' + bucket_name + ': ' + str(e))
        
        def put_bucket_acl(s3, bucket_name):
            try:
                s3.put_bucket_acl(
                    Bucket=bucket_name,
                    GrantReadACP='uri=http://acs.amazonaws.com/groups/s3/LogDelivery',
                    GrantWrite='uri=http://acs.amazonaws.com/groups/s3/LogDelivery'
                )
            except Exception as e:
                exit('Error setting ACL for bucket ' + bucket_name + ': ' + str(e))
        
        
        

    isEnd: false

  - 
    name: CreateCloudTrailBucket
    action: 'aws:executeScript'
    outputs:
      - Name: CloudTrailBucketName
        Selector: $.Payload.cloudtrail_bucket
        Type: String
    inputs:
      InputPayload: 
        account: '{{global:ACCOUNT_ID}}'
        region: '{{global:REGION}}'
        kms_key_arn: '{{KMSKeyArn}}'
        logging_bucket: '{{CreateLoggingBucket.LoggingBucketName}}'
      Runtime: python3.8
      Handler: create_encrypted_bucket
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.    #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0                                     #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    #
        #  sions and limitations under the License.                                   #
        ###############################################################################
        
        import boto3
        from botocore.config import Config
        from botocore.exceptions import ClientError
        
        def connect_to_s3(boto_config):
            return boto3.client('s3', config=boto_config)
        
        def create_encrypted_bucket(event, context):
        
            boto_config = Config(
                retries ={
                  'mode': 'standard'
                }
            )
            s3 = connect_to_s3(boto_config)
        
            kms_key_arn = event['kms_key_arn']
            aws_account = event['account']
            aws_region = event['region']
            logging_bucket = event['logging_bucket']
            bucket_name = 'so0111-aws-cloudtrail-' + aws_account
        
            if create_s3_bucket(s3, bucket_name, aws_region) == 'bucket_exists':
                return {\\"cloudtrail_bucket\\": bucket_name}
            put_bucket_encryption(s3, bucket_name, kms_key_arn)
            put_public_access_block(s3, bucket_name)
            put_bucket_logging(s3, bucket_name, logging_bucket)
        
            return {\\"cloudtrail_bucket\\": bucket_name}
        
        def create_s3_bucket(s3, bucket_name, aws_region):
            try:
                kwargs = {
                    'Bucket': bucket_name,
                    'ACL': 'private'
                }
                if aws_region != 'us-east-1':
                    kwargs['CreateBucketConfiguration'] = {
                        'LocationConstraint': aws_region
                    }
        
                s3.create_bucket(**kwargs)
        
            except ClientError as client_ex:
                exception_type = client_ex.response['Error']['Code']
                if exception_type in [\\"BucketAlreadyExists\\", \\"BucketAlreadyOwnedByYou\\"]:
                  print('Bucket ' + bucket_name + ' already exists')
                  return 'bucket_exists'
                else:
                    exit('Error creating bucket ' + bucket_name + ' ' + str(client_ex))
            except Exception as e:
                exit('Error creating bucket ' + bucket_name + ' ' + str(e))
        
        def put_bucket_encryption(s3, bucket_name, kms_key_arn):
            try:
                s3.put_bucket_encryption(
                    Bucket=bucket_name,
                    ServerSideEncryptionConfiguration={
                        'Rules': [
                            {
                                'ApplyServerSideEncryptionByDefault': {
                                    'SSEAlgorithm': 'aws:kms',
                                    'KMSMasterKeyID': kms_key_arn.split('key/')[1]
                                }
                            }
                        ]
                    }
                )
            except Exception as e:
                print(e)
                exit('Error applying encryption to bucket ' + bucket_name + ' with key ' + kms_key_arn)
        
        def put_public_access_block(s3, bucket_name):
            try:
                s3.put_public_access_block(
                    Bucket=bucket_name,
                    PublicAccessBlockConfiguration={
                        'BlockPublicAcls': True,
                        'IgnorePublicAcls': True,
                        'BlockPublicPolicy': True,
                        'RestrictPublicBuckets': True
                    }
                )
            except Exception as e:
                exit(f'Error setting public access block for bucket {bucket_name}: {str(e)}')
        
        def put_bucket_logging(s3, bucket_name, logging_bucket):
            try:
                s3.put_bucket_logging(
                    Bucket=bucket_name,
                    BucketLoggingStatus={
                        'LoggingEnabled': {
                            'TargetBucket': logging_bucket,
                            'TargetPrefix': 'cloudtrail-access-logs'
                        }
                    }
                )
            except Exception as e:
                print(e)
                exit('Error setting public access block for bucket ' + bucket_name)
        
        
    isEnd: false

  - 
    name: CreateCloudTrailBucketPolicy
    action: 'aws:executeScript'
    inputs:
      InputPayload: 
        cloudtrail_bucket: '{{CreateCloudTrailBucket.CloudTrailBucketName}}'
        partition: '{{AWSPartition}}'
        account: '{{global:ACCOUNT_ID}}'
      Runtime: python3.8
      Handler: create_bucket_policy
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.    #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0/                                        #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    #
        #  sions and limitations under the License.                                   #
        ###############################################################################
        
        import json
        import boto3
        from botocore.config import Config
        from botocore.exceptions import ClientError
        
        def connect_to_s3(boto_config):
            return boto3.client('s3', config=boto_config)
        
        def create_bucket_policy(event, context):
        
            boto_config = Config(
                retries ={
                  'mode': 'standard'
                }
            )
            s3 = connect_to_s3(boto_config)
        
            cloudtrail_bucket = event['cloudtrail_bucket']
            aws_partition = event['partition']
            aws_account = event['account']
            try:
                bucket_policy = {
                    \\"Version\\": \\"2012-10-17\\",
                    \\"Statement\\": [
                        {
                            \\"Sid\\": \\"AWSCloudTrailAclCheck20150319\\",
                            \\"Effect\\": \\"Allow\\",
                            \\"Principal\\": {
                                \\"Service\\": [
                                    \\"cloudtrail.amazonaws.com\\"
                                ]
                            },
                            \\"Action\\": \\"s3:GetBucketAcl\\",
                            \\"Resource\\": \\"arn:\\" + aws_partition + \\":s3:::\\" + cloudtrail_bucket
                        },
                        {
                            \\"Sid\\": \\"AWSCloudTrailWrite20150319\\",
                            \\"Effect\\": \\"Allow\\",
                            \\"Principal\\": {
                                \\"Service\\": [
                                    \\"cloudtrail.amazonaws.com\\"
                                ]
                            },
                            \\"Action\\": \\"s3:PutObject\\",
                            \\"Resource\\": \\"arn:\\" + aws_partition + \\":s3:::\\" + cloudtrail_bucket + \\"/AWSLogs/\\" + aws_account + \\"/*\\",
                            \\"Condition\\": { 
                                \\"StringEquals\\": { 
                                    \\"s3:x-amz-acl\\": \\"bucket-owner-full-control\\"
                                }
                            }
                        }
                    ]
                }
                s3.put_bucket_policy(
                    Bucket=cloudtrail_bucket,
                    Policy=json.dumps(bucket_policy)
                )
                return {
                    \\"output\\": {
                        \\"Message\\": f'Set bucket policy for bucket {cloudtrail_bucket}'
                    }
                }
            except Exception as e:
                print(e)
                exit('PutBucketPolicy failed: ' + str(e))
        
    isEnd: false

  -
    name: EnableCloudTrail
    action: 'aws:executeScript'
    outputs:
      - Name: CloudTrailBucketName
        Selector: $.Payload.cloudtrail_bucket
        Type: String
    inputs:
      InputPayload: 
        cloudtrail_bucket: '{{CreateCloudTrailBucket.CloudTrailBucketName}}'
        kms_key_arn: '{{KMSKeyArn}}'
      Runtime: python3.8
      Handler: enable_cloudtrail
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.    #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0/                                        #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    #
        #  sions and limitations under the License.                                   #
        ###############################################################################
        
        import boto3
        from botocore.config import Config
        from botocore.exceptions import ClientError
        
        def connect_to_cloudtrail(boto_config):
            return boto3.client('cloudtrail', config=boto_config)
        
        def enable_cloudtrail(event, context):
        
            boto_config = Config(
                retries ={
                  'mode': 'standard'
                }
            )
            ct = connect_to_cloudtrail(boto_config)
        
            try:
                ct.create_trail(
                    Name='multi-region-cloud-trail',
                    S3BucketName=event['cloudtrail_bucket'],
                    IncludeGlobalServiceEvents=True,
                    EnableLogFileValidation=True,
                    IsMultiRegionTrail=True,
                    KmsKeyId=event['kms_key_arn']
                )
                ct.start_logging(
                    Name='multi-region-cloud-trail'
                )
                return {
                    \\"output\\": {
                        \\"Message\\": f'CloudTrail Trail multi-region-cloud-trail created'
                    }
                }
            except Exception as e:
                exit('Error enabling AWS Config: ' + str(e))
                

    isEnd: false

  -
    name: Remediation
    action: 'aws:executeScript'
    outputs:
      - Name: Output
        Selector: $
        Type: StringMap
    inputs:
      InputPayload:
        cloudtrail_bucket: '{{CreateCloudTrailBucket.CloudTrailBucketName}}'
        logging_bucket: '{{CreateLoggingBucket.LoggingBucketName}}'
      Runtime: python3.8
      Handler: process_results
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.    #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0/                                        #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    #
        #  sions and limitations under the License.                                   #
        ###############################################################################
        
        def process_results(event, context):
          print(f'Created encrypted CloudTrail bucket {event[\\"cloudtrail_bucket\\"]}')
          print(f'Created access logging for CloudTrail bucket in bucket {event[\\"logging_bucket\\"]}')
          print('Enabled multi-region AWS CloudTrail')
          return {
            \\"response\\": {
              \\"message\\": \\"AWS CloudTrail successfully enabled\\",
              \\"status\\": \\"Success\\"
            }
          }
    isEnd: true

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-CreateCloudTrailMultiRegionTrail",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARRCreateLogMetricFilterAndAlarm": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "description: |
  ### Document Name - SHARR-CreateLogMetricFilterAndAlarm
  ## What does this document do?
  Creates a metric filter for a given log group and also creates and alarm for the metric.

  ## Input Parameters
  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  * CloudWatch Log Group Name: Name of the CloudWatch log group to use to create metric filter
  * Alarm Value: Threshhold value for the creating an alarm for the CloudWatch Alarm

  ## Security Standards / Controls
  * CIS v1.2.0:     3.1-3.14
schemaVersion: '0.3'
assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  LogGroupName:
    type: String
    description: Name of the log group to be used to create metric filter
    allowedPattern: '.*'
  FilterName:
    type: String
    description: Name for the metric filter
    allowedPattern: '.*'
  FilterPattern:
    type: String
    description: Filter pattern to create metric filter
    allowedPattern: '.*'
  MetricName:
    type: String
    description: Name of the metric for metric filter
    allowedPattern: '.*'
  MetricValue:
    type: Integer
    description: Value of the metric for metric filter
  MetricNamespace:
    type: String
    description: Namespace where the metrics will be sent
    allowedPattern: '.*'
  AlarmName:
    type: String
    description: Name of the Alarm to be created for the metric filter
    allowedPattern: '.*'
  AlarmDesc:
    type: String
    description: Description of the Alarm to be created for the metric filter
    allowedPattern: '.*'
  AlarmThreshold:
    type: Integer
    description: Threshold value for the alarm
  KMSKeyArn:
    type: String
    description: The ARN of a KMS key to use for encryption of the SNS Topic and Config bucket
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):kms:(?:[a-z]{2}(?:-gov)?-[a-z]+-\\\\d):\\\\d{12}:(?:(?:alias/[A-Za-z0-9/-_])|(?:key/(?i:[0-9a-f]{8}-(?:[0-9a-f]{4}-){3}[0-9a-f]{12})))$'
  SNSTopicName:
    type: String
    allowedPattern: ^[a-zA-Z0-9][a-zA-Z0-9-_]{0,255}$

mainSteps:
  -
    name: CreateTopic
    action: 'aws:executeScript'
    outputs:
      - Name: TopicArn
        Selector: $.Payload.topic_arn
        Type: String
    inputs:
      InputPayload:
        kms_key_arn: '{{KMSKeyArn}}'
        topic_name: '{{SNSTopicName}}'
      Runtime: python3.8
      Handler: create_encrypted_topic
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0                             #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    # 
        #  sions and limitations under the License.                                   #
        ###############################################################################
        
        import json
        import boto3
        from botocore.config import Config
        from botocore.exceptions import ClientError
        
        boto_config = Config(
            retries ={
                'mode': 'standard'
            }
        )
        
        def connect_to_sns():
            return boto3.client('sns', config=boto_config)
        
        def connect_to_ssm():
            return boto3.client('ssm', config=boto_config)
        
        def create_encrypted_topic(event, context):
        
            kms_key_arn = event['kms_key_arn']
            new_topic = False
            topic_arn = ''
            topic_name = event['topic_name']
        
            try:
                sns = connect_to_sns()
                topic_arn = sns.create_topic(
                    Name=topic_name,
                    Attributes={
                        'KmsMasterKeyId': kms_key_arn.split('key/')[1]
                    }
                )['TopicArn']
                new_topic = True
        
            except ClientError as client_exception:
                exception_type = client_exception.response['Error']['Code']
                if exception_type == 'InvalidParameter':
                    print(f'Topic {topic_name} already exists. This remediation may have been run before.')
                    print('Ignoring exception - remediation continues.')
                    topic_arn = sns.create_topic(
                        Name=topic_name
                    )['TopicArn']
                else:
                    exit(f'ERROR: Unhandled client exception: {client_exception}')
              
            except Exception as e:
                exit(f'ERROR: could not create SNS Topic {topic_name}: {str(e)}')
        
            if new_topic:
                try:
                    ssm = connect_to_ssm()
                    ssm.put_parameter(
                        Name='/Solutions/SO0111/SNS_Topic_CIS3.x',
                        Description='SNS Topic for AWS Config updates',
                        Type='String',
                        Overwrite=True,
                        Value=topic_arn
                    )               
                except Exception as e:
                    exit(f'ERROR: could not create SNS Topic {topic_name}: {str(e)}')
        
            create_topic_policy(topic_arn)
            
            return {\\"topic_arn\\": topic_arn} 
        
        def create_topic_policy(topic_arn):
            sns = connect_to_sns()
            try:
                topic_policy = {
                    \\"Id\\": \\"Policy_ID\\",
                    \\"Statement\\": [
                    {
                        \\"Sid\\": \\"AWSConfigSNSPolicy\\",
                        \\"Effect\\": \\"Allow\\",
                        \\"Principal\\": {
                        \\"Service\\": \\"cloudwatch.amazonaws.com\\"
                        },
                        \\"Action\\": \\"SNS:Publish\\",
                        \\"Resource\\": topic_arn,
                    }]
                }
                    
                sns.set_topic_attributes(
                    TopicArn=topic_arn,
                    AttributeName='Policy',
                    AttributeValue=json.dumps(topic_policy)
                )
            except Exception as e:
                exit(f'ERROR: Failed to SetTopicAttributes for {topic_arn}: {str(e)}')
        

  -
    name: CreateMetricFilerAndAlarm
    action: 'aws:executeScript'
    outputs:
      - Name: Output
        Selector: $.Payload.response
        Type: StringMap
    inputs:
      InputPayload:
        LogGroupName: '{{LogGroupName}}'
        FilterName: '{{FilterName}}'
        FilterPattern: '{{FilterPattern}}'
        MetricName: '{{MetricName}}'
        MetricNamespace: '{{MetricNamespace}}'
        MetricValue: '{{MetricValue}}'
        AlarmName: '{{AlarmName}}'
        AlarmDesc: '{{AlarmDesc}}'
        AlarmThreshold: '{{AlarmThreshold}}'
        TopicArn: '{{CreateTopic.TopicArn}}'
      Runtime: python3.8
      Handler: verify
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0/                            #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    #
        #  sions and limitations under the License.                                   #
        ###############################################################################
        
        import boto3
        import logging
        import os
        from botocore.config import Config
        
        boto_config = Config(
            retries={
                'max_attempts': 10,
                'mode': 'standard'
            }
        )
        
        log = logging.getLogger()
        LOG_LEVEL = str(os.getenv('LogLevel', 'INFO'))
        log.setLevel(LOG_LEVEL)
        
        
        def get_service_client(service_name):
            \\"\\"\\"
            Returns the service client for given the service name
            :param service_name: name of the service
            :return: service client
            \\"\\"\\"
            log.debug(\\"Getting the service client for service: {}\\".format(service_name))
            return boto3.client(service_name, config=boto_config)
        
        
        def put_metric_filter(cw_log_group, filter_name, filter_pattern, metric_name, metric_namespace, metric_value):
            \\"\\"\\"
            Puts the metric filter on the CloudWatch log group with provided values
            :param cw_log_group: Name of the CloudWatch log group
            :param filter_name: Name of the filter
            :param filter_pattern: Pattern for the filter
            :param metric_name: Name of the metric
            :param metric_namespace: Namespace where metric is logged
            :param metric_value: Value to be logged for the metric
            \\"\\"\\"
            logs_client = get_service_client('logs')
            log.debug(\\"Putting the metric filter with values: {}\\".format([
                cw_log_group, filter_name, filter_pattern, metric_name, metric_namespace, metric_value]))
            try:
                logs_client.put_metric_filter(
                    logGroupName=cw_log_group,
                    filterName=filter_name,
                    filterPattern=filter_pattern,
                    metricTransformations=[
                        {
                            'metricName': metric_name,
                            'metricNamespace': metric_namespace,
                            'metricValue': str(metric_value),
                            'unit': 'Count'
                        }
                    ]
                )
            except Exception as e:
                exit(\\"Exception occurred while putting metric filter: \\" + str(e))
            log.debug(\\"Successfully added the metric filter.\\")
        
        
        def put_metric_alarm(alarm_name, alarm_desc, alarm_threshold, metric_name, metric_namespace, topic_arn):
            \\"\\"\\"
            Puts the metric alarm for the metric name with provided values
            :param alarm_name: Name for the alarm
            :param alarm_desc: Description for the alarm
            :param alarm_threshold: Threshold value for the alarm
            :param metric_name: Name of the metric
            :param metric_namespace: Namespace where metric is logged
            \\"\\"\\"
            cw_client = get_service_client('cloudwatch')
            log.debug(\\"Putting the metric alarm with values {}\\".format(
                [alarm_name, alarm_desc, alarm_threshold, metric_name, metric_namespace]))
            try:
                cw_client.put_metric_alarm(
                    AlarmName=alarm_name,
                    AlarmDescription=alarm_desc,
                    ActionsEnabled=True,
                    OKActions=[
                        topic_arn
                    ],
                    AlarmActions=[
                        topic_arn
                    ],
                    MetricName=metric_name,
                    Namespace=metric_namespace,
                    Statistic='Sum',
                    Period=300,
                    Unit='Count',
                    EvaluationPeriods=12,
                    DatapointsToAlarm=1,
                    Threshold=alarm_threshold,
                    ComparisonOperator='GreaterThanOrEqualToThreshold',
                    TreatMissingData='notBreaching'
                )
            except Exception as e:
                exit(\\"Exception occurred while putting metric alarm: \\" + str(e))
            log.debug(\\"Successfully added metric alarm.\\")
        
        
        def verify(event, context):
            log.info(\\"Begin handler\\")
            log.debug(\\"====Print Event====\\")
            log.debug(event)
        
            filter_name = event['FilterName']
            filter_pattern = event['FilterPattern']
            metric_name = event['MetricName']
            metric_namespace = event['MetricNamespace']
            metric_value = event['MetricValue']
            alarm_name = event['AlarmName']
            alarm_desc = event['AlarmDesc']
            alarm_threshold = event['AlarmThreshold']
            cw_log_group = event['LogGroupName']
            topic_arn = event['TopicArn']
        
            put_metric_filter(cw_log_group, filter_name, filter_pattern, metric_name, metric_namespace, metric_value)
            put_metric_alarm(alarm_name, alarm_desc, alarm_threshold, metric_name, metric_namespace, topic_arn)
            return {
                \\"response\\": {
                    \\"message\\": f'Created filter {event[\\"FilterName\\"]} for metric {event[\\"MetricName\\"]}, and alarm {event[\\"AlarmName\\"]}',
                    \\"status\\": \\"Success\\"
                }
            }
        

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-CreateLogMetricFilterAndAlarm",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARRDisablePublicAccessToRDSInstance": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "schemaVersion: \\"0.3\\"
description: |
   ### Document name - AWSConfigRemediation-DisablePublicAccessToRDSInstance

   ## What does this document do?
   The runbook disables public accessibility for the Amazon RDS database instance you specify using
   the [ModifyDBInstance](https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_ModifyDBInstance.html) API.

   ## Input Parameters
   * AutomationAssumeRole: (Required) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf.
   * DbiResourceId: (Required) The resource identifier for the DB instance you want to disable public accessibility.

   ## Output Parameters
   * DisablePubliclyAccessibleOnRDS.Response: The standard HTTP response from the ModifyDBInstance API.

assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  DbiResourceId:
    type: String
    description: (Required) The resource identifier for the DB instance you want to disable public accessibility.
    allowedPattern: \\"db-[A-Z0-9]{26}\\"
outputs:
  - DisablePubliclyAccessibleOnRDS.Response
mainSteps:
  -
    name: GetRDSInstanceIdentifier
    action: \\"aws:executeAwsApi\\"
    description: |
      ## GetRDSInstanceIdentifier
      Gathers the DB instance identifier from the DB instance resource identifier.
      ## Outputs
      * DbInstanceIdentifier: The Amazon RDS DB instance identifier.
    timeoutSeconds: 600
    isEnd: false
    inputs:
      Service: rds
      Api: DescribeDBInstances
      Filters:
        - Name: \\"dbi-resource-id\\"
          Values:
            - \\"{{ DbiResourceId }}\\"
    outputs:
      - Name: DbInstanceIdentifier
        Selector: $.DBInstances[0].DBInstanceIdentifier
        Type: String
  -
    name: VerifyDBInstanceStatus
    action: \\"aws:assertAwsResourceProperty\\"
    timeoutSeconds: 600
    isEnd: false
    description: |
      ## VerifyDBInstanceStatus
      Verifies the DB instances is in an AVAILABLE state.
    inputs:
      Service: rds
      Api: DescribeDBInstances
      DBInstanceIdentifier: \\"{{ GetRDSInstanceIdentifier.DbInstanceIdentifier }}\\"
      PropertySelector: \\"$.DBInstances[0].DBInstanceStatus\\"
      DesiredValues:
        - \\"available\\"
  -
    name: DisablePubliclyAccessibleOnRDS
    action: \\"aws:executeAwsApi\\"
    description: |
      ## DisablePubliclyAccessibleOnRDS
      Disables public accessibility on your DB instance.
      ## Outputs
      * Response: The standard HTTP response from the ModifyDBInstance API.
    timeoutSeconds: 600
    isEnd: false
    inputs:
       Service: rds
       Api: ModifyDBInstance
       DBInstanceIdentifier: \\"{{ GetRDSInstanceIdentifier.DbInstanceIdentifier }}\\"
       PubliclyAccessible: false
    outputs:
      - Name: Response
        Selector: $
        Type: StringMap
  -
    name: WaitForDBInstanceStatusToModify
    action: \\"aws:waitForAwsResourceProperty\\"
    timeoutSeconds: 600
    isEnd: false
    description: |
      ## WaitForDBInstanceStatusToModify
      Waits for the DB instance to change to a MODIFYING state.
    inputs:
      Service: rds
      Api: DescribeDBInstances
      DBInstanceIdentifier: \\"{{ GetRDSInstanceIdentifier.DbInstanceIdentifier }}\\"
      PropertySelector: \\"$.DBInstances[0].DBInstanceStatus\\"
      DesiredValues:
        - \\"modifying\\"
  -
    name: WaitForDBInstanceStatusToAvailableAfterModify
    action: \\"aws:waitForAwsResourceProperty\\"
    timeoutSeconds: 600
    isEnd: false
    description: |
      ## WaitForDBInstanceStatusToAvailableAfterModify
      Waits for the DB instance to change to an AVAILABLE state
    inputs:
      Service: rds
      Api: DescribeDBInstances
      DBInstanceIdentifier: \\"{{ GetRDSInstanceIdentifier.DbInstanceIdentifier }}\\"
      PropertySelector: \\"$.DBInstances[0].DBInstanceStatus\\"
      DesiredValues:
        - \\"available\\"
  -
    name: VerifyDBInstancePubliclyAccess
    action: \\"aws:assertAwsResourceProperty\\"
    timeoutSeconds: 600
    isEnd: true
    description: |
      ## VerifyDBInstancePubliclyAccess
      Confirms public accessibility is disabled on the DB instance.
    inputs:
      Service: rds
      Api: DescribeDBInstances
      DBInstanceIdentifier: \\"{{ GetRDSInstanceIdentifier.DbInstanceIdentifier }}\\"
      PropertySelector: \\"$.DBInstances[0].PubliclyAccessible\\"
      DesiredValues:
        - \\"False\\"

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-DisablePublicAccessToRDSInstance",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARRDisablePublicAccessToRedshiftCluster": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "schemaVersion: \\"0.3\\"
description: |
  ### Document name - SHARR-DisablePublicAccessToRedshiftCluster

  ## What does this document do?
  The runbook disables public accessibility for the Amazon Redshift cluster you specify using the [ModifyCluster]
  (https://docs.aws.amazon.com/redshift/latest/APIReference/API_ModifyCluster.html) API.

  ## Input Parameters
  * AutomationAssumeRole: (Required) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf.
  * ClusterIdentifier: (Required) The unique identifier of the cluster you want to disable the public accessibility.

  ## Output Parameters
  * DisableRedshiftPubliclyAccessible.Response: The standard HTTP response from the ModifyCluster API call.

assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern:  '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  ClusterIdentifier:
    type: String
    description: (Required) The unique identifier of the cluster you want to disable the public accessibility.
    allowedPattern: \\"^(?!.*--)[a-z][a-z0-9-]{0,62}(?<!-)$\\"

outputs:
  - DisableRedshiftPubliclyAccessible.Response
mainSteps:
  -
    name: DisableRedshiftPubliclyAccessible
    action: aws:executeAwsApi
    description: |
      ## DisableRedshiftPubliclyAccessible
      Disables public accessibility for the cluster specified in the ClusterIdentifer parameter.
      ## Outputs
      * Response: The standard HTTP response from the ModifyCluster API call.
    timeoutSeconds: 600
    isEnd: false
    inputs:
      Service: redshift
      Api: ModifyCluster
      ClusterIdentifier: \\"{{ ClusterIdentifier }}\\"
      PubliclyAccessible: false
    outputs:
      - Name: Response
        Selector: $
        Type: StringMap
  - name: WaitForRedshiftClusterAvailability
    action: aws:waitForAwsResourceProperty
    description: |
      ## WaitForRedshiftClusterAvailability
      Waits for the state of the cluster to change to available.
    timeoutSeconds: 600
    isEnd: false
    inputs:
      Service: redshift
      Api: DescribeClusters
      ClusterIdentifier: \\"{{ ClusterIdentifier }}\\"
      PropertySelector: $.Clusters[0].ClusterStatus
      DesiredValues:
        - \\"available\\"
  -
    name: VerifyRedshiftPubliclyAccessible
    action: \\"aws:assertAwsResourceProperty\\"
    timeoutSeconds: 600
    isEnd: true
    description: |
      ## VerifyRedshiftPubliclyAccessible
      Confirms the public accessibility setting is disabled on the cluster.
    inputs:
      Service: redshift
      Api: DescribeClusters
      ClusterIdentifier: \\"{{ ClusterIdentifier }}\\"
      PropertySelector: $.Clusters[0].PubliclyAccessible
      DesiredValues:
        - \\"False\\"

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-DisablePublicAccessToRedshiftCluster",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARREnableAWSConfig": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "schemaVersion: \\"0.3\\"
description: |
  ### Document name - SHARR-EnableAWSConfig

  ## What does this document do?
  Enables AWS Config:
  * Turns on recording for all resources.
  * Creates an encrypted bucket for Config logging.
  * Creates a logging bucket for access logs for the config bucket
  * Creates an SNS topic for Config notifications
  * Creates a service-linked role

  ## Input Parameters
  * AutomationAssumeRole: (Required) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf.
  * KMSKeyArn: KMS Customer-managed key to use for encryption of Config log data and SNS Topic
  * AWSServiceRoleForConfig: (Optional) The name of the exiting IAM role to use for the Config service. Default: aws-service-role/config.amazonaws.com/AWSServiceRoleForConfig
  * SNSTopicName: (Required) Name of the SNS Topic to use to post AWS Config messages.

  ## Output Parameters
  * Remediation.Output: STDOUT and messages from the remediation steps.

assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  KMSKeyArn:
    type: String
    description: The ARN of a KMS key to use for encryption of the SNS Topic and Config bucket
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):kms:(?:[a-z]{2}(?:-gov)?-[a-z]+-\\\\d):\\\\d{12}:(?:(?:alias/[A-Za-z0-9/-_])|(?:key/(?i:[0-9a-f]{8}-(?:[0-9a-f]{4}-){3}[0-9a-f]{12})))$'
  AWSServiceRoleForConfig:
    type: String
    default: aws-service-role/config.amazonaws.com/AWSServiceRoleForConfig
    allowedPattern: '^(:?[\\\\w+=,.@-]+/)+[\\\\w+=,.@-]+$'
  SNSTopicName:
    type: String
    allowedPattern: ^[a-zA-Z0-9][a-zA-Z0-9-_]{0,255}$
outputs:
  - Remediation.Output

mainSteps:
  -
    name: CreateTopic
    action: 'aws:executeScript'
    outputs:
      - Name: TopicArn
        Selector: $.Payload.topic_arn
        Type: String
    inputs:
      InputPayload:
        kms_key_arn: '{{KMSKeyArn}}'
        topic_name: '{{SNSTopicName}}'
      Runtime: python3.8
      Handler: create_encrypted_topic
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0                             #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    # 
        #  sions and limitations under the License.                                   #
        ###############################################################################
        
        import json
        import boto3
        from botocore.config import Config
        from botocore.exceptions import ClientError
        
        boto_config = Config(
            retries ={
                'mode': 'standard'
            }
        )
        
        def connect_to_sns():
            return boto3.client('sns', config=boto_config)
        
        def connect_to_ssm():
            return boto3.client('ssm', config=boto_config)
        
        def create_encrypted_topic(event, context):
        
            kms_key_arn = event['kms_key_arn']
            new_topic = False
            topic_arn = ''
            topic_name = event['topic_name']
        
            try:
                sns = connect_to_sns()
                topic_arn = sns.create_topic(
                    Name=topic_name,
                    Attributes={
                        'KmsMasterKeyId': kms_key_arn.split('key/')[1]
                    }
                )['TopicArn']
                new_topic = True
        
            except ClientError as client_exception:
                exception_type = client_exception.response['Error']['Code']
                if exception_type == 'InvalidParameter':
                    print(f'Topic {topic_name} already exists. This remediation may have been run before.')
                    print('Ignoring exception - remediation continues.')
                    topic_arn = sns.create_topic(
                        Name=topic_name
                    )['TopicArn']
                else:
                    exit(f'ERROR: Unhandled client exception: {client_exception}')
              
            except Exception as e:
                exit(f'ERROR: could not create SNS Topic {topic_name}: {str(e)}')
        
            if new_topic:
                try:
                    ssm = connect_to_ssm()
                    ssm.put_parameter(
                        Name='/Solutions/SO0111/SNS_Topic_Config.1',
                        Description='SNS Topic for AWS Config updates',
                        Type='String',
                        Overwrite=True,
                        Value=topic_arn
                    )               
                except Exception as e:
                    exit(f'ERROR: could not create SNS Topic {topic_name}: {str(e)}')
        
            create_topic_policy(topic_arn)
            
            return {\\"topic_arn\\": topic_arn} 
        
        def create_topic_policy(topic_arn):
            sns = connect_to_sns()
            try:
                topic_policy = {
                    \\"Id\\": \\"Policy_ID\\",
                    \\"Statement\\": [
                    {
                        \\"Sid\\": \\"AWSConfigSNSPolicy\\",
                        \\"Effect\\": \\"Allow\\",
                        \\"Principal\\": {
                        \\"Service\\": \\"config.amazonaws.com\\"
                        },
                        \\"Action\\": \\"SNS:Publish\\",
                        \\"Resource\\": topic_arn,
                    }]
                }
                    
                sns.set_topic_attributes(
                    TopicArn=topic_arn,
                    AttributeName='Policy',
                    AttributeValue=json.dumps(topic_policy)
                )
            except Exception as e:
                exit(f'ERROR: Failed to SetTopicAttributes for {topic_arn}: {str(e)}')
        
    isEnd: false

  - name: CreateAccessLoggingBucket
    action: 'aws:executeAutomation'
    isEnd: false
    inputs:
      DocumentName: SHARR-CreateAccessLoggingBucket
      RuntimeParameters:
        BucketName: 'so0111-accesslogs-{{global:ACCOUNT_ID}}-{{global:REGION}}'
        AutomationAssumeRole: 'arn:{{global:AWS_PARTITION}}:iam::{{global:ACCOUNT_ID}}:role/SO0111-CreateAccessLoggingBucket'

  - name: CreateConfigBucket
    action: 'aws:executeScript'
    isEnd: false
    outputs:
      - Name: ConfigBucketName
        Selector: $.Payload.config_bucket
        Type: String
    inputs:
      InputPayload:
        logging_bucket: 'so0111-accesslogs-{{global:ACCOUNT_ID}}-{{global:REGION}}'
        account: '{{global:ACCOUNT_ID}}'
        region: '{{global:REGION}}'
        partition: '{{global:AWS_PARTITION}}'
        kms_key_arn: '{{KMSKeyArn}}'
      Runtime: python3.8
      Handler: create_encrypted_bucket
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0/                            #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    #
        #  sions and limitations under the License.                                   #
        ###############################################################################
        
        import json
        import boto3
        from botocore.config import Config
        from botocore.exceptions import ClientError
        from botocore.retries import bucket
        
        boto_config = Config(
            retries ={
                'mode': 'standard'
            }
        )
        
        def connect_to_s3(boto_config):
            return boto3.client('s3', config=boto_config)
        
        def create_bucket(bucket_name, aws_region):
            s3 = connect_to_s3(boto_config)
            try:
                if aws_region == 'us-east-1':
                    s3.create_bucket(
                        ACL='private',
                        Bucket=bucket_name
                    )
                else:
                    s3.create_bucket(
                        ACL='private',
                        Bucket=bucket_name,
                        CreateBucketConfiguration={
                            'LocationConstraint': aws_region
                        }
                    )
                return \\"created\\"
        
            except ClientError as ex:
                exception_type = ex.response['Error']['Code']
                # bucket already exists - return
                if exception_type in [\\"BucketAlreadyExists\\", \\"BucketAlreadyOwnedByYou\\"]:
                    print('Bucket ' + bucket_name + ' already exists')
                    return \\"already exists\\"
                else:
                    exit(f'ERROR creating bucket {bucket_name}: {str(ex)}')
            except Exception as e:
                exit(f'ERROR creating bucket {bucket_name}: {str(e)}')
        
        def encrypt_bucket(bucket_name, kms_key):
            s3 = connect_to_s3(boto_config)
            try:
                s3.put_bucket_encryption(
                Bucket=bucket_name,
                ServerSideEncryptionConfiguration={
                'Rules': [
                    {
                    'ApplyServerSideEncryptionByDefault': {
                        'SSEAlgorithm': 'aws:kms',
                        'KMSMasterKeyID': kms_key
                    }
                    }
                ]
                }
            )
            except Exception as e:
                exit(f'ERROR putting bucket encryption for {bucket_name}: {str(e)}')
        
        def block_public_access(bucket_name):
            s3 = connect_to_s3(boto_config)
            try:
                s3.put_public_access_block(
                    Bucket=bucket_name,
                    PublicAccessBlockConfiguration={
                        'BlockPublicAcls': True,
                        'IgnorePublicAcls': True,
                        'BlockPublicPolicy': True,
                        'RestrictPublicBuckets': True
                    }
                )
            except Exception as e:
                exit(f'ERROR setting public access block for bucket {bucket_name}: {str(e)}')
        
        def enable_access_logging(bucket_name, logging_bucket):
            s3 = connect_to_s3(boto_config)
            try:
                s3.put_bucket_logging(
                    Bucket=bucket_name,
                    BucketLoggingStatus={
                    'LoggingEnabled': {
                        'TargetBucket': logging_bucket,
                        'TargetPrefix': f'access-logs/{bucket_name}'
                    }
                    }
                )
            except Exception as e:
                exit(f'Error setting access logging for bucket {bucket_name}: {str(e)}')
        
        def create_bucket_policy(config_bucket, aws_partition):  
            s3 = connect_to_s3(boto_config)   
            try:
                bucket_policy = {
                    \\"Version\\": \\"2012-10-17\\",
                    \\"Statement\\": [
                    {
                        \\"Sid\\": \\"AWSConfigBucketPermissionsCheck\\",
                        \\"Effect\\": \\"Allow\\",
                        \\"Principal\\": {
                            \\"Service\\": [
                                \\"config.amazonaws.com\\"
                            ]
                        },
                        \\"Action\\": \\"s3:GetBucketAcl\\",
                        \\"Resource\\": \\"arn:\\" + aws_partition + \\":s3:::\\" + config_bucket
                    },
                    {
                        \\"Sid\\": \\"AWSConfigBucketExistenceCheck\\",
                        \\"Effect\\": \\"Allow\\",
                        \\"Principal\\": {
                            \\"Service\\": [
                                \\"config.amazonaws.com\\"
                            ]
                        },
                        \\"Action\\": \\"s3:ListBucket\\",
                        \\"Resource\\": \\"arn:\\" + aws_partition + \\":s3:::\\" + config_bucket
                    },
                    {
                        \\"Sid\\": \\"AWSConfigBucketDelivery\\",
                        \\"Effect\\": \\"Allow\\",
                        \\"Principal\\": {
                            \\"Service\\": [
                                \\"config.amazonaws.com\\"    
                            ]
                        },
                        \\"Action\\": \\"s3:PutObject\\",
                        \\"Resource\\": \\"arn:\\" + aws_partition + \\":s3:::\\" + config_bucket + \\"/*\\",
                        \\"Condition\\": { 
                            \\"StringEquals\\": { 
                                \\"s3:x-amz-acl\\": \\"bucket-owner-full-control\\"
                            }
                        }
                    }
                    ]
                }
                s3.put_bucket_policy(
                    Bucket=config_bucket,
                    Policy=json.dumps(bucket_policy)
                )
            except Exception as e:
                exit(f'ERROR: PutBucketPolicy failed for {config_bucket}: {str(e)}')
        
        def create_encrypted_bucket(event, context):
            
            kms_key_arn = event['kms_key_arn']
            aws_partition = event['partition']
            aws_account = event['account']
            aws_region = event['region']
            logging_bucket = event['logging_bucket']
            bucket_name = 'so0111-aws-config-' + aws_region + '-' + aws_account
        
            if create_bucket(bucket_name, aws_region) == 'already exists':
                return {\\"config_bucket\\": bucket_name}
        
            encrypt_bucket(bucket_name, kms_key_arn.split('key/')[1])
            block_public_access(bucket_name)
            enable_access_logging(bucket_name, logging_bucket)
            create_bucket_policy(bucket_name, aws_partition)
        
            return {\\"config_bucket\\": bucket_name}
        

  -
    name: EnableConfig
    action: 'aws:executeScript'
    outputs:
      - Name: ConfigBucketName
        Selector: $.Payload.config_bucket
        Type: String
    inputs:
      InputPayload:
        partition: '{{global:AWS_PARTITION}}'
        account: '{{global:ACCOUNT_ID}}'
        region: '{{global:REGION}}'
        config_bucket: '{{CreateConfigBucket.ConfigBucketName}}'
        aws_service_role: '{{AWSServiceRoleForConfig}}'
        topic_arn: '{{CreateTopic.TopicArn}}'
      Runtime: python3.8
      Handler: enable_config
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0/                            #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    #
        #  sions and limitations under the License.                                   #
        ###############################################################################
         
        import boto3
        from botocore.config import Config
        from botocore.exceptions import ClientError
        
        boto_config = Config(
            retries ={
                'mode': 'standard'
            }
        )
        
        def connect_to_config(boto_config):
            return boto3.client('config', config=boto_config)
        
        def create_config_recorder(aws_partition, aws_account, aws_service_role):
            cfgsvc = connect_to_config(boto_config)
            try:
                config_service_role_arn = 'arn:' + aws_partition + ':iam::' + aws_account + ':role/' + aws_service_role
                cfgsvc.put_configuration_recorder(
                    ConfigurationRecorder={
                        'name': 'default',
                        'roleARN': config_service_role_arn,
                        'recordingGroup': {
                            'allSupported': True,
                            'includeGlobalResourceTypes': True
                        }
                    }
                )
            except ClientError as ex:
                exception_type = ex.response['Error']['Code']
                # recorder already exists - continue
                if exception_type in [\\"MaxNumberOfConfigurationRecordersExceededException\\"]:
                    print('Config Recorder already exists. Continuing.')
                else:
                    exit(f'ERROR: Boto3 ClientError enabling Config: {exception_type} - {str(ex)}')
            except Exception as e:
                exit(f'ERROR enabling AWS Config - create_config_recorder: {str(e)}')
        
        def create_delivery_channel(config_bucket, aws_account, topic_arn):
            cfgsvc = connect_to_config(boto_config)
            try:
                cfgsvc.put_delivery_channel(
                    DeliveryChannel={
                        'name': 'default',
                        's3BucketName': config_bucket,
                        's3KeyPrefix': aws_account,
                        'snsTopicARN': topic_arn,
                        'configSnapshotDeliveryProperties': {
                            'deliveryFrequency': 'Twelve_Hours'
                        }
                    }
                )
            except ClientError as ex:
                exception_type = ex.response['Error']['Code']
                # delivery channel already exists - return
                if exception_type in [\\"MaxNumberOfDeliveryChannelsExceededException\\"]:
                    print('DeliveryChannel already exists')
                else:
                    exit(f'ERROR: Boto3 ClientError enabling Config: {exception_type} - {str(ex)}')
            except Exception as e:
                exit(f'ERROR enabling AWS Config - create_delivery_channel: {str(e)}')
        
        def start_recorder():
            cfgsvc = connect_to_config(boto_config)
            try:
                cfgsvc.start_configuration_recorder(
                    ConfigurationRecorderName='default'
                )
            except Exception as e:
                exit(f'ERROR enabling AWS Config: {str(e)}')          
        
        def enable_config(event, context):
            aws_account = event['account']
            aws_partition = event['partition']
            aws_service_role = event['aws_service_role']
            config_bucket = event['config_bucket']
            topic_arn = event['topic_arn']
        
            create_config_recorder(aws_partition, aws_account, aws_service_role)
            create_delivery_channel(config_bucket, aws_account, topic_arn)
            start_recorder()
        
    isEnd: false

  -
    name: Remediation
    action: 'aws:executeScript'
    outputs:
      - Name: Output
        Selector: $
        Type: StringMap
    inputs:
      InputPayload:
        config_bucket: '{{CreateConfigBucket.ConfigBucketName}}'
        logging_bucket: 'so0111-accesslogs-{{global:ACCOUNT_ID}}-{{global:REGION}}'
        sns_topic_arn: '{{CreateTopic.TopicArn}}'
      Runtime: python3.8
      Handler: process_results
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0/                            #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    #
        #  sions and limitations under the License.                                   #
        ###############################################################################
         
        def process_results(event, context):
            print(f'Created encrypted SNS topic {event[\\"sns_topic_arn\\"]}')
            print(f'Created encrypted Config bucket {event[\\"config_bucket\\"]}')
            print(f'Created access logging for Config bucket in bucket {event[\\"logging_bucket\\"]}')
            print('Enabled AWS Config by creating a default recorder')
            return {
                \\"response\\": {
                    \\"message\\": \\"AWS Config successfully enabled\\",
                    \\"status\\": \\"Success\\"
                }
            }
    isEnd: true

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-EnableAWSConfig",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARREnableAutoScalingGroupELBHealthCheck": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "schemaVersion: \\"0.3\\"
description: |
  ### Document name - SHARR-EnableAutoScalingGroupELBHealthCheck

  ## What does this document do?
  This runbook enables health checks for the Amazon EC2 Auto Scaling (Auto Scaling) group you specify using the [UpdateAutoScalingGroup](https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_UpdateAutoScalingGroup.html) API.

  ## Input Parameters
  * AutomationAssumeRole: (Required) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf.
  * AutoScalingGroupARN: (Required) The Amazon Resource Name (ARN) of the auto scaling group that you want to enable health checks on.
  * HealthCheckGracePeriod: (Optional) The amount of time, in seconds, that Auto Scaling waits before checking the health status of an Amazon Elastic Compute Cloud (Amazon EC2) instance that has come into service.

  ## Output Parameters

  * Remediation.Output - stdout messages from the remediation

  ## Security Standards / Controls
  * AFSBP v1.0.0: Autoscaling.1
  * CIS v1.2.0:   2.1
  * PCI:          Autoscaling.1

assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  AutoScalingGroupName:
    type: String
    description: (Required) The Amazon Resource Name (ARN) of the auto scaling group that you want to enable health checks on.
    allowedPattern: ^[\\\\u0020-\\\\uD7FF\\\\uE000-\\\\uFFFD\\\\uD800\\\\uDC00-\\\\uDBFF\\\\uDFFF]{1,255}$
  HealthCheckGracePeriod:
    type: Integer
    description: (Optional) The amount of time, in seconds, that Auto Scaling waits before checking the health status of an Amazon Elastic Compute Cloud (Amazon EC2) instance that has come into service.
    allowedPattern: ^[0-9]\\\\d*$
    default: 300

outputs:
  -  Remediation.Output
mainSteps:
  - name: EnableELBHealthCheck
    action: 'aws:executeAwsApi'
    inputs:
      Service: autoscaling
      Api: UpdateAutoScalingGroup
      AutoScalingGroupName: '{{AutoScalingGroupName}}'
      HealthCheckType: ELB
      HealthCheckGracePeriod: '{{HealthCheckGracePeriod}}'
    description: Enable ELB health check type on ASG
    outputs:
      - Name: Output
        Selector: $
        Type: StringMap

  - name: Remediation
    action: 'aws:executeScript'
    outputs:
      - Name: Output
        Selector: $.Payload.response
        Type: StringMap
    inputs:
      InputPayload:
        AsgName: '{{AutoScalingGroupName}}'
      Runtime: python3.8
      Handler: verify
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.    #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0/                                        #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    #
        #  sions and limitations under the License.                                   #
        ###############################################################################
        
        import json
        import boto3
        from botocore.config import Config
        from botocore.exceptions import ClientError
        
        def connect_to_autoscaling(boto_config):
            return boto3.client('autoscaling', config=boto_config)
        
        def verify(event, context):
        
            boto_config = Config(
                retries ={
                  'mode': 'standard'
                }
            )
            asg_client = connect_to_autoscaling(boto_config)
            asg_name = event['AsgName']
            try:
                desc_asg = asg_client.describe_auto_scaling_groups(
                    AutoScalingGroupNames=[asg_name]
                )
                if len(desc_asg['AutoScalingGroups']) < 1:
                    exit(f'No AutoScaling Group found matching {asg_name}')
                    
                health_check = desc_asg['AutoScalingGroups'][0]['HealthCheckType']
                print(json.dumps(desc_asg['AutoScalingGroups'][0], default=str))
                if (health_check == 'ELB'):
                    return {
                        \\"response\\": {
                            \\"message\\": \\"Autoscaling Group health check type updated to ELB\\",
                            \\"status\\": \\"Success\\"
                        }
                    }
                else:
                    return {
                        \\"response\\": {
                            \\"message\\": \\"Autoscaling Group health check type is not ELB\\",
                            \\"status\\": \\"Failed\\"
                        }
                    }
            except Exception as e:
                exit(\\"Exception while executing remediation: \\" + str(e))
        

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-EnableAutoScalingGroupELBHealthCheck",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARREnableAutomaticSnapshotsOnRedshiftCluster": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
# SPDX-License-Identifier: Apache-2.0
---
schemaVersion: '0.3'
description: |
  ### Document name - SHARR-EnableAutomaticSnapshotsOnRedshiftCluster

  ## What does this document do?
  The runbook enables automatic snapshots on a Redshift cluster.

  ## Input Parameters
  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  * ClusterIdentifier: (Required) The unique identifier of the cluster.
  * RetentionPeriod: (Optional) The minimum retention period for the automatic snapshots in days.

  ## Output Parameters
  * QueryRetentionPeriod.CurrentRetentionPeriod: The retention period of the cluster in days at the start of the automation.
  * ModifyRetentionPeriod.Response: The response of the API call to modify the retention period of the cluster.
assumeRole: '{{AutomationAssumeRole}}'
parameters:
  AutomationAssumeRole:
    type: 'String'
    description: '(Required) The ARN of the role that allows Automation to perform the actions on your behalf.'
    allowedPattern:  '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  ClusterIdentifier:
    type: 'String'
    description: '(Required) The unique identifier of the cluster.'
    allowedPattern: '^(?!.*--)[a-z][a-z0-9-]{0,62}(?<!-)$'
  MinRetentionPeriod:
    type: 'Integer'
    description: (Optional) The minimum retention period for the automatic snapshots in days.
    default: 7
outputs:
- 'QueryRetentionPeriod.CurrentRetentionPeriod'
- 'ModifyRetentionPeriod.Response'
mainSteps:
- name: 'QueryRetentionPeriod'
  action: 'aws:executeAwsApi'
  inputs:
    Service: 'redshift'
    Api: 'DescribeClusters'
    ClusterIdentifier: '{{ClusterIdentifier}}'
  outputs:
  - Name: 'CurrentRetentionPeriod'
    Selector: '$.Clusters[0].AutomatedSnapshotRetentionPeriod'
    Type: Integer
- name: 'ChooseModifyRetentionPeriod'
  action: 'aws:branch'
  inputs:
    Choices:
    - NextStep: 'CastCurrentRetentionPeriodToString'
      Variable: '{{QueryRetentionPeriod.CurrentRetentionPeriod}}'
      NumericGreaterOrEquals: '{{MinRetentionPeriod}}'
    Default: 'ModifyRetentionPeriod'

- name: 'CastCurrentRetentionPeriodToString'
  action: 'aws:executeScript'
  inputs:
    Runtime: 'python3.8'
    Handler: 'event_handler'
    InputPayload:
      RetentionPeriod: '{{QueryRetentionPeriod.CurrentRetentionPeriod}}'
    Script: >
      def event_handler(event, context):
          return str(event['RetentionPeriod'])
  outputs:
  - Name: 'CurrentRetentionPeriodString'
    Selector: '$.Payload'
    Type: 'String'
- name: 'VerifyCurrentRetentionPeriod'
  action: 'aws:assertAwsResourceProperty'
  inputs:
    Service: 'redshift'
    Api: 'DescribeClusters'
    ClusterIdentifier: '{{ClusterIdentifier}}'
    PropertySelector: '$.Clusters[0].AutomatedSnapshotRetentionPeriod'
    DesiredValues:
    - '{{CastCurrentRetentionPeriodToString.CurrentRetentionPeriodString}}'
  isEnd: true

- name: 'ModifyRetentionPeriod'
  action: 'aws:executeAwsApi'
  inputs:
    Service: 'redshift'
    Api: 'ModifyCluster'
    ClusterIdentifier: '{{ClusterIdentifier}}'
    AutomatedSnapshotRetentionPeriod: '{{MinRetentionPeriod}}'
  outputs:
  - Name: 'Response'
    Selector: '$'
    Type: 'StringMap'
- name: 'WaitForClusterAvailability'
  action: 'aws:waitForAwsResourceProperty'
  timeoutSeconds: 600
  inputs:
    Service: 'redshift'
    Api: 'DescribeClusters'
    ClusterIdentifier: '{{ClusterIdentifier}}'
    PropertySelector: '$.Clusters[0].ClusterStatus'
    DesiredValues:
    - 'available'
- name: 'CastRetentionPeriodToString'
  action: 'aws:executeScript'
  inputs:
    Runtime: 'python3.8'
    Handler: 'event_handler'
    InputPayload:
      RetentionPeriod: '{{MinRetentionPeriod}}'
    Script: >
      def event_handler(event, context):
          return str(event['RetentionPeriod'])
  outputs:
  - Name: 'MinRetentionPeriodString'
    Selector: '$.Payload'
    Type: 'String'
- name: 'VerifyModifiedRetentionPeriod'
  action: 'aws:assertAwsResourceProperty'
  inputs:
    Service: 'redshift'
    Api: 'DescribeClusters'
    ClusterIdentifier: '{{ClusterIdentifier}}'
    PropertySelector: '$.Clusters[0].AutomatedSnapshotRetentionPeriod'
    DesiredValues:
    - '{{CastRetentionPeriodToString.MinRetentionPeriodString}}'
  isEnd: true

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-EnableAutomaticSnapshotsOnRedshiftCluster",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARREnableAutomaticVersionUpgradeOnRedshiftCluster": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
# SPDX-License-Identifier: Apache-2.0
---
schemaVersion: '0.3'
description: |
  ### Document name - SHARR-EnableAutomaticVersionUpgradeOnRedshiftCluster

  ## What does this document do?
  The runbook enables automatic version upgrade on a Redshift cluster.

  ## Input Parameters
  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  * ClusterIdentifier: (Required) The unique identifier of the cluster.
  * AllowVersionUpgrade: (Optional) Whether to allow version upgrade on the cluster.

  ## Output Parameters
  * EnableAutomaticVersionUpgrade.Response: The response of the API call to enable automatic version upgrade on the cluster.
assumeRole: '{{AutomationAssumeRole}}'
parameters:
  AutomationAssumeRole:
    type: 'String'
    description: '(Required) The ARN of the role that allows Automation to perform the actions on your behalf.'
    allowedPattern:  '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  ClusterIdentifier:
    type: 'String'
    description: '(Required) The unique identifier of the cluster.'
    allowedPattern: '^(?!.*--)[a-z][a-z0-9-]{0,62}(?<!-)$'
  AllowVersionUpgrade:
    type: 'Boolean'
    description: (Optional) Whether to allow version upgrade on the cluster.
    default: true
outputs:
- 'EnableAutomaticVersionUpgrade.Response'
mainSteps:
- name: 'EnableAutomaticVersionUpgrade'
  action: 'aws:executeAwsApi'
  inputs:
    Service: 'redshift'
    Api: 'ModifyCluster'
    ClusterIdentifier: '{{ClusterIdentifier}}'
    AllowVersionUpgrade: '{{AllowVersionUpgrade}}'
  outputs:
  - Name: 'Response'
    Selector: '$'
    Type: 'StringMap'
- name: 'WaitForClusterAvailability'
  action: 'aws:waitForAwsResourceProperty'
  timeoutSeconds: 600
  inputs:
    Service: 'redshift'
    Api: 'DescribeClusters'
    ClusterIdentifier: '{{ClusterIdentifier}}'
    PropertySelector: '$.Clusters[0].ClusterStatus'
    DesiredValues:
    - 'available'
- name: 'CastAllowVersionUpgradeToString'
  action: 'aws:executeScript'
  inputs:
    Runtime: 'python3.8'
    Handler: 'event_handler'
    InputPayload:
      AllowVersionUpgrade: '{{AllowVersionUpgrade}}'
    Script: >
      def event_handler(event, context):
          return str(event['AllowVersionUpgrade'])
  outputs:
  - Name: 'AllowVersionUpgradeString'
    Selector: '$.Payload'
    Type: 'String'
- name: 'VerifyAutomaticVersionUpgrade'
  action: 'aws:assertAwsResourceProperty'
  inputs:
    Service: 'redshift'
    Api: 'DescribeClusters'
    ClusterIdentifier: '{{ClusterIdentifier}}'
    PropertySelector: '$.Clusters[0].AllowVersionUpgrade'
    DesiredValues:
    - '{{CastAllowVersionUpgradeToString.AllowVersionUpgradeString}}'
  isEnd: true

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-EnableAutomaticVersionUpgradeOnRedshiftCluster",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARREnableCloudTrailEncryption": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "description: |
  ### Document Name - SHARR-EnableCloudTrailEncryption
  ## What does this document do?
  Enables encryption on a CloudTrail using the provided KMS CMK
  
  ## Input Parameters
  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  * KMSKeyArn (from SSM): Arn of the KMS key to be used to encrypt data
  * TrailRegion: region of the CloudTrail to encrypt
  * TrailArn: ARN of the CloudTrail to encrypt

  ## Security Standards / Controls
  * AFSBP v1.0.0:   CloudTrail.2
  * CIS v1.2.0:     2.7
  * PCI:            CloudTrail.1

schemaVersion: \\"0.3\\"
assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  KMSKeyArn:
    type: String
    default: >-
      {{ssm:/Solutions/SO0111/CMK_REMEDIATION_ARN}}
    description: The ARN of the KMS key created by SHARR for this remediation
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):kms:(?:[a-z]{2}(?:-gov)?-[a-z]+-\\\\d):\\\\d{12}:(?:(?:alias/[A-Za-z0-9/-_])|(?:key/(?i:[0-9a-f]{8}-(?:[0-9a-f]{4}-){3}[0-9a-f]{12})))$'
  TrailRegion:
    type: String
    description: 'Region the CloudTrail is in'
    allowedPattern: '^[a-z]{2}(?:-gov)?-[a-z]+-\\\\d$'
  TrailArn:
    type: String
    description: 'ARN of the CloudTrail'
    allowedPattern: '^arn:(?:aws|aws-cn|aws-us-gov):cloudtrail:(?:[a-z]{2}(?:-gov)?-[a-z]+-\\\\d):\\\\d{12}:trail/[A-Za-z0-9._-]{3,128}$'
outputs:
  - Remediation.Output

mainSteps:
  - 
    name: Remediation
    action: 'aws:executeScript'
    outputs:
      - Name: Output
        Selector: $.Payload.response
        Type: StringMap
    inputs:
      InputPayload: 
        exec_region: '{{global:REGION}}'
        trail_region: '{{TrailRegion}}'
        trail: '{{TrailArn}}'
        region: '{{global:REGION}}'
        kms_key_arn: '{{KMSKeyArn}}'        
      Runtime: python3.8
      Handler: enable_trail_encryption
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.    #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0/                                        #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    #
        #  sions and limitations under the License.                                   #
        ###############################################################################
        
        import boto3
        from botocore.config import Config
        from botocore.exceptions import ClientError
        
        def connect_to_cloudtrail(region, boto_config):
            return boto3.client('cloudtrail', region_name=region, config=boto_config)
        
        def enable_trail_encryption(event, context):
            \\"\\"\\"
            remediates CloudTrail.2 by enabling SSE-KMS
            On success returns a string map
            On failure returns NoneType
            \\"\\"\\"
            boto_config = Config(
                retries ={
                  'mode': 'standard'
                }
            )
          
            if event['trail_region'] != event['exec_region']:
                exit('ERROR: cross-region remediation is not yet supported')
        
            ctrail_client = connect_to_cloudtrail(event['trail_region'], boto_config)
            kms_key_arn = event['kms_key_arn'] 
        
            try:
                ctrail_client.update_trail(
                    Name=event['trail'],
                    KmsKeyId=kms_key_arn
                )
                return {
                    \\"response\\": {
                        \\"message\\": f'Enabled KMS CMK encryption on {event[\\"trail\\"]}',
                        \\"status\\": \\"Success\\"
                    }
                }
            except Exception as e:
                exit(f'Error enabling SSE-KMS encryption: {str(e)}')
        

    isEnd: true

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-EnableCloudTrailEncryption",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARREnableCloudTrailLogFileValidation": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "schemaVersion: \\"0.3\\"
description: |
  ### Document name - AWSConfigRemediation-EnableCloudTrailLogFileValidation

  ## What does this document do?
  This runbook enables log file validation for your AWS CloudTrail trail using the [UpdateTrail](https://docs.aws.amazon.com/awscloudtrail/latest/APIReference/API_UpdateTrail.html) API.

  ## Input Parameters
  * AutomationAssumeRole: (Required) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf.
  * TrailName: (Required) The name or Amazon Resource Name (ARN) of the trail you want to enable log file validation for.

  ## Output Parameters
  * UpdateTrail.Output: The response of the UpdateTrail API call.

  ## Note: this is a local copy of the AWS-owned document to enable support in aws-cn and aws-us-gov partitions.

assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  TrailName:
    type: String
    description: (Required) The name or Amazon Resource Name (ARN) of the trail you want to enable log file validation for.
    allowedPattern: (^arn:(aws[a-zA-Z-]*)?:cloudtrail:[a-z0-9-]+:\\\\d{12}:trail\\\\/(?![-_.])(?!.*[-_.]{2})(?!.*[-_.]$)(?!^\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}$)[-\\\\w.]{3,128}$)|(^(?![-_.])(?!.*[-_.]{2})(?!.*[-_.]$)(?!^\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}$)[-\\\\w.]{3,128}$)
outputs:
  - UpdateTrail.Output
mainSteps:
  - name: UpdateTrail
    action: aws:executeAwsApi
    description: |
      ## UpdateTrail
      Enables log file validation for the AWS CloudTrail trail you specify in the TrailName parameter.
      ## Outputs
      * Output: Response from the UpdateTrail API call.
    timeoutSeconds: 600
    isEnd: false
    inputs:
      Service: cloudtrail
      Api: UpdateTrail
      Name: \\"{{ TrailName }}\\"
      EnableLogFileValidation: True
    outputs:
      - Name: Output
        Selector: $
        Type: StringMap
  - name: VerifyTrail
    action: aws:assertAwsResourceProperty
    description: |
      ## VerifyTrail
      Verifies log file validation is enabled for your trail.
    timeoutSeconds: 600
    isEnd: true
    inputs:
      Service: cloudtrail
      Api: GetTrail
      Name: \\"{{ TrailName }}\\"
      PropertySelector: $.Trail.LogFileValidationEnabled
      DesiredValues:
        - \\"True\\"

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-EnableCloudTrailLogFileValidation",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARREnableCloudTrailToCloudWatchLogging": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "description: |
  ### Document Name - SHARR-EnableCloudTrailToCloudWatchLogging
  ## What does this document do?
  Creates a CloudWatch logs group for CloudTrail data.
  
  ## Input Parameters
  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  * KMSKeyArn (from SSM): Arn of the KMS key to be used to encrypt data

  ## Security Standards / Controls
  * AFSBP v1.0.0:   N/A
  * CIS v1.2.0:     2.4
  * PCI:            CloudTrail.4

schemaVersion: \\"0.3\\"
assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  TrailName:
    type: String
    description: (Required) The name of the CloudTrail.
    allowedPattern: '^[A-Za-z0-9._-]{3,128}$'
  CloudWatchLogsRole:
    type: String
    description: (Required) The ARN of the role that allows CloudTrail to log to CloudWatch.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$' 
  LogGroupName:
    type: String
    description: (Required) The name of the Log Group for CloudTrail logs.
    allowedPattern: '^[a-zA-Z0-9-_./]{1,512}$'
outputs:
  - UpdateTrailToCWLogs.Output

mainSteps:
  - 
    name: CreateLogGroup
    action: 'aws:executeAwsApi'
    inputs:
      Service: logs
      Api: CreateLogGroup
      logGroupName: '{{LogGroupName}}'
    description: Create the log group
    outputs:
      - Name: Output
        Selector: $
        Type: StringMap
  - 
    name: WaitForCreation
    action: 'aws:executeScript'
    inputs:
      InputPayload:       
        LogGroup: '{{LogGroupName}}'
      Runtime: python3.8
      Handler: wait_for_loggroup
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.    #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0/                                        #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    #
        #  sions and limitations under the License.                                   #
        ###############################################################################
        
        import boto3
        from botocore.config import Config
        import time
        
        def connect_to_logs(boto_config):
            return boto3.client('logs', config=boto_config)
        
        def wait_for_loggroup(event, context):
            boto_config = Config(
                retries ={
                  'mode': 'standard'
                }
            )
            cwl_client = connect_to_logs(boto_config)
        
            max_retries = 3
            attempts = 0
            while attempts < max_retries:
                try:
                    describe_group = cwl_client.describe_log_groups(logGroupNamePrefix=event['LogGroup'])
                    print(len(describe_group['logGroups']))
                    for group in describe_group['logGroups']:
                        if group['logGroupName'] == event['LogGroup']:
                            return str(group['arn'])
                    # no match - wait and retry
                    time.sleep(2)
                    attempts += 1
        
                except Exception as e:
                    exit(f'Failed to create Log Group {event[\\"LogGroup\\"]}: {str(e)}')
        
            exit(f'Failed to create Log Group {event[\\"LogGroup\\"]}: Timed out')
        
        
    outputs:
      - Name: CloudWatchLogsGroupArn
        Selector: $.Payload
        Type: String

    isEnd: false

  - 
    name: UpdateTrailToCWLogs
    action: 'aws:executeAwsApi'
    inputs:
      Service: cloudtrail
      Api: UpdateTrail
      Name: '{{TrailName}}'
      CloudWatchLogsLogGroupArn: '{{WaitForCreation.CloudWatchLogsGroupArn}}'
      CloudWatchLogsRoleArn: '{{CloudWatchLogsRole}}'
    description: Enable logging to CloudWatch Logs
    outputs:
      - Name: Output
        Selector: $
        Type: StringMap
  
",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-EnableCloudTrailToCloudWatchLogging",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARREnableCopyTagsToSnapshotOnRDSCluster": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "schemaVersion: \\"0.3\\"
description: |
  ### Document name - AWSConfigRemediation-EnableCopyTagsToSnapshotOnRDSCluster

  ## What does this document do?
  The document enables CopyTagsToSnapshot on an Amazon RDS cluster using the [ModifyDBCluster API](https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_ModifyDBCluster.html).  Please note, AWS Config is required to be enabled in this region for this document to work as it requires the Resource ID recorded by the AWS Config service.

  ## Input Parameters
  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  * DbClusterResourceId: (Required) Resource ID of the Amazon RDS Cluster for which CopyTagsToSnapshot needs to be enabled.
  * ApplyImmediately: (Optional) A value that indicates whether the modifications in this request and any pending modifications are asynchronously applied as soon as possible, regardless of the PreferredMaintenanceWindow setting for the DB instance. By default, this parameter is disabled.
    * Default: false

  ## Output Parameters
  * ModifyDBClusterResponse.Output: The response of the ModifyDBCluster API call.

assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  DbClusterResourceId:
    type: String
    description: (Required) Resource ID of the Amazon RDS Cluster for which CopyTagsToSnapshot needs to be enabled.
    allowedPattern: '^cluster-[A-Z0-9]+$'
  ApplyImmediately:
    type: Boolean
    description: (Optional) A value that indicates whether the modifications in this request and any pending modifications are asynchronously applied as soon as possible, regardless of the PreferredMaintenanceWindow setting for the DB instance.  By default, this parameter is disabled.
    default: false

outputs:
  - EnableCopyTagsToSnapshot.Output
mainSteps:
- name: GetDBClusterIdentifier
  action: aws:executeAwsApi
  description: |
    ## GetDBClusterIdentifier
    Accepts the Resource ID as input and returns the DB cluster identifier.
    ## Outputs
    * DBClusterIdentifier: The ID of the DB cluster.
  timeoutSeconds: 600
  isEnd: false
  inputs:
    Service: config
    Api: GetResourceConfigHistory
    resourceId: \\"{{ DbClusterResourceId }}\\"
    resourceType: AWS::RDS::DBCluster
  outputs:
    - Name: DBClusterIdentifier
      Selector: $.configurationItems[0].resourceName
      Type: String
- name: VerifyStatus
  action: aws:assertAwsResourceProperty
  description: |
    ## VerifyStatus
    Verifies if \`Status\` is available before proeeding to the next step.
  timeoutSeconds: 600
  isEnd: false
  inputs:
    Service: rds
    Api: DescribeDBClusters
    DBClusterIdentifier: \\"{{ GetDBClusterIdentifier.DBClusterIdentifier }}\\"
    PropertySelector: $.DBClusters[0].Status
    DesiredValues:
      - \\"available\\"
- name: EnableCopyTagsToSnapshot
  action: aws:executeAwsApi
  description: |
    ## EnableCopyTagsToSnapshot
    Accepts the cluster name as input and modifies it to set true for \`CopyTagsToSnapshot\`.
    ## Outputs
    * Output: Response from the ModifyDBCluster API call.
  timeoutSeconds: 600
  isEnd: false
  inputs:
    Service: rds
    Api: ModifyDBCluster
    DBClusterIdentifier: \\"{{ GetDBClusterIdentifier.DBClusterIdentifier }}\\"
    ApplyImmediately: \\"{{ ApplyImmediately }}\\"
    CopyTagsToSnapshot: True
  outputs:
    - Name: Output
      Selector: $
      Type: StringMap
- name: VerifyDBClusterCopyTagsToSnapshotEnabled
  action: aws:assertAwsResourceProperty
  description: |
    ## VerifyDBClusterCopyTagsToSnapshotEnabled
    Verifies that \`CopyTagsToSnapshot\` has been enabled on the target resource.
    ## Outputs
    * Output: A success message or failure exception.
  timeoutSeconds: 600
  isEnd: true
  inputs:
    Service: rds
    Api: DescribeDBClusters
    DBClusterIdentifier: \\"{{ GetDBClusterIdentifier.DBClusterIdentifier }}\\"
    PropertySelector: $.DBClusters[0].CopyTagsToSnapshot
    DesiredValues:
      - \\"True\\"
",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-EnableCopyTagsToSnapshotOnRDSCluster",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARREnableDefaultEncryptionS3": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "description: |
  ### Document name - SHARR-EnableDefaultEncryptionS3

  ## What does this document do?
  This document configures default encryption for an Amazon S3 Bucket.

  ## Input Parameters
  * AutomationAssumeRole: (Required) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf.
  * BucketName: (Required) Name of the bucket to modify.
  * AccountId: (Required) Account to which the bucket belongs

  ## Output Parameters

  * Remediation.Output - stdout messages from the remediation

  ## Security Standards / Controls
  * AFSBP v1.0.0: S3.4
  * CIS v1.2.0:   n/a
  * PCI:          S3.4

schemaVersion: \\"0.3\\"
assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AccountId:
    type: String
    description: Account ID of the account for the finding
    allowedPattern: ^[0-9]{12}$
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  BucketName:
    type: String
    description: Name of the bucket to have a policy added
    allowedPattern: (?=^.{3,63}$)(?!^(\\\\d+\\\\.)+\\\\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\\\\-]*[a-z0-9])\\\\.)*([a-z0-9]|[a-z0-9][a-z0-9\\\\-]*[a-z0-9])$)
  KmsKeyAlias:
    type: String
    description: (Required) KMS Customer-Managed Key (CMK) alias or the default value which is created in the SSM parameter at solution deployment (default-s3-encryption) is used to identify that the s3 bucket encryption value should be set to AES-256.
    default: 'default-s3-encryption'
    allowedPattern: '^$|^[a-zA-Z0-9/_-]{1,256}$'

mainSteps:
  - name: ChooseEncryptionMethod
    action: aws:branch
    inputs:
      Choices:
      - NextStep: EncryptWithAES
        Variable: '{{KmsKeyAlias}}'
        StringEquals: 'default-s3-encryption'
      Default:
        EncryptWithCMK

  - name: EncryptWithAES
    action: aws:executeAwsApi
    inputs:
      Service: s3
      Api: PutBucketEncryption
      Bucket: '{{BucketName}}'
      ExpectedBucketOwner: '{{AccountId}}'
      ServerSideEncryptionConfiguration:
        Rules:
        - ApplyServerSideEncryptionByDefault:
            SSEAlgorithm: 'AES256'
          BucketKeyEnabled: true
    isEnd: true

  - name: EncryptWithCMK
    action: aws:executeAwsApi
    inputs:
      Service: s3
      Api: PutBucketEncryption
      Bucket: '{{BucketName}}'
      ExpectedBucketOwner: '{{AccountId}}'
      ServerSideEncryptionConfiguration:
        Rules:
        - ApplyServerSideEncryptionByDefault:
            SSEAlgorithm: 'aws:kms'
            KMSMasterKeyID: '{{KmsKeyAlias}}'
          BucketKeyEnabled: true
    isEnd: true

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-EnableDefaultEncryptionS3",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARREnableEbsEncryptionByDefault": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "schemaVersion: \\"0.3\\"
description: |
   ### Document Name - AWSConfigRemediation-EnableEbsEncryptionByDefault

   ## What does this document do?
   This document enables EBS encryption by default for an AWS account in the current region using the [EnableEbsEncryptionByDefault](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_EnableEbsEncryptionByDefault.html) API.

   ## Input Parameters
   * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.

   ## Output Parameters
   * ModifyAccount.EnableEbsEncryptionByDefaultResponse: JSON formatted response from the EnableEbsEncryptionByDefault API.

assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
outputs:
  - ModifyAccount.EnableEbsEncryptionByDefaultResponse
mainSteps:
  -
    name: ModifyAccount
    action: \\"aws:executeAwsApi\\"
    description: |
      ## ModifyAccount
      Enables EBS encryption by default for the account in the current region.
      ## Outputs
      * EnableEbsEncryptionByDefaultResponse: Response from the EnableEbsEncryptionByDefault API.
    timeoutSeconds: 600
    isEnd: false
    inputs:
      Service: ec2
      Api: EnableEbsEncryptionByDefault
    outputs:
      - Name: EnableEbsEncryptionByDefaultResponse
        Selector: $
        Type: StringMap
  -
    name: VerifyEbsEncryptionByDefault
    action: \\"aws:assertAwsResourceProperty\\"
    timeoutSeconds: 600
    isEnd: true
    description: |
      ## VerifyEbsEncryptionByDefault
      Checks if EbsEncryptionByDefault is enabled correctly from the previous step.
    inputs:
      Service: ec2
      Api: GetEbsEncryptionByDefault
      PropertySelector: \\"$.EbsEncryptionByDefault\\"
      DesiredValues:
        - \\"True\\"

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-EnableEbsEncryptionByDefault",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARREnableEnhancedMonitoringOnRDSInstance": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "schemaVersion: \\"0.3\\"
description: |
   ### Document Name - AWSConfigRemediation-EnableEnhancedMonitoringOnRDSInstance

   ## What does this document do?
   This document is used to enable enhanced monitoring on an RDS Instance using the input parameter DB Instance resourceId.

   ## Input Parameters
   * ResourceId: (Required) Resource ID of the RDS DB Instance.
   * MonitoringInterval: (Optional)
      * The interval, in seconds, between points when Enhanced Monitoring metrics are collected for the DB instance.
      * If MonitoringRoleArn is specified, then you must also set MonitoringInterval to a value other than 0.
      * Valid Values: 1, 5, 10, 15, 30, 60
      * Default: 60
   * MonitoringRoleArn: (Required) The ARN for the IAM role that permits RDS to send enhanced monitoring metrics to Amazon CloudWatch Logs.
   * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.

   ## Output Parameters
   * EnableEnhancedMonitoring.DbInstance - The standard HTTP response from the ModifyDBInstance API.

assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  ResourceId:
    type: String
    description: (Required) Resource ID of the Amazon RDS instance for which Enhanced Monitoring needs to be enabled.
    allowedPattern: \\"db-[A-Z0-9]{26}\\"
  MonitoringInterval:
    type: Integer
    description: (Optional) The interval, in seconds, between points when Enhanced Monitoring metrics are collected for the DB instance.
    default: 60
    allowedValues:
      - 1
      - 5
      - 10
      - 15
      - 30
      - 60
  MonitoringRoleArn:
    type: String
    description: (Required) The ARN for the IAM role that permits RDS to send enhanced monitoring metrics to Amazon CloudWatch Logs.
    allowedPattern: ^arn:(aws[a-zA-Z-]*)?:iam::\\\\d{12}:role/[a-zA-Z0-9+=,.@_/-]+$
outputs:
  - EnableEnhancedMonitoring.DbInstance
mainSteps:
  -
    name: DescribeDBInstances
    action: \\"aws:executeAwsApi\\"
    description: |
      ## DescribeDBInstances
        Makes describeDBInstances API call using RDS Instance DbiResourceId to get DBInstanceId.
      ## Outputs
      * DbInstanceIdentifier: DBInstance Identifier of the RDS Instance.
    timeoutSeconds: 600
    isEnd: false
    inputs:
      Service: rds
      Api: DescribeDBInstances
      Filters:
        - Name: \\"dbi-resource-id\\"
          Values:
            - \\"{{ ResourceId }}\\"
    outputs:
      - Name: DbInstanceIdentifier
        Selector: $.DBInstances[0].DBInstanceIdentifier
        Type: String
  -
    name: VerifyDBInstanceStatus
    action: \\"aws:assertAwsResourceProperty\\"
    timeoutSeconds: 600
    isEnd: false
    description: |
      ## VerifyDBInstanceStatus
      Verifies if DB Instance status is available before enabling enhanced monitoring.
    inputs:
      Service: rds
      Api: DescribeDBInstances
      DBInstanceIdentifier: \\"{{ DescribeDBInstances.DbInstanceIdentifier }}\\"
      PropertySelector: \\"$.DBInstances[0].DBInstanceStatus\\"
      DesiredValues:
        - \\"available\\"
  -
    name: EnableEnhancedMonitoring
    action: \\"aws:executeAwsApi\\"
    description: |
      ## EnableEnhancedMonitoring
        Makes ModifyDBInstance API call to enable Enhanced Monitoring on the RDS Instance
        using the DBInstanceId from the previous action.
      ## Outputs
        * DbInstance: The standard HTTP response from the ModifyDBInstance API.
    timeoutSeconds: 600
    isEnd: false
    inputs:
       Service: rds
       Api: ModifyDBInstance
       ApplyImmediately: False
       DBInstanceIdentifier: \\"{{ DescribeDBInstances.DbInstanceIdentifier }}\\"
       MonitoringInterval: \\"{{ MonitoringInterval }}\\"
       MonitoringRoleArn: \\"{{ MonitoringRoleArn }}\\"
    outputs:
      - Name: DbInstance
        Selector: $
        Type: StringMap
  -
    name: VerifyEnhancedMonitoringEnabled
    action: \\"aws:executeScript\\"
    description: |
      ## VerifyEnhancedMonitoringEnabled
      Checks that the enhanced monitoring is enabled on RDS Instance in the previous step exists.
      ## Outputs
      * Output: The standard HTTP response from the ModifyDBInstance API.
    isEnd: true
    timeoutSeconds: 600
    inputs:
      Runtime: python3.8
      Handler: handler
      InputPayload:
        MonitoringInterval: \\"{{ MonitoringInterval }}\\"
        DBIdentifier: \\"{{ DescribeDBInstances.DbInstanceIdentifier }}\\"
      Script: |-
        import boto3
        import time

        def handler(event, context):
            rds_client = boto3.client(\\"rds\\")
            db_instance_id = event[\\"DBIdentifier\\"]
            monitoring_interval = event[\\"MonitoringInterval\\"]

            try:
                rds_waiter = rds_client.get_waiter(\\"db_instance_available\\")
                rds_waiter.wait(DBInstanceIdentifier=db_instance_id)

                db_instances = rds_client.describe_db_instances(
                    DBInstanceIdentifier=db_instance_id)

                for db_instance in db_instances.get(\\"DBInstances\\", [{}]):
                    db_monitoring_interval = db_instance.get(\\"MonitoringInterval\\")

                if db_monitoring_interval == monitoring_interval:
                    return {
                              \\"output\\": db_instances[\\"ResponseMetadata\\"]
                            }
                else:
                    info = \\"VERIFICATION FAILED. RDS INSTANCE MONITORING INTERVAL {} IS NOT ENABLED WITH THE REQUIRED VALUE {}\\".format(
                            db_monitoring_interval, monitoring_interval)
                    raise Exception(info)
            except Exception as e:
                raise e
    outputs:
      - Name: Output
        Selector: $.Payload.output
        Type: StringMap

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-EnableEnhancedMonitoringOnRDSInstance",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARREnableKeyRotation": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "schemaVersion: \\"0.3\\"
description: |
  ### Document name - AWSConfigRemediation-EnableKeyRotation

  ## What does this document do?
  This document enables automatic key rotation for the given AWS Key Management Service (KMS) symmetric customer master key(CMK) using [EnableKeyRotation](https://docs.aws.amazon.com/kms/latest/APIReference/API_EnableKeyRotation.html) API.

  ## Input Parameters
  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  * KeyId: (Required) The Key ID of the AWS KMS symmetric CMK.

  ## Output Parameters
  * EnableKeyRotation.EnableKeyRotationResponse: The standard HTTP response from the EnableKeyRotation API.

assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  KeyId:
    type: String
    description: (Required) The Key ID of the AWS KMS symmetric CMK.
    allowedPattern: \\"[a-z0-9-]{1,2048}\\"

outputs:
  - EnableKeyRotation.EnableKeyRotationResponse
mainSteps:
  -
    name: EnableKeyRotation
    action: aws:executeAwsApi
    description: |
      ## EnableKeyRotation
      Enables automatic key rotation for the given AWS KMS CMK.
      ## Outputs
      * EnableKeyRotationResponse: The standard HTTP response from the EnableKeyRotation API.
    timeoutSeconds: 600
    isEnd: false
    inputs:
      Service: kms
      Api: EnableKeyRotation
      KeyId: \\"{{ KeyId }}\\"
    outputs:
      - Name: EnableKeyRotationResponse
        Selector: $
        Type: StringMap
  -
    name: VerifyKeyRotation
    action: \\"aws:assertAwsResourceProperty\\"
    timeoutSeconds: 600
    isEnd: true
    description: |
      ## VerifyKeyRotation
      Verifies that the KeyRotationEnabled is set to true for the given AWS KMS CMK.
    inputs:
      Service: kms
      Api: GetKeyRotationStatus
      KeyId: \\"{{ KeyId }}\\"
      PropertySelector: $.KeyRotationEnabled
      DesiredValues:
        - \\"True\\"
",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-EnableKeyRotation",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARREnableMinorVersionUpgradeOnRDSDBInstance": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "
schemaVersion: \\"0.3\\"
description: |
  ### Document name - AWSConfigRemediation-EnableMinorVersionUpgradeOnRDSDBInstance

  ## What does this document do?
  This document enables AutoMinorVersionUpgrade on the Amazon Relational Database Service (Amazon RDS) instance using the [ModifyDBInstance](https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_ModifyDBInstance.html) API.

  ## Input parameters
  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  * DbiResourceId: (Required) Resource ID of the Amazon RDS instance to be modified.

  ## Output parameters
  * ModifyDBInstance.Output: The standard HTTP response from the ModifyDBInstance API.
assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  DbiResourceId:
    type: String
    description: (Required) Resource ID of the Amazon RDS instance for which AutoMinorVersionUpgrade needs to be enabled.
    allowedPattern: \\"^db-[A-Z0-9]{26}$\\"
outputs:
  - ModifyDBInstance.Output
mainSteps:
  - name: GetRDSInstanceIdentifier
    action: \\"aws:executeAwsApi\\"
    description: |
      ## GetRDSInstanceIdentifier
      Makes DescribeDBInstances API call using the database instance resource identifier to get DBInstanceIdentifier.
      ## Outputs
      * DBInstanceIdentifier: DBInstance identifier of the Amazon RDS instance.
    timeoutSeconds: 600
    isEnd: false
    inputs:
      Service: rds
      Api: DescribeDBInstances
      Filters:
        - Name: dbi-resource-id
          Values:
            - \\"{{ DbiResourceId }}\\"
    outputs:
      - Name: DBInstanceIdentifier
        Selector: \\"$.DBInstances[0].DBInstanceIdentifier\\"
        Type: String
  - name: VerifyDBInstanceStatus
    action: \\"aws:assertAwsResourceProperty\\"
    timeoutSeconds: 600
    isEnd: false
    description: |
      ## VerifyDBInstanceStatus
      Verifies whether AWS RDS DBInstance status is available before enabling AutoMiniorVersionUpgrade.
    inputs:
      Service: rds
      Api: DescribeDBInstances
      DBInstanceIdentifier: \\"{{ GetRDSInstanceIdentifier.DBInstanceIdentifier }}\\"
      PropertySelector: \\"$.DBInstances[0].DBInstanceStatus\\"
      DesiredValues:
        - \\"available\\"
  - name: ModifyDBInstance
    action: \\"aws:executeAwsApi\\"
    description: |
      ## ModifyDBInstance
      Makes ModifyDBInstance API call to enable AutoMinorVersionUpgrade on the Amazon RDS instance using the DBInstanceIdentifier.
      ## Outputs
      * Output: The standard HTTP response from the ModifyDBInstance API.
    timeoutSeconds: 600
    isEnd: false
    inputs:
      Service: rds
      Api: ModifyDBInstance
      DBInstanceIdentifier: \\"{{ GetRDSInstanceIdentifier.DBInstanceIdentifier }}\\"
      AutoMinorVersionUpgrade: true
    outputs:
      - Name: Output
        Selector: $
        Type: StringMap
  - name: VerifyDBInstanceState
    action: \\"aws:assertAwsResourceProperty\\"
    timeoutSeconds: 600
    isEnd: true
    description: |
      ## VerifyDBInstanceState
      Verifies the Amazon RDS Instance's \\"AutoMinorVersionUpgrade\\" property is set to \\"True\\".
    inputs:
      Service: rds
      Api: DescribeDBInstances
      DBInstanceIdentifier: \\"{{ GetRDSInstanceIdentifier.DBInstanceIdentifier }}\\"
      PropertySelector: \\"$.DBInstances[0].AutoMinorVersionUpgrade\\"
      DesiredValues:
        - \\"True\\"
",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-EnableMinorVersionUpgradeOnRDSDBInstance",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARREnableMultiAZOnRDSInstance": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "schemaVersion: \\"0.3\\"
description: |
   ### Document name - SHARR-EnableMultiAZOnRDSInstance

   ## What does this document do?
   This document enables MultiAZ on an RDS instance.

   ## Input Parameters
   * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
   * DbiResourceId: (Required) Resource ID of the RDS instance to be modified.
   * ApplyImmediately: (Optional) The MultiAZ on an RDS instance change is applied during the next maintenance window unless the ApplyImmediately parameter is enabled (true) for this request. By default, this parameter is disabled (false).

   ## Output Parameters
   * EnableMultiAZ.DBInstance: The standard HTTP response from the ModifyDBInstance API.

assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  DbiResourceId:
    type: String
    description: (Required) Resource ID of the RDS instance for which MultiAZ needs to be enabled.
    allowedPattern: ^db-[A-Z0-9]{26}$
  ApplyImmediately:
    type: Boolean
    description: (Optional) MultiAZ on an RDS instance change is applied during the next maintenance window unless the ApplyImmediately parameter is enabled (true) for this request. By default, this parameter is disabled (false).
    default: False
    allowedValues:
      - True
      - False

outputs:
  - EnableMultiAZ.DBInstance
mainSteps:
  -
    name: DescribeDBInstances
    action: \\"aws:executeAwsApi\\"
    description: |
      ## DescribeDBInstances
      Makes DescribeDBInstances API call using RDS DB instance resource identifiers to get DBInstanceIdentifier.
      ## Outputs
      * DBInstanceIdentifier: DBInstance identifier of the RDS instance.
      * MultiAZ: MultiAZ state of the RDS instance.
    timeoutSeconds: 600
    isEnd: false
    inputs:
      Service: rds
      Api: DescribeDBInstances
      Filters:
        - Name: \\"dbi-resource-id\\"
          Values:
            - \\"{{ DbiResourceId }}\\"
    outputs:
      - Name: DBInstanceIdentifier
        Selector: $.DBInstances[0].DBInstanceIdentifier
        Type: String
      - Name: MultiAZ
        Selector: $.DBInstances[0].MultiAZ
        Type: Boolean

  -
    name: VerifyDBInstanceStatus
    action: \\"aws:assertAwsResourceProperty\\"
    timeoutSeconds: 600
    isEnd: false
    description: |
      ## VerifyDBInstanceStatus
      Verifies if DB instance status is available before enabling MultiAZ.
    inputs:
      Service: rds
      Api: DescribeDBInstances
      DBInstanceIdentifier: \\"{{ DescribeDBInstances.DBInstanceIdentifier }}\\"
      PropertySelector: \\"$.DBInstances[0].DBInstanceStatus\\"
      DesiredValues:
        - \\"available\\"

  -
    name: EndIfMultiAZAlreadyEnabled
    action: aws:branch
    description: |
      ## EndIfMultiAZAlreadyEnabled
      Checks if MultiAZ is not enabled on the DB instance. If not enabled, proceed with EnableMultiAZ step. Otherwise, end the flow.
    inputs:
      Choices:
      - NextStep: EnableMultiAZ
        Variable: \\"{{ DescribeDBInstances.MultiAZ }}\\"
        BooleanEquals: false
    isEnd: true

  -
    name: EnableMultiAZ
    action: \\"aws:executeAwsApi\\"
    description: |
      ## EnableMultiAZ
      Makes ModifyDBInstance API call to enable MultiAZ on the RDS instance using the DBInstanceIdentifier from the previous step and MultiAZ as true.
      ## Outputs
      * DBInstance: The standard HTTP response from the ModifyDBInstance API.
    timeoutSeconds: 600
    isEnd: false
    inputs:
      Service: rds
      Api: ModifyDBInstance
      DBInstanceIdentifier: \\"{{ DescribeDBInstances.DBInstanceIdentifier }}\\"
      MultiAZ: True
      ApplyImmediately: \\"{{ ApplyImmediately }}\\"
    outputs:
      - Name: DBInstance
        Selector: $
        Type: StringMap

  -
    name: VerifyMultiAZEnabled
    action: \\"aws:assertAwsResourceProperty\\"
    timeoutSeconds: 600
    isEnd: true
    description: |
      ## VerifyMultiAZEnabled
      Verifies that the RDS Instance's \`PendingModifiedValues.MultiAZ\` value is \`True\`.
    inputs:
      Service: rds
      Api: DescribeDBInstances
      DBInstanceIdentifier: \\"{{ DescribeDBInstances.DBInstanceIdentifier }}\\"
      PropertySelector: \\"$.DBInstances[0].PendingModifiedValues.MultiAZ\\"
      DesiredValues:
        - \\"True\\"

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-EnableMultiAZOnRDSInstance",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARREnableRDSClusterDeletionProtection": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "schemaVersion: \\"0.3\\"
description: |
   ### Document name - AWSConfigRemediation-EnableRDSClusterDeletionProtection

   ## What does this document do?
   This document enables \`Deletion Protection\` on a given Amazon RDS cluster using the [ModifyDBCluster](https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_ModifyDBCluster.html) API.
   Please note, AWS Config is required to be enabled in this region for this document to work as it requires the resource ID recorded by the AWS Config service.

   ## Input Parameters
   * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
   * ClusterId: (Required) Resource ID of the Amazon RDS cluster.

   ## Output Parameters
   * EnableRDSClusterDeletionProtection.ModifyDBClusterResponse: The standard HTTP response from the ModifyDBCluster API.

assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  ClusterId:
    type: String
    description: (Required) Amazon RDS cluster resourceId for which deletion protection needs to be enabled.
    allowedPattern: ^[a-zA-Z0-9-]{1,35}$

outputs:
  - EnableRDSClusterDeletionProtection.ModifyDBClusterResponse
mainSteps:
  -
    name: GetRDSClusterIdentifer
    action: \\"aws:executeAwsApi\\"
    description: |
      ## GetRDSClusterIdentifer
      Accepts the resource ID of the Amazon RDS Cluster as input and returns the cluster name.
      ## Outputs
      * DbClusterIdentifier: The ID of the DB cluster for which the input parameter matches DbClusterResourceId element from the output of the DescribeDBClusters API call.
    timeoutSeconds: 600
    isEnd: false
    inputs:
      Service: config
      Api: GetResourceConfigHistory
      resourceId: \\"{{ ClusterId }}\\"
      resourceType: \\"AWS::RDS::DBCluster\\"
      limit: 1
    outputs:
      - Name: DbClusterIdentifier
        Selector: $.configurationItems[0].resourceName
        Type: String
  -
    name: VerifyDBClusterStatus
    action: \\"aws:assertAwsResourceProperty\\"
    timeoutSeconds: 600
    isEnd: false
    description: |
      ## VerifyDBClusterStatus
      Verifies if the DB Cluster status is available before enabling cluster deletion protection.
    inputs:
      Service: rds
      Api: DescribeDBClusters
      DBClusterIdentifier: \\"{{ GetRDSClusterIdentifer.DbClusterIdentifier }}\\"
      PropertySelector: \\"$.DBClusters[0].Status\\"
      DesiredValues:
        - \\"available\\"
  -
    name: EnableRDSClusterDeletionProtection
    action: \\"aws:executeAwsApi\\"
    description: |
      ## EnableRDSClusterDeletionProtection
      Enables deletion protection on the Amazon RDS Cluster.
      ## Outputs
      * ModifyDBClusterResponse: The standard HTTP response from the ModifyDBCluster API.
    timeoutSeconds: 600
    isEnd: false
    inputs:
       Service: rds
       Api: ModifyDBCluster
       DBClusterIdentifier: \\"{{ GetRDSClusterIdentifer.DbClusterIdentifier }}\\"
       DeletionProtection: True
    outputs:
      - Name: ModifyDBClusterResponse
        Selector: $
        Type: StringMap
  -
    name: VerifyDBClusterModification
    action: \\"aws:assertAwsResourceProperty\\"
    description: |
      ## VerifyDBClusterModification
      Verifies that deletion protection has been enabled for the given Amazon RDS database cluster.
    timeoutSeconds: 600
    isEnd: true
    inputs:
       Service: rds
       Api: DescribeDBClusters
       DBClusterIdentifier: \\"{{ GetRDSClusterIdentifer.DbClusterIdentifier }}\\"
       PropertySelector: \\"$.DBClusters[0].DeletionProtection\\"
       DesiredValues:
         - \\"True\\"

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-EnableRDSClusterDeletionProtection",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARREnableRDSInstanceDeletionProtection": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "schemaVersion: \\"0.3\\"
description: |
  ### Document Name - SHARR-EnableRDSInstanceDeletionProtection

  ## What does this document do?
  This document enables \`Deletion Protection\` on a given Amazon RDS instance using the [ModifyDBInstance](https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_ModifyDBInstance.html) API.

  ## Input Parameters
  * ApplyImmediately: (Optional) A value that indicates whether the modifications in this request and any pending modifications
    are asynchronously applied as soon as possible, regardless of the PreferredMaintenanceWindow setting for the DB instance.
    * Default: \\"false\\"
  * DbInstanceResourceId: (Required) Amazon RDS Instance resourceId for which deletion protection needs to be enabled.
  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.

  ## Output Parameters
  * EnableRDSInstanceDeletionProtection.ModifyDBInstanceResponse - The standard HTTP response from the ModifyDBInstance API.

assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  ApplyImmediately:
    type: Boolean
    description: (Optional) A value that indicates whether the modifications in this request and any pending modifications are asynchronously applied as soon as possible, regardless of the PreferredMaintenanceWindow setting for the DB instance.
    default: false
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  DbInstanceResourceId:
    type: String
    description: (Required) Resource ID of the Amazon RDS instance for which deletion protection needs to be enabled.
    allowedPattern: \\"^db-[A-Z0-9]{26}$\\"
outputs:
  - EnableRDSInstanceDeletionProtection.ModifyDBInstanceResponse
mainSteps:
  -
    name: GetRDSInstanceIdentifier
    action: \\"aws:executeAwsApi\\"
    description: |
      ## GetRDSInstanceIdentifier
      Makes DescribeDBInstances API call using Amazon RDS Instance DbiResourceId to get DBInstance Identifier.
      ## Outputs
      * DbInstanceIdentifier: DBInstance Identifier of the Amazon RDS Instance.
    timeoutSeconds: 600
    isEnd: false
    inputs:
      Service: rds
      Api: DescribeDBInstances
      Filters:
        - Name: \\"dbi-resource-id\\"
          Values:
            - \\"{{ DbInstanceResourceId }}\\"
    outputs:
      - Name: DbInstanceIdentifier
        Selector: $.DBInstances[0].DBInstanceIdentifier
        Type: String
  -
    name: EnableRDSInstanceDeletionProtection
    action: \\"aws:executeAwsApi\\"
    description: |
      ## EnableRDSInstanceDeletionProtection
      Makes ModifyDBInstance API call to enable deletion protection on the Amazon RDS Instance using the DBInstanceId from the previous action.
      ## Outputs
      * DbInstance: The standard HTTP response from the ModifyDBInstance API.
    timeoutSeconds: 600
    isEnd: false
    inputs:
      Service: rds
      Api: ModifyDBInstance
      ApplyImmediately: \\"{{ ApplyImmediately }}\\"
      DBInstanceIdentifier: \\"{{ GetRDSInstanceIdentifier.DbInstanceIdentifier }}\\"
      DeletionProtection: True
    outputs:
      - Name: ModifyDBInstanceResponse
        Selector: $
        Type: StringMap
  -
    name: VerifyDBInstanceModification
    action: \\"aws:assertAwsResourceProperty\\"
    timeoutSeconds: 600
    isEnd: true
    description: |
      ## VerifyDBInstanceModification
      Checks whether deletion protection is enabled on Amazon RDS Instance.
    inputs:
      Service: rds
      Api: DescribeDBInstances
      DBInstanceIdentifier: \\"{{ GetRDSInstanceIdentifier.DbInstanceIdentifier }}\\"
      PropertySelector: \\"$.DBInstances[0].DeletionProtection\\"
      DesiredValues:
        - \\"True\\"

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-EnableRDSInstanceDeletionProtection",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARREnableRedshiftClusterAuditLogging": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "description: |
  ### Document name - AWSConfigRemediation-EnableRedshiftClusterAuditLogging 

  ## What does this document do?
  This automation document enables audit logging on the Amazon Redshift cluster using [EnableLogging](https://docs.aws.amazon.com/redshift/latest/APIReference/API_EnableLogging.html) API call with given bucket name and s3 key prefix. 

  ## Input Parameters
  * ClusterIdentifier: (Required) The unique identifier of the Amazon Redshift cluster on which logging to be started.
  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  * BucketName: (Required) The name of an existing Amazon S3 bucket where the log files are to be stored.
  * S3KeyPrefix: (Optional) The prefix applied to the log file names.  

  ## Output Parameters
  * EnableLoggingWithPrefix.Response: Standard HTTP response of the EnableLogging API.
  * EnableLoggingWithoutPrefix.Response: Standard HTTP response of the EnableLogging API.
schemaVersion: \\"0.3\\"
assumeRole: \\"{{ AutomationAssumeRole }}\\"
outputs:
  - EnableLoggingWithoutPrefix.Response
  - EnableLoggingWithPrefix.Response
parameters:
  ClusterIdentifier:
    type: String
    description: The unique identifier of the Amazon Redshift cluster on which the logging logging to be started.
    allowedPattern: \\"^(?!.*--)[a-z][a-z0-9-]{0,62}(?<!-)$\\"
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  BucketName:
    type: String
    description: The name of an existing Amazon S3 bucket where the log files are to be stored.
    allowedPattern: (?=^.{3,63}$)(?!^(\\\\d+\\\\.)+\\\\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\\\\-]*[a-z0-9])\\\\.)*([a-z0-9]|[a-z0-9][a-z0-9\\\\-]*[a-z0-9])$)
  S3KeyPrefix:
    type: String
    description: The prefix applied to the log file names.
    allowedPattern: ^[^\\"'\\\\\\\\ ]{0,512}$
    default: \\"\\"
mainSteps:
  - name: CheckS3KeyPrefix
    description: |
      ## CheckS3KeyPrefix
      Checks whether S3KeyPrefix provided in the input parameters. 
    action: \\"aws:branch\\"
    inputs:
      Choices:
        - NextStep: EnableLoggingWithoutPrefix
          Variable: \\"{{S3KeyPrefix}}\\"
          StringEquals: \\"\\"
      Default: EnableLoggingWithPrefix
    isEnd: true
  - name: EnableLoggingWithoutPrefix
    nextStep: AssertClusterLoggingEnabled
    action: \\"aws:executeAwsApi\\"
    description: |
      ## EnableLoggingWithoutPrefix 
      Enables logging on the given Amazon Redshift cluster using the [EnableLogging](https://docs.aws.amazon.com/redshift/latest/APIReference/API_EnableLogging.html) API with given bucket name in input parameters.
      ## Outputs
      * Response: Standard HTTP response of the EnableLogging API. 
    inputs:
      Service: redshift
      Api: EnableLogging
      BucketName: \\"{{BucketName}}\\"
      ClusterIdentifier: \\"{{ ClusterIdentifier }}\\"
    outputs:
      - Name: Response
        Selector: $
        Type: StringMap
  - name: EnableLoggingWithPrefix
    action: \\"aws:executeAwsApi\\"
    description: |
      ## EnableLoggingWithPrefix
      Enables logging on the given Amazon Redshift cluster using the [EnableLogging](https://docs.aws.amazon.com/redshift/latest/APIReference/API_EnableLogging.html) API with given bucket name and s3 key prefix in input parameters.
      ## Outputs
      * Response: Standard HTTP response of the EnableLogging API.
    inputs:
      Service: redshift
      Api: EnableLogging
      BucketName: \\"{{BucketName}}\\"
      S3KeyPrefix: \\"{{S3KeyPrefix}}\\"
      ClusterIdentifier: \\"{{ ClusterIdentifier }}\\"
    outputs:
      - Name: Response
        Selector: $
        Type: StringMap
  - name: AssertClusterBucketPrefix
    description: |
      ## AssertClusterBucketPrefix
      Verifies whether the value of the \\"S3KeyPrefix\\" parameter is used for logging for the given Amazon Redshift cluster.
    action: \\"aws:assertAwsResourceProperty\\"
    inputs:
      Service: redshift
      Api: DescribeLoggingStatus
      ClusterIdentifier: \\"{{ ClusterIdentifier }}\\"
      PropertySelector: $.S3KeyPrefix
      DesiredValues:
        - \\"{{S3KeyPrefix}}/\\"
  - name: AssertClusterLoggingEnabled
    description: |
      ## AssertClusterLoggingEnabled
      Verifies whether the \\"LoggingEnabled\\" property is set to \\"True\\" for the given Amazon Redshift cluster.
    action: \\"aws:assertAwsResourceProperty\\"
    inputs:
      Service: redshift
      Api: DescribeLoggingStatus
      ClusterIdentifier: \\"{{ ClusterIdentifier }}\\"
      PropertySelector: $.LoggingEnabled
      DesiredValues:
        - \\"True\\"
  - name: AssertClusterLoggingBucket
    description: |
      ## AssertClusterLoggingBucket
      Checks whether the value of the \\"BucketName\\" parameter is used for the audit logging configuration of the given Amazon Redshift cluster.
    action: \\"aws:assertAwsResourceProperty\\"
    inputs:
      Service: redshift
      Api: DescribeLoggingStatus
      ClusterIdentifier: \\"{{ ClusterIdentifier }}\\"
      PropertySelector: $.BucketName
      DesiredValues:
        - \\"{{BucketName}}\\"
    isEnd: true
",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-EnableRedshiftClusterAuditLogging",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARREnableVPCFlowLogs": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "description: |
  ### Document Name - SHARR-EnableVPCFlowLogs
  ## What does this document do?
  Enables VPC Flow Logs for a given VPC
  
  ## Input Parameters
  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  * VPC: VPC Id of the VPC for which logs are to be enabled
  * RemediationRole: role arn of the role to use for logging
  * KMSKeyArn: Amazon Resource Name (ARN) of the KMS Customer-Managed Key to use to encrypt the log group

  ## Security Standards / Controls
  * AFSBP v1.0.0:   CloudTrail.2
  * CIS v1.2.0:     2.7
  * PCI:            CloudTrail.1

schemaVersion: \\"0.3\\"
assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  VPC:
    type: String
    allowedPattern: '^vpc-[0-9a-f]{8,17}'
    description: The VPC ID of the VPC
  RemediationRole:
    type: String
    description: The ARN of the role that will allow VPC Flow Logs to log to CloudWatch logs
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  KMSKeyArn:
    type: String
    default: >-
      {{ssm:/Solutions/SO0111/CMK_REMEDIATION_ARN}}
    description: The ARN of the KMS key created by SHARR for remediations requiring encryption
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):kms:(?:[a-z]{2}(?:-gov)?-[a-z]+-\\\\d):\\\\d{12}:(?:(?:alias/[A-Za-z0-9/-_])|(?:key/(?i:[0-9a-f]{8}-(?:[0-9a-f]{4}-){3}[0-9a-f]{12})))$'

outputs:
  - Remediation.Output

mainSteps:
  - 
    name: Remediation
    action: 'aws:executeScript'
    outputs:
      - Name: Output
        Selector: $.Payload.response
        Type: StringMap
    inputs:
      InputPayload: 
        vpc: '{{VPC}}'
        remediation_role: '{{RemediationRole}}'   
        kms_key_arn: '{{KMSKeyArn}}'      
      Runtime: python3.8
      Handler: enable_flow_logs
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.    #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0/                                        #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    #
        #  sions and limitations under the License.                                   #
        ###############################################################################
        
        import boto3
        import time
        from botocore.config import Config
        from botocore.exceptions import ClientError
        
        def connect_to_logs(boto_config):
            return boto3.client('logs', config=boto_config)
        
        def connect_to_ec2(boto_config):
            return boto3.client('ec2', config=boto_config)
        
        def log_group_exists(client, group):
            try:
                log_group_verification = client.describe_log_groups(
                    logGroupNamePrefix=group
                )['logGroups']
                if len(log_group_verification) >= 1:
                    for existing_loggroup in log_group_verification:
                        if existing_loggroup['logGroupName'] == group:
                            return 1
                return 0
        
            except Exception as e:
                exit(f'EnableVPCFlowLogs failed - unhandled exception {str(e)}')
        
        def wait_for_loggroup(client, wait_interval, max_retries, loggroup):
            attempts = 1
            while not log_group_exists(client, loggroup):
                time.sleep(wait_interval)
                attempts += 1
                if attempts > max_retries:
                    exit(f'Timeout waiting for log group {loggroup} to become active')
        
        def flowlogs_active(client, loggroup):
            # searches for flow log status, filtered on unique CW Log Group created earlier
            try:
                flow_status = client.describe_flow_logs(
                    DryRun=False,
                    Filters=[
                        {
                            'Name': 'log-group-name',
                            'Values': [loggroup]
                        },
                    ]
                )['FlowLogs']
                if len(flow_status) == 1 and flow_status[0]['FlowLogStatus'] == 'ACTIVE':
                    return 1
                else:
                    return 0
        
            except Exception as e:
                exit(f'EnableVPCFlowLogs failed - unhandled exception {str(e)}')
        
        def wait_for_flowlogs(client, wait_interval, max_retries, loggroup):
            attempts = 1
            while not flowlogs_active(client, loggroup):
                time.sleep(wait_interval)
                attempts += 1
                if attempts > max_retries:
                    exit(f'Timeout waiting for flowlogs to log group {loggroup} to become active')
        
        def enable_flow_logs(event, context):
            \\"\\"\\"
            remediates CloudTrail.2 by enabling SSE-KMS
            On success returns a string map
            On failure returns NoneType
            \\"\\"\\"
            max_retries = event.get('retries', 12) # max number of waits for actions to complete.
            wait_interval = event.get('wait', 5) # how many seconds between attempts
        
            boto_config_args = {
                'retries': {
                    'mode': 'standard'
                }
            }
        
            boto_config = Config(**boto_config_args)
        
            if 'vpc' not in event or 'remediation_role' not in event or 'kms_key_arn' not in event:
                exit('Error: missing vpc from input')
        
            logs_client = connect_to_logs(boto_config)
            ec2_client = connect_to_ec2(boto_config)
            
            kms_key_arn = event['kms_key_arn'] # for logs encryption at rest
            
            # set dynamic variable for CW Log Group for VPC Flow Logs
            vpc_flow_loggroup = \\"VPCFlowLogs/\\" + event['vpc']        
            # create cloudwatch log group
            try:
                logs_client.create_log_group(
                    logGroupName=vpc_flow_loggroup,
                    kmsKeyId=kms_key_arn
                )
            except ClientError as client_error:
                exception_type = client_error.response['Error']['Code']
        
                if exception_type in [\\"ResourceAlreadyExistsException\\"]:
                    print(f'CloudWatch Logs group {vpc_flow_loggroup} already exists')
                else:
                    exit(f'ERROR CREATING LOGGROUP {vpc_flow_loggroup}: {str(exception_type)}')
                    
            except Exception as e:
                exit(f'ERROR CREATING LOGGROUP {vpc_flow_loggroup}: {str(e)}')
        
            # wait for CWL creation to propagate
            wait_for_loggroup(logs_client, wait_interval, max_retries, vpc_flow_loggroup)
        
            # create VPC Flow Logging
            try:
                ec2_client.create_flow_logs(
                    DryRun=False,
                    DeliverLogsPermissionArn=event['remediation_role'],
                    LogGroupName=vpc_flow_loggroup,
                    ResourceIds=[event['vpc']],
                    ResourceType='VPC',
                    TrafficType='REJECT',
                    LogDestinationType='cloud-watch-logs'
                )
            except ClientError as client_error:
                exception_type = client_error.response['Error']['Code']
        
                if exception_type in [\\"FlowLogAlreadyExists\\"]:
                    return {
                        \\"response\\": {
                            \\"message\\": f'VPC Flow Logs for {event[\\"vpc\\"]} already enabled',
                            \\"status\\": \\"Success\\"
                        }
                    }
                else:
                    exit(f'ERROR CREATING LOGGROUP {vpc_flow_loggroup}: {str(exception_type)}')
            except Exception as e:
                exit(f'create_flow_logs failed {str(e)}')
        
            # wait for Flow Log creation to propagate. Exits on timeout (no need to check results)
            wait_for_flowlogs(ec2_client, wait_interval, max_retries, vpc_flow_loggroup)
        
            # wait_for_flowlogs will exit if unsuccessful after max_retries * wait_interval (60 seconds by default)
            return {
                \\"response\\": {
                    \\"message\\": f'VPC Flow Logs enabled for {event[\\"vpc\\"]} to {vpc_flow_loggroup}',
                    \\"status\\": \\"Success\\"
                }
            }
        

    isEnd: true

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-EnableVPCFlowLogs",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARREncryptRDSSnapshot": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
# SPDX-License-Identifier: Apache-2.0
---
schemaVersion: '0.3'
description: |
  ### Document Name - SHARR-EncryptRDSSnapshot

  ## What does this document do?
  This document encrypts an RDS snapshot or cluster snapshot.

  ## Input Parameters
  * SourceDBSnapshotIdentifier: (Required) The name of the unencrypted RDS snapshot. Note that this snapshot will be deleted as part of this document's execution.
  * TargetDBSnapshotIdentifier: (Required) The name of the encrypted RDS snapshot to create.
  * DBSnapshotType: (Required) The type of snapshot (DB or cluster).
  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  * KmsKeyId: (Optional) ID, ARN or Alias for the AWS KMS Customer-Managed Key (CMK) to use. If no key is specified, the default encryption key for snapshots (\`alias/aws/rds\`) will be used.

  ## Output Parameters
  * CopyRdsSnapshotToEncryptedRdsSnapshot.EncryptedSnapshotId: The ID of the encrypted RDS snapshot.
  * CopyRdsClusterSnapshotToEncryptedRdsClusterSnapshot.EncryptedClusterSnapshotId: The ID of the encrypted RDS cluster snapshot.

  ## Minimum Permissions Required
  * \`rds:CopyDBSnapshot\`
  * \`rds:CopyDBClusterSnapshot\`
  * \`rds:DescribeDBSnapshots\`
  * \`rds:DescribeDBClusterSnapshots\`
  * \`rds:DeleteDBSnapshot\`
  * \`rds:DeleteDBClusterSnapshot\`

  ### Key Permissions
  If KmsKeyId is a Customer-Managed Key (CMK), then AutomationAssumeRole must have the following permissions on that key:
  * \`kms:DescribeKey\`
  * \`kms:CreateGrant\`
assumeRole: '{{AutomationAssumeRole}}'
parameters:
  SourceDBSnapshotIdentifier:
    type: 'String'
    description: '(Required) The name of the unencrypted RDS snapshot or cluster snapshot to copy.'
    allowedPattern: '^(?:rds:)?(?!.*--.*)(?!.*-$)[a-zA-Z][a-zA-Z0-9-]{0,254}$'
  TargetDBSnapshotIdentifier:
    type: 'String'
    description: '(Required) The name of the encrypted RDS snapshot or cluster snapshot to create.'
    allowedPattern: '^(?!.*--.*)(?!.*-$)[a-zA-Z][a-zA-Z0-9-]{0,254}$'
  DBSnapshotType:
    type: 'String'
    allowedValues:
    - 'snapshot'
    - 'cluster-snapshot'
    - 'dbclustersnapshot'
  AutomationAssumeRole:
    type: 'String'
    description: '(Required) The ARN of the role that allows Automation to perform the actions on your behalf.'
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  KmsKeyId:
    type: 'String'
    description: '(Optional) ID, ARN or Alias for the AWS KMS Customer-Managed Key (CMK) to use to encrypt the snapshot.'
    default: 'alias/aws/rds'
    allowedPattern: '^(?:arn:(?:aws|aws-us-gov|aws-cn):kms:(?:[a-z]{2}(?:-gov)?-[a-z]+-\\\\d):\\\\d{12}:)?(?:(?:alias/[A-Za-z0-9/_-]+)|(?:key/(?i:[0-9a-f]{8}-(?:[0-9a-f]{4}-){3}[0-9a-f]{12})))$'
outputs:
- 'CopyRdsSnapshotToEncryptedRdsSnapshot.EncryptedSnapshotId'
- 'CopyRdsClusterSnapshotToEncryptedRdsClusterSnapshot.EncryptedClusterSnapshotId'
mainSteps:
- name: 'ChooseSnapshotOrClusterSnapshot'
  action: 'aws:branch'
  inputs:
    Choices:
    - NextStep: 'CopyRdsSnapshotToEncryptedRdsSnapshot'
      Variable: '{{DBSnapshotType}}'
      StringEquals: 'snapshot'
    - Or:
      - Variable: '{{DBSnapshotType}}'
        StringEquals: 'cluster-snapshot'
      - Variable: '{{DBSnapshotType}}'
        StringEquals: 'dbclustersnapshot'
      NextStep: 'CopyRdsClusterSnapshotToEncryptedRdsClusterSnapshot'

- name: 'CopyRdsSnapshotToEncryptedRdsSnapshot'
  action: 'aws:executeAwsApi'
  inputs:
    Service: 'rds'
    Api: 'CopyDBSnapshot'
    SourceDBSnapshotIdentifier: '{{SourceDBSnapshotIdentifier}}'
    TargetDBSnapshotIdentifier: '{{TargetDBSnapshotIdentifier}}'
    CopyTags: true
    KmsKeyId: '{{KmsKeyId}}'
  outputs:
  - Name: 'EncryptedSnapshotId'
    Selector: '$.DBSnapshot.DBSnapshotIdentifier'
    Type: 'String'
- name: 'VerifyRdsEncryptedSnapshot'
  action: 'aws:waitForAwsResourceProperty'
  timeoutSeconds: 14400
  inputs:
    Service: 'rds'
    Api: 'DescribeDBSnapshots'
    Filters:
    - Name: 'db-snapshot-id'
      Values:
      - '{{CopyRdsSnapshotToEncryptedRdsSnapshot.EncryptedSnapshotId}}'
    PropertySelector: '$.DBSnapshots[0].Status'
    DesiredValues:
    - 'available'
- name: 'DeleteUnencryptedRdsSnapshot'
  action: 'aws:executeAwsApi'
  inputs:
    Service: 'rds'
    Api: 'DeleteDBSnapshot'
    DBSnapshotIdentifier: '{{SourceDBSnapshotIdentifier}}'
  isEnd: true

- name: 'CopyRdsClusterSnapshotToEncryptedRdsClusterSnapshot'
  action: 'aws:executeAwsApi'
  inputs:
    Service: 'rds'
    Api: 'CopyDBClusterSnapshot'
    SourceDBClusterSnapshotIdentifier: '{{SourceDBSnapshotIdentifier}}'
    TargetDBClusterSnapshotIdentifier: '{{TargetDBSnapshotIdentifier}}'
    CopyTags: true
    KmsKeyId: '{{KmsKeyId}}'
  outputs:
  - Name: 'EncryptedClusterSnapshotId'
    Selector: '$.DBClusterSnapshot.DBClusterSnapshotIdentifier'
    Type: 'String'
- name: 'VerifyRdsEncryptedClusterSnapshot'
  action: 'aws:waitForAwsResourceProperty'
  timeoutSeconds: 14400
  inputs:
    Service: 'rds'
    Api: 'DescribeDBClusterSnapshots'
    Filters:
    - Name: 'db-cluster-snapshot-id'
      Values:
      - '{{CopyRdsClusterSnapshotToEncryptedRdsClusterSnapshot.EncryptedClusterSnapshotId}}'
    PropertySelector: '$.DBClusterSnapshots[0].Status'
    DesiredValues:
    - 'available'
- name: 'DeleteUnencryptedRdsClusterSnapshot'
  action: 'aws:executeAwsApi'
  inputs:
    Service: 'rds'
    Api: 'DeleteDBClusterSnapshot'
    DBSnapshotIdentifier: '{{SourceDBSnapshotIdentifier}}'
  isEnd: true

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-EncryptRDSSnapshot",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARRMakeEBSSnapshotsPrivate": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "schemaVersion: \\"0.3\\"
description: |
  ### Document name - SHARR-MakeEBSSnapshotPrivate

  ## What does this document do?
  This runbook works an the account level to remove public share on all EBS snapshots

  ## Input Parameters
  * AutomationAssumeRole: (Required) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf.

  ## Output Parameters

  * Remediation.Output - stdout messages from the remediation

  ## Security Standards / Controls
  * AFSBP v1.0.0: EC2.1
  * CIS v1.2.0:   n/a
  * PCI:          EC2.1

assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AccountId:
    type: String
    description: Account ID of the account for which snapshots are to be checked.
    allowedPattern: ^[0-9]{12}$
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  TestMode:
    type: Boolean
    description: Enables test mode, which generates a list of fake volume Ids
    default: false

outputs:
  -  Remediation.Output
mainSteps:
  - name: GetPublicSnapshotIds
    action: 'aws:executeScript'
    outputs:
      - Name: Snapshots
        Selector: $.Payload
        Type: StringList
    inputs:
      InputPayload:
        region: '{{global:REGION}}'
        account_id: '{{AccountId}}'
        testmode: '{{TestMode}}'
      Runtime: python3.8
      Handler: get_public_snapshots
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0/                            #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    #
        #  sions and limitations under the License.                                   #
        ###############################################################################
        
        import json
        import boto3
        from botocore.config import Config
        from botocore.exceptions import ClientError
        
        boto_config = Config(
            retries = {
                    'mode': 'standard',
                    'max_attempts': 10
                }
            )
        
        def connect_to_ec2(boto_config):
            return boto3.client('ec2', config=boto_config)
        
        def get_public_snapshots(event, context):
            account_id = event['account_id']
        
            if 'testmode' in event and event['testmode']:
                return [
                    \\"snap-12341234123412345\\",
                    \\"snap-12341234123412345\\",
                    \\"snap-12341234123412345\\",
                    \\"snap-12341234123412345\\",
                    \\"snap-12341234123412345\\"
                ]
        
            return list_public_snapshots(account_id)
        
        def list_public_snapshots(account_id):
            ec2 = connect_to_ec2(boto_config)
            control_token = 'start'
            try:
        
                public_snapshot_ids = []
        
                while control_token:
        
                    if control_token == 'start': # needed a value to start the loop. Now reset it
                        control_token = ''
        
                    kwargs = {
                        'MaxResults': 100, 
                        'OwnerIds': [ account_id ],
                        'RestorableByUserIds': [ 'all' ]
                    }
                    if control_token:
                        kwargs['NextToken'] = control_token
                        
                    response = ec2.describe_snapshots(
                                **kwargs
                        )
                
                    for snapshot in response['Snapshots']:
                        public_snapshot_ids.append(snapshot['SnapshotId'])
        
                    if 'NextToken' in response:
                        control_token = response['NextToken']
                    else:
                        control_token = ''
        
                return public_snapshot_ids
                
            except Exception as e:
                print(e)
                exit('Failed to describe_snapshots')
        

  - name: Remediation
    action: 'aws:executeScript'
    outputs:
      - Name: Output
        Selector: $.Payload.response
        Type: StringMap
    inputs:
      InputPayload:
        region: '{{global:REGION}}'
        snapshots: '{{GetPublicSnapshotIds.Snapshots}}'
      Runtime: python3.8
      Handler: make_snapshots_private
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0/                            #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    #
        #  sions and limitations under the License.                                   #
        ###############################################################################
        
        import json
        import boto3
        from botocore.config import Config
        from botocore.exceptions import ClientError
        
        def connect_to_ec2(boto_config):
            return boto3.client('ec2', config=boto_config)
        
        def make_snapshots_private(event, context):
            boto_config = Config(
                retries = {
                        'mode': 'standard',
                        'max_attempts': 10
                    }
                )
            ec2 = connect_to_ec2(boto_config)
        
            remediated = []
            snapshots = event['snapshots']
        
            success_count = 0
            
            for snapshot_id in snapshots:
                try:
                    ec2.modify_snapshot_attribute(
                        Attribute='CreateVolumePermission',
                        CreateVolumePermission={
                            'Remove': [{'Group': 'all'}]
                        },
                        SnapshotId=snapshot_id
                    )
                    print(f'Snapshot {snapshot_id} permissions set to private')
        
                    remediated.append(snapshot_id)
                    success_count += 1
                except Exception as e:
                    print(e)
                    print(f'FAILED to remediate Snapshot {snapshot_id}')
        
            result=json.dumps(ec2.describe_snapshots(
                    SnapshotIds=remediated
                ), indent=2, default=str)
            print(result)
        
            return {
                \\"response\\": {
                    \\"message\\": f'{success_count} of {len(snapshots)} Snapshot permissions set to private',
                    \\"status\\": \\"Success\\"
                }
            }

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-MakeEBSSnapshotsPrivate",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARRMakeRDSSnapshotPrivate": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "schemaVersion: \\"0.3\\"
description: |
  ### Document name - SHARR-MakeRDSSnapshotPrivate

  ## What does this document do?
  This runbook removes public access to an RDS Snapshot

  ## Input Parameters
  * AutomationAssumeRole: (Required) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf.
  * DBSnapshotId: identifier of the public snapshot
  * DBSnapshotType: snapshot or cluster-snapshot

  ## Output Parameters

  * Remediation.Output - stdout messages from the remediation

  ## Security Standards / Controls
  * AFSBP v1.0.0: RDS.1
  * CIS v1.2.0:   n/a
  * PCI:          RDS.1

assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  DBSnapshotId:
    type: String
    allowedPattern: ^[a-zA-Z](?:[0-9a-zA-Z]+[-]{1})*[0-9a-zA-Z]{1,}$
  DBSnapshotType:
    type: String
    allowedValues:
    - cluster-snapshot
    - snapshot
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'

outputs:
  -  MakeRDSSnapshotPrivate.Output
mainSteps:
  - name: MakeRDSSnapshotPrivate
    action: 'aws:executeScript'
    outputs:
      - Name: Output
        Selector: $.Payload.response
        Type: StringMap
    inputs:
      InputPayload:
        DBSnapshotType: '{{DBSnapshotType}}'
        DBSnapshotId: '{{DBSnapshotId}}'
      Runtime: python3.8
      Handler: make_snapshot_private
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0/                            #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    #
        #  sions and limitations under the License.                                   #
        ###############################################################################
        
        import json
        import boto3
        from botocore.config import Config
        from botocore.exceptions import ClientError
        
        def connect_to_rds():
            boto_config = Config(
                retries ={
                    'mode': 'standard'
                }
            )
            return boto3.client('rds', config=boto_config)
        
        def make_snapshot_private(event, context):
        
            rds_client = connect_to_rds()
            snapshot_id = event['DBSnapshotId']
            snapshot_type = event['DBSnapshotType']
            try:
                if (snapshot_type == 'snapshot'):
                    rds_client.modify_db_snapshot_attribute(
                        DBSnapshotIdentifier=snapshot_id,
                        AttributeName='restore',
                        ValuesToRemove=['all']
                    )
                elif (snapshot_type == 'cluster-snapshot'):
                    rds_client.modify_db_cluster_snapshot_attribute(
                        DBClusterSnapshotIdentifier=snapshot_id,
                        AttributeName='restore',
                        ValuesToRemove=['all']
                    )
                else:
                    exit(f'Unrecognized snapshot_type {snapshot_type}')
        
                print(f'Remediation completed: {snapshot_id} public access removed.')
                return {
                    \\"response\\": {
                        \\"message\\": f'Snapshot {snapshot_id} permissions set to private',
                        \\"status\\": \\"Success\\"
                    }
                }
            except Exception as e:
                exit(f'Remediation failed for {snapshot_id}: {str(e)}')
        

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-MakeRDSSnapshotPrivate",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARRRemoveLambdaPublicAccess": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "schemaVersion: \\"0.3\\"
description: |
  ### Document name - SHARR-RemoveLambdaPublicAccess

  ## What does this document do?
  This document removes the public resource policy. A public resource policy
  contains a principal \\"*\\" or AWS: \\"*\\", which allows public access to the
  function. The remediation is to remove the SID of the public policy.

  ## Input Parameters
  * FunctionName: name of the AWS Lambda function that has open access policies
  * AutomationAssumeRole: (Required) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf.

  ## Output Parameters

  * RemoveLambdaPublicAccess.Output - stdout messages from the remediation

  ## Security Standards / Controls
  * AFSBP v1.0.0: Lambda.1
  * CIS v1.2.0:   n/a
  * PCI:          Lambda.1

assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  FunctionName:
    type: String
    allowedPattern: ^[a-zA-Z0-9\\\\-_]{1,64}$
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'

outputs:
  -  RemoveLambdaPublicAccess.Output
mainSteps:
  - name: RemoveLambdaPublicAccess
    action: 'aws:executeScript'
    outputs:
      - Name: Output
        Selector: $.Payload.response
        Type: StringMap
    inputs:
      InputPayload:
        FunctionName: '{{FunctionName}}'
      Runtime: python3.8
      Handler: remove_lambda_public_access
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0/                            #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    #
        #  sions and limitations under the License.                                   #
        ###############################################################################
        
        import json
        import boto3
        from botocore.config import Config
        from botocore.exceptions import ClientError
        
        boto_config = Config(
            retries = {
                'mode': 'standard',
                'max_attempts': 10
            }
        )
        
        def connect_to_lambda(boto_config):
            return boto3.client('lambda', config=boto_config)
        
        def print_policy_before(policy):
            print('Resource Policy to be deleted:')
            print(json.dumps(policy, indent=2, default=str))
        
        def remove_resource_policy(functionname, sid, client):
            try:
                client.remove_permission(
                    FunctionName=functionname,
                    StatementId=sid
                )
                print(f'SID {sid} removed from Lambda function {functionname}')
            except Exception as e:
                exit(f'FAILED: SID {sid} was NOT removed from Lambda function {functionname} - {str(e)}')
        
        def remove_public_statement(client, functionname, statement, principal_source):
            for principal in list(principal_source):
                if principal == \\"*\\" or (isinstance(principal, dict) and principal.get(\\"AWS\\",\\"\\") == \\"*\\"):
                    print_policy_before(statement)
                    remove_resource_policy(functionname, statement['Sid'], client)
                    break # there will only be one that matches
        
        def remove_lambda_public_access(event, context):
        
            client = connect_to_lambda(boto_config)
        
            functionname = event['FunctionName']
            try:
                response = client.get_policy(FunctionName=functionname)
                policy = response['Policy']
                policy_json = json.loads(policy)
                statements = policy_json['Statement']
        
                print('Scanning for public resource policies in ' + functionname)
        
                for statement in statements:
                    remove_public_statement(client, functionname, statement, list(statement['Principal']))
        
                client.get_policy(FunctionName=functionname)
        
                verify(functionname)
            except ClientError as ex:
                exception_type = ex.response['Error']['Code']
                if exception_type in ['ResourceNotFoundException']:
                    print(\\"Remediation completed. Resource policy is now empty.\\")
                else:
                    exit(f'ERROR: Remediation failed for RemoveLambdaPublicAccess: {str(ex)}')
            except Exception as e:
                exit(f'ERROR: Remediation failed for RemoveLambdaPublicAccess: {str(e)}')
        
        def verify(function_name_to_check):
        
            client = connect_to_lambda(boto_config)
        
            try:
                response = client.get_policy(FunctionName=function_name_to_check)
        
                print(\\"Remediation executed successfully. Policy after:\\")
                print(json.dumps(response, indent=2, default=str))
                
            except ClientError as ex:
                exception_type = ex.response['Error']['Code']
                if exception_type in ['ResourceNotFoundException']:
                    print(\\"Remediation completed. Resource policy is now empty.\\")
                else:
                    exit(f'ERROR: {exception_type} on get_policy')
            except Exception as e:
                exit(f'Exception while retrieving lambda function policy: {str(e)}')
        

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-RemoveLambdaPublicAccess",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARRRemoveVPCDefaultSecurityGroupRules": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "description: |
  ### Document name - AWSConfigRemediation-RemoveVPCDefaultSecurityGroupRules

  ## What does this document do?
  This document removes all inbound and outbound rules from the default security group in an Amazon VPC. A default security group is defined as any security group whose name is \`default\`. If the security group ID passed to this automation document belongs to a non-default security group, this document does not perform any changes to the AWS account.

  ## Input Parameters
  * GroupId: (Required) The unique ID of the security group.
  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.

  ## Output Parameters
  * RemoveRulesAndVerify.Output - Success message or failure exception.

schemaVersion: \\"0.3\\"
assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  GroupId:
    type: String
    description: (Required) The unique ID of the security group.
    allowedPattern: \\"sg-[a-z0-9]+$\\"
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'

outputs:
  - RemoveRulesAndVerify.Output

mainSteps:
  - name: CheckDefaultSecurityGroup
    action: aws:assertAwsResourceProperty
    isCritical: True
    onFailure: Abort
    maxAttempts: 3
    timeoutSeconds: 20
    description: |
      ## CheckDefaultSecurityGroup
      Verifies that the security group name does match \`default\`. If the group name does match \`default\`, go to the next step: DescribeSecurityGroups.
    inputs:
      Service: ec2
      Api: DescribeSecurityGroups
      GroupIds:
        - \\"{{ GroupId }}\\"
      PropertySelector: \\"$.SecurityGroups[0].GroupName\\"
      DesiredValues:
        - \\"default\\"
    nextStep: RemoveRulesAndVerify

  - name: RemoveRulesAndVerify
    action: \\"aws:executeScript\\"
    isCritical: True
    onFailure: Abort
    maxAttempts: 3
    timeoutSeconds: 180
    isEnd: true
    description: |
      ## RemoveRulesAndVerify
      Removes all rules from the default security group.
      ## Outputs
      * Output: Success message or failure exception.
    inputs:
      Runtime: python3.8
      Handler: handler
      InputPayload:
        GroupId: \\"{{ GroupId }}\\"
      Script: |-
        import boto3
        from botocore.exceptions import ClientError
        from time import sleep


        ec2_client = boto3.client(\\"ec2\\")


        def get_permissions(group_id):
            default_group = ec2_client.describe_security_groups(GroupIds=[group_id]).get(\\"SecurityGroups\\")[0]
            return default_group.get(\\"IpPermissions\\"), default_group.get(\\"IpPermissionsEgress\\")


        def handler(event, context):
            group_id = event.get(\\"GroupId\\")
            ingress_permissions, egress_permissions = get_permissions(group_id)

            if ingress_permissions:
                ec2_client.revoke_security_group_ingress(GroupId=group_id, IpPermissions=ingress_permissions)
            if egress_permissions:
                ec2_client.revoke_security_group_egress(GroupId=group_id, IpPermissions=egress_permissions)

            ingress_permissions, egress_permissions = get_permissions(group_id)
            if ingress_permissions or egress_permissions:
                raise Exception(f\\"VERIFICATION FAILED. SECURITY GROUP {group_id} NOT CLOSED.\\")

            return {
                \\"output\\": \\"Security group closed successfully.\\"
            }
    outputs:
      - Name: Output
        Selector: $.Payload.output
        Type: String

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-RemoveVPCDefaultSecurityGroupRules",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARRReplaceCodeBuildClearTextCredentials": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "description:  |
  ### Document Name - SHARR-ReplaceCodeBuildClearTextCredentials

  ## What does this document do?
  This document is used to replace environment variables containing clear text credentials in a CodeBuild project with Amazon EC2 Systems Manager Parameters.

  ## Input Parameters
  * ProjectName: (Required) Name of the CodeBuild project (not the ARN).
  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.

  ## Output Parameters
  * CreateParameters.Parameters - results of the API calls to create SSM parameters
  * CreateParameters.Policy - result of the API call to create an IAM policy for the project to access the new parameters
  * CreateParameters.AttachResponse - result of the API call to attach the new IAM policy to the project service role
  * UpdateProject.Output - result of the API call to update the project environment with the new parameters
schemaVersion: \\"0.3\\"
assumeRole: \\"{{ AutomationAssumeRole }}\\"
outputs:
  - CreateParameters.Parameters
  - CreateParameters.Policy
  - CreateParameters.AttachResponse
  - UpdateProject.Output
parameters:
  ProjectName:
    type: String
    description: (Required) The project name (not the ARN).
    allowedPattern: ^[A-Za-z0-9][A-Za-z0-9\\\\-_]{1,254}$
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
mainSteps:
  - name: BatchGetProjects
    action: \\"aws:executeAwsApi\\"
    description: |
      ## BatchGetProjects
      Gets information about one or more build projects.
    inputs:
      Service: codebuild
      Api: BatchGetProjects
      names: [ \\"{{ ProjectName }}\\" ]
    isCritical: true
    maxAttempts: 2
    timeoutSeconds: 600
    outputs:
      - Name: ProjectInfo
        Selector: $.projects[0]
        Type: StringMap
  - name: CreateParameters
    action: \\"aws:executeScript\\"
    description: |
      ## CreateParameters
      Parses project environment variables for credentials.
      Creates SSM parameters.
      Returns new project environment variables and SSM parameter information (without values).
    timeoutSeconds: 600
    isCritical: true
    inputs:
      Runtime: python3.8
      Handler: replace_credentials
      InputPayload:
        ProjectInfo: \\"{{ BatchGetProjects.ProjectInfo }}\\"
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0/                            #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    #
        #  sions and limitations under the License.                                   #
        ###############################################################################
        from json import dumps
        from boto3 import client
        from botocore.config import Config
        from botocore.exceptions import ClientError
        import re
        
        boto_config = Config(retries = {'mode': 'standard'})
        
        CREDENTIAL_NAMES_UPPER = [
            'AWS_ACCESS_KEY_ID',
            'AWS_SECRET_ACCESS_KEY'
        ]
        
        def connect_to_ssm(boto_config):
            return client('ssm', config = boto_config)
        
        def connect_to_iam(boto_config):
            return client('iam', config = boto_config)
        
        def is_clear_text_credential(env_var):
            if not env_var.get('type') == 'PLAINTEXT':
                return False
            return any(env_var.get('name').upper() == credential_name for credential_name in CREDENTIAL_NAMES_UPPER)
        
        def get_project_ssm_namespace(project_name):
            return f'/CodeBuild/{ project_name }'
        
        def create_parameter(project_name, env_var):
            env_var_name = env_var.get('name')
            parameter_name = f'{ get_project_ssm_namespace(project_name) }/env/{ env_var_name }'
        
            ssm_client = connect_to_ssm(boto_config)
            try:
                response = ssm_client.put_parameter(
                    Name = parameter_name,
                    Description = 'Automatically created by SHARR',
                    Value = env_var.get(\\"value\\"),
                    Type = 'SecureString',
                    Overwrite = False,
                    DataType = 'text'
                )
            except ClientError as client_exception:
                exception_type = client_exception.response['Error']['Code']
                if exception_type == 'ParameterAlreadyExists':
                    print(f'Parameter { parameter_name } already exists. This remediation may have been run before.')
                    print('Ignoring exception - remediation continues.')
                    response = None
                else:
                    exit(f'ERROR: Unhandled client exception: { client_exception }')
            except Exception as e:
                exit(f'ERROR: could not create SSM parameter { parameter_name }: { str(e) }')
        
            return response, parameter_name
        
        def create_policy(region, account, partition, project_name):
            iam_client = connect_to_iam(boto_config)
            policy_resource_filter = f'arn:{ partition }:ssm:{ region }:{ account }:parameter{ get_project_ssm_namespace(project_name) }/*'
            policy_document = {
                'Version': '2012-10-17',
                'Statement': [
                    {
                        'Effect': 'Allow',
                        'Action': [
                            'ssm:GetParameter',
                            'ssm:GetParameters'
                        ],
                        'Resource': policy_resource_filter
                    }
                ]
            }
            policy_name = f'CodeBuildSSMParameterPolicy-{ project_name }-{ region }'
            try:
                response = iam_client.create_policy(
                    Description = \\"Automatically created by SHARR\\",
                    PolicyDocument = dumps(policy_document),
                    PolicyName = policy_name
                )
            except ClientError as client_exception:
                exception_type = client_exception.response['Error']['Code']
                if exception_type == 'EntityAlreadyExists':
                    print(f'Policy { \\"\\" } already exists. This remediation may have been run before.')
                    print('Ignoring exception - remediation continues.')
                    # Attach needs to know the ARN of the created policy
                    response = {
                        'Policy': {
                            'Arn': f'arn:{ partition }:iam::{ account }:policy/{ policy_name }'
                        }
                    }
                else:
                    exit(f'ERROR: Unhandled client exception: { client_exception }')
            except Exception as e:
                exit(f'ERROR: could not create access policy { policy_name }: { str(e) }')
            return response
        
        def attach_policy(policy_arn, service_role_name):
            iam_client = connect_to_iam(boto_config)
            try:
                response = iam_client.attach_role_policy(
                    PolicyArn = policy_arn,
                    RoleName = service_role_name
                )
            except ClientError as client_exception:
                exit(f'ERROR: Unhandled client exception: { client_exception }')
            except Exception as e:
                exit(f'ERROR: could not attach policy { policy_arn } to role { service_role_name }: { str(e) }')
            return response
        
        def parse_project_arn(arn):
            pattern = re.compile(r'arn:(aws[a-zA-Z-]*):codebuild:([a-z]{2}(?:-gov)?-[a-z]+-\\\\d):(\\\\d{12}):project/[A-Za-z0-9][A-Za-z0-9\\\\-_]{1,254}$')
            match = pattern.match(arn)
            if match:
                partition = match.group(1)
                region = match.group(2)
                account = match.group(3)
                return partition, region, account
            else:
                raise ValueError
        
        def replace_credentials(event, context):
            project_info = event.get('ProjectInfo')
            project_name = project_info.get('name')
            project_env = project_info.get('environment')
            project_env_vars = project_env.get('environmentVariables')
            updated_project_env_vars = []
            parameters = []
        
            for env_var in project_env_vars:
                if (is_clear_text_credential(env_var)):
                    parameter_response, parameter_name = create_parameter(project_name, env_var)
                    updated_env_var = {
                        'name': env_var.get('name'),
                        'type': 'PARAMETER_STORE',
                        'value': parameter_name
                    }
                    updated_project_env_vars.append(updated_env_var)
                    parameters.append(parameter_response)
                else:
                    updated_project_env_vars.append(env_var)
        
            updated_project_env = project_env
            updated_project_env['environmentVariables'] = updated_project_env_vars
        
            partition, region, account = parse_project_arn(project_info.get('arn'))
            policy = create_policy(region, account, partition, project_name)
            service_role_arn = project_info.get('serviceRole')
            service_role_name = service_role_arn[service_role_arn.rfind('/') + 1:]
            attach_response = attach_policy(policy['Policy']['Arn'], service_role_name)
        
            # datetimes are not serializable, so convert them to ISO 8601 strings
            policy_datetime_keys = ['CreateDate', 'UpdateDate']
            for key in policy_datetime_keys:
                if key in policy['Policy']:
                    policy['Policy'][key] = policy['Policy'][key].isoformat()
        
            return {
                'UpdatedProjectEnv': updated_project_env,
                'Parameters': parameters,
                'Policy': policy,
                'AttachResponse': attach_response
            }
        
    outputs:
      - Name: UpdatedProjectEnv
        Selector: $.Payload.UpdatedProjectEnv
        Type: StringMap
      - Name: Parameters
        Selector: $.Payload.Parameters
        Type: MapList
      - Name: Policy
        Selector: $.Payload.Policy
        Type: StringMap
      - Name: AttachResponse
        Selector: $.Payload.AttachResponse
        Type: StringMap
  - name: UpdateProject
    action: \\"aws:executeAwsApi\\"
    description: |
      ## UpdateProject
      Changes the settings of a build project.
    isEnd: true
    inputs:
      Service: codebuild
      Api: UpdateProject
      name: \\"{{ ProjectName }}\\"
      environment: \\"{{ CreateParameters.UpdatedProjectEnv }}\\"
    isCritical: true
    maxAttempts: 2
    timeoutSeconds: 600
    outputs:
      - Name: Output
        Selector: $.Payload.output
        Type: StringMap

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-ReplaceCodeBuildClearTextCredentials",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARRRevokeUnrotatedKeys": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "schemaVersion: \\"0.3\\"
description: |
  ### Document Name - SHARR-RevokeUnrotatedKeys

  ## What does this document do?
  This document disables active keys that have not been rotated for more than 90 days. Note that this remediation is **DISRUPTIVE**. It will disabled keys that have been used within the previous 90 days by have not been rotated by using the [UpdateAccessKey API](https://docs.aws.amazon.com/IAM/latest/APIReference/API_UpdateAccessKey.html). Please note, this automation document requires AWS Config to be enabled.

  ## Input Parameters
  * Finding: (Required) Security Hub finding details JSON
  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  * MaxCredentialUsageAge: (Optional) Maximum number of days a key is allowed to be unrotated before revoking it. DEFAULT: 90

  ## Output Parameters
  * RevokeUnrotatedKeys.Output

assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  IAMResourceId:
    type: String
    description: (Required) IAM resource unique identifier.
    allowedPattern: ^[\\\\w+=,.@_-]{1,128}$
  MaxCredentialUsageAge:
    type: String
    description: (Required) Maximum number of days within which a credential must be used. The default value is 90 days.
    allowedPattern: ^[1-9][0-9]{0,3}|10000$
    default: \\"90\\"
outputs:
  - RevokeUnrotatedKeys.Output
mainSteps:
  - name: RevokeUnrotatedKeys
    action: aws:executeScript
    timeoutSeconds: 600
    isEnd: true
    description: |
      ## RevokeUnrotatedKeys

      This step deactivates IAM user access keys that have not been rotated in more than MaxCredentialUsageAge days
      ## Outputs
      * Output: Success message or failure Exception.
    inputs:
      Runtime: python3.8
      Handler: unrotated_key_handler
      InputPayload:
        IAMResourceId: \\"{{ IAMResourceId }}\\"
        MaxCredentialUsageAge: \\"{{ MaxCredentialUsageAge }}\\"
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0/                            #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    #
        #  sions and limitations under the License.                                   #
        ###############################################################################
        from datetime import datetime, timezone, timedelta
        import boto3
        from botocore.config import Config
        
        boto_config = Config(
            retries ={
                'mode': 'standard'
            }
        )
        
        responses = {}
        responses[\\"DeactivateUnusedKeysResponse\\"] = []
        
        def connect_to_iam(boto_config):
            return boto3.client('iam', config=boto_config)
        
        def connect_to_config(boto_config):
            return boto3.client('config', config=boto_config)
        
        def get_user_name(resource_id):
            config_client = connect_to_config(boto_config)
            list_discovered_resources_response = config_client.list_discovered_resources(
                resourceType='AWS::IAM::User',
                resourceIds=[resource_id]
            )
            resource_name = list_discovered_resources_response.get(\\"resourceIdentifiers\\")[0].get(\\"resourceName\\")
            return resource_name
        
        def list_access_keys(user_name, include_inactive=False):
            iam_client = connect_to_iam(boto_config)
            active_keys = []
            keys = iam_client.list_access_keys(UserName=user_name).get(\\"AccessKeyMetadata\\", [])
            for key in keys:
                if include_inactive or key.get('Status') == 'Active':
                    active_keys.append(key)
            return active_keys
        
        def deactivate_unused_keys(access_keys, max_credential_usage_age, user_name):
            iam_client = connect_to_iam(boto_config)
            for key in access_keys:
                print(key)
                last_used = iam_client.get_access_key_last_used(AccessKeyId=key.get(\\"AccessKeyId\\")).get(\\"AccessKeyLastUsed\\")
                deactivate = False
        
                now = datetime.now(timezone.utc)
                days_since_creation = (now - key.get(\\"CreateDate\\")).days
                last_used_days = (now - last_used.get(\\"LastUsedDate\\", now)).days
        
                print(f'Key {key.get(\\"AccessKeyId\\")} is {days_since_creation} days old and last used {last_used_days} days ago')
        
                if days_since_creation > max_credential_usage_age:
                    deactivate = True
        
                if last_used_days > max_credential_usage_age:
                    deactivate = True
        
                if deactivate:
                    deactivate_key(user_name, key.get(\\"AccessKeyId\\"))
        
        def deactivate_key(user_name, access_key):
            iam_client = connect_to_iam(boto_config)
            responses[\\"DeactivateUnusedKeysResponse\\"].append({\\"AccessKeyId\\": access_key, \\"Response\\": iam_client.update_access_key(UserName=user_name, AccessKeyId=access_key, Status=\\"Inactive\\")})
        
        def verify_expired_credentials_revoked(responses, user_name):
            if responses.get(\\"DeactivateUnusedKeysResponse\\"):
                for key in responses.get(\\"DeactivateUnusedKeysResponse\\"):
                    key_data = next(filter(lambda x: x.get(\\"AccessKeyId\\") == key.get(\\"AccessKeyId\\"), list_access_keys(user_name, True)))
                    if key_data.get(\\"Status\\") != \\"Inactive\\":
                        error_message = \\"VERIFICATION FAILED. ACCESS KEY {} NOT DEACTIVATED\\".format(key_data.get(\\"AccessKeyId\\"))
                        raise Exception(error_message)
        
            return {
                \\"output\\": \\"Verification of unrotated access keys is successful.\\",
                \\"http_responses\\": responses
            }
        
        def unrotated_key_handler(event, context):
            user_name = get_user_name(event.get(\\"IAMResourceId\\"))
            max_credential_usage_age = int(event.get(\\"MaxCredentialUsageAge\\"))
            access_keys = list_access_keys(user_name)
            deactivate_unused_keys(access_keys, max_credential_usage_age, user_name)
            return verify_expired_credentials_revoked(responses, user_name)
        

    outputs:
      - Name: Output
        Selector: $.Payload
        Type: StringMap

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-RevokeUnrotatedKeys",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARRRevokeUnusedIAMUserCredentials": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "schemaVersion: \\"0.3\\"
description: |
   ### Document Name - AWSConfigRemediation-RevokeUnusedIAMUserCredentials

   ## What does this document do?
   This document revokes unused IAM passwords and active access keys. This document will deactivate expired access keys by using the [UpdateAccessKey API](https://docs.aws.amazon.com/IAM/latest/APIReference/API_UpdateAccessKey.html) and delete expired login profiles by using the [DeleteLoginProfile API](https://docs.aws.amazon.com/IAM/latest/APIReference/API_DeleteLoginProfile.html). Please note, this automation document requires AWS Config to be enabled.

   ## Input Parameters
   * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
   * IAMResourceId: (Required) IAM resource unique identifier.
   * MaxCredentialUsageAge: (Required) Maximum number of days within which a credential must be used. The default value is 90 days.

   ## Output Parameters
   * RevokeUnusedIAMUserCredentialsAndVerify.Output - Success message or failure Exception.

assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  IAMResourceId:
    type: String
    description: (Required) IAM resource unique identifier.
    allowedPattern: ^[\\\\w+=,.@_-]{1,128}$
  MaxCredentialUsageAge:
    type: String
    description: (Required) Maximum number of days within which a credential must be used. The default value is 90 days.
    allowedPattern: ^(\\\\b([0-9]|[1-8][0-9]|9[0-9]|[1-8][0-9]{2}|9[0-8][0-9]|99[0-9]|[1-8][0-9]{3}|9[0-8][0-9]{2}|99[0-8][0-9]|999[0-9]|10000)\\\\b)$
    default: \\"90\\"
outputs:
  - RevokeUnusedIAMUserCredentialsAndVerify.Output
mainSteps:
  - name: RevokeUnusedIAMUserCredentialsAndVerify
    action: aws:executeScript
    timeoutSeconds: 600
    isEnd: true
    description: |
      ## RevokeUnusedIAMUserCredentialsAndVerify
      This step deactivates expired IAM User access keys, deletes expired login profiles and verifies credentials were revoked
      ## Outputs
      * Output: Success message or failure Exception.
    inputs:
      Runtime: python3.8
      Handler: unused_iam_credentials_handler
      InputPayload:
        IAMResourceId: \\"{{ IAMResourceId }}\\"
        MaxCredentialUsageAge: \\"{{ MaxCredentialUsageAge }}\\"
      Script: |-
        import boto3
        from datetime import datetime
        from datetime import timedelta

        iam_client = boto3.client(\\"iam\\")
        config_client = boto3.client(\\"config\\")

        responses = {}
        responses[\\"DeactivateUnusedKeysResponse\\"] = []

        def list_access_keys(user_name):
          return iam_client.list_access_keys(UserName=user_name).get(\\"AccessKeyMetadata\\")

        def deactivate_key(user_name, access_key):
          responses[\\"DeactivateUnusedKeysResponse\\"].append({\\"AccessKeyId\\": access_key, \\"Response\\": iam_client.update_access_key(UserName=user_name, AccessKeyId=access_key, Status=\\"Inactive\\")})

        def deactivate_unused_keys(access_keys, max_credential_usage_age, user_name):
          for key in access_keys:
            last_used = iam_client.get_access_key_last_used(AccessKeyId=key.get(\\"AccessKeyId\\")).get(\\"AccessKeyLastUsed\\")
            if last_used.get(\\"LastUsedDate\\"):
              last_used_date = last_used.get(\\"LastUsedDate\\").replace(tzinfo=None)
              last_used_days = (datetime.now() - last_used_date).days
              if last_used_days >= max_credential_usage_age:
                deactivate_key(user_name, key.get(\\"AccessKeyId\\"))
            else:
              create_date = key.get(\\"CreateDate\\").replace(tzinfo=None)
              days_since_creation = (datetime.now() - create_date).days
              if days_since_creation >= max_credential_usage_age:
                deactivate_key(user_name, key.get(\\"AccessKeyId\\"))

        def get_login_profile(user_name):
          try:
            return iam_client.get_login_profile(UserName=user_name)[\\"LoginProfile\\"]
          except iam_client.exceptions.NoSuchEntityException:
            return False

        def delete_unused_password(user_name, max_credential_usage_age):
          user = iam_client.get_user(UserName=user_name).get(\\"User\\")
          password_last_used_days = 0
          login_profile = get_login_profile(user_name)
          if login_profile and user.get(\\"PasswordLastUsed\\"):
            password_last_used = user.get(\\"PasswordLastUsed\\").replace(tzinfo=None)
            password_last_used_days = (datetime.now() - password_last_used).days
          elif login_profile and not user.get(\\"PasswordLastUsed\\"):
            password_creation_date = login_profile.get(\\"CreateDate\\").replace(tzinfo=None)
            password_last_used_days = (datetime.now() - password_creation_date).days
          if password_last_used_days >= max_credential_usage_age:
            responses[\\"DeleteUnusedPasswordResponse\\"] = iam_client.delete_login_profile(UserName=user_name)

        def verify_expired_credentials_revoked(responses, user_name):
          if responses.get(\\"DeactivateUnusedKeysResponse\\"):
            for key in responses.get(\\"DeactivateUnusedKeysResponse\\"):
              key_data = next(filter(lambda x: x.get(\\"AccessKeyId\\") == key.get(\\"AccessKeyId\\"), list_access_keys(user_name)))
              if key_data.get(\\"Status\\") != \\"Inactive\\":
                error_message = \\"VERIFICATION FAILED. ACCESS KEY {} NOT DEACTIVATED\\".format(key_data.get(\\"AccessKeyId\\"))
                raise Exception(error_message)
          if responses.get(\\"DeleteUnusedPasswordResponse\\"):
            try:
              iam_client.get_login_profile(UserName=user_name)
              error_message = \\"VERIFICATION FAILED. IAM USER {} LOGIN PROFILE NOT DELETED\\".format(user_name)
              raise Exception(error_message)
            except iam_client.exceptions.NoSuchEntityException:
              pass
          return {
              \\"output\\": \\"Verification of unused IAM User credentials is successful.\\",
              \\"http_responses\\": responses
          }

        def get_user_name(resource_id):
          list_discovered_resources_response = config_client.list_discovered_resources(
              resourceType='AWS::IAM::User',
              resourceIds=[resource_id]
          )
          resource_name = list_discovered_resources_response.get(\\"resourceIdentifiers\\")[0].get(\\"resourceName\\")
          return resource_name

        def unused_iam_credentials_handler(event, context):
          iam_resource_id = event.get(\\"IAMResourceId\\")
          user_name = get_user_name(iam_resource_id)

          max_credential_usage_age = int(event.get(\\"MaxCredentialUsageAge\\"))

          access_keys = list_access_keys(user_name)
          unused_keys = deactivate_unused_keys(access_keys, max_credential_usage_age, user_name)

          delete_unused_password(user_name, max_credential_usage_age)

          return verify_expired_credentials_revoked(responses, user_name)
    outputs:
      - Name: Output
        Selector: $.Payload
        Type: StringMap
",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-RevokeUnusedIAMUserCredentials",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARRS3BlockDenylist": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "description: |
  ### Document Name - SHARR-S3BlockDenyList

  ## What does this document do?
  This document adds an explicit DENY to the bucket policy to prevent cross-account access to specific sensitive API calls. By default these are s3:DeleteBucketPolicy, s3:PutBucketAcl, s3:PutBucketPolicy, s3:PutEncryptionConfiguration, and s3:PutObjectAcl.

  ## Input Parameters
  * BucketName: (Required) Bucket whose bucket policy is to be restricted.
  * DenyList: (Required) List of permissions to be explicitly denied when the Principal contains a role or user in another account.
  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.

  ## Output Parameters
  * PutS3BucketPolicyDeny.Output

schemaVersion: \\"0.3\\"
assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  BucketName:
    type: String
    description: (Required) The bucket name (not the ARN).
    allowedPattern: (?=^.{3,63}$)(?!^(\\\\d+\\\\.)+\\\\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\\\\-]*[a-z0-9])\\\\.)*([a-z0-9]|[a-z0-9][a-z0-9\\\\-]*[a-z0-9])$)
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  DenyList:
    type: String
    description: (Required) Comma-delimited list (string) of permissions to be explicitly denied when the Principal contains a role or user in another account.
    allowedPattern: '.*'
outputs:
  - PutS3BucketPolicyDeny.Output
mainSteps:
  -
    name: PutS3BucketPolicyDeny
    action: 'aws:executeScript'
    description: |
      ## PutS3BucketPolicyDeny
      Adds an explicit deny to the bucket policy for specific restricted permissions.
    timeoutSeconds: 600
    inputs:
      InputPayload:
        accountid: '{{global:ACCOUNT_ID}}'
        bucket: '{{BucketName}}'
        denylist: '{{DenyList}}'
      Runtime: python3.8
      Handler: update_bucket_policy
      Script: |-
        #!/usr/bin/python
        # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
        # SPDX-License-Identifier: Apache-2.0
        '''
        Given a bucket name and list of \\"sensitive\\" IAM permissions that shall not be
        allowed cross-account, create an explicit deny policy for all cross-account
        principals, denying access to all IAM permissions in the deny list for all
        resources.
        
        Note:
        - The deny list is a comma-separated list configured on the Config rule in parameter blacklistedActionPattern
        '''
        import json
        import boto3
        import copy
        from botocore.config import Config
        from botocore.exceptions import ClientError
        
        BOTO_CONFIG = Config(
            retries = {
                    'mode': 'standard',
                    'max_attempts': 10
                }
            )
        
        def connect_to_s3():
            return boto3.client('s3', config=BOTO_CONFIG)
        
        def get_partition():
            return boto3.client('sts', config=BOTO_CONFIG).get_caller_identity().get('Arn').split(':')[1]
        
        class BucketToRemediate:
            def __init__(self, bucketName):
                self.bucket_name = bucketName
                self.get_partition_where_running()
                self.initialize_bucket_policy_to_none()
        
            def __str__(self):
                return json.dumps(self.__dict__)
        
            def initialize_bucket_policy_to_none(self):
                self.bucket_policy = None
        
            def get_partition_where_running(self):
                self.partition = get_partition()
        
            def set_account_id_from_event(self, event):
                self.account_id = event.get('accountid') or exit('AWS Account not specified')
        
            def set_denylist_from_event(self, event):
                self.denylist = event.get('denylist').split(',') or exit('DenyList is empty or not a comma-delimited string') # Expect a comma seperated list in a string
        
            def get_current_bucket_policy(self):
                try:
                    self.bucket_policy = connect_to_s3().get_bucket_policy(
                        Bucket=self.bucket_name,
                        ExpectedBucketOwner=self.account_id
                    ).get('Policy')
        
                except Exception as e:
                    print(e)
                    exit(f'Failed to retrieve the bucket policy: {self.account_id} {self.bucket_name}')
        
            def update_bucket_policy(self):
                try:
                    connect_to_s3().put_bucket_policy(
                        Bucket=self.bucket_name,
                        ExpectedBucketOwner=self.account_id,
                        Policy=self.bucket_policy
                    )
                except Exception as e:
                    print(e)
                    exit(f'Failed to store the new bucket policy: {self.account_id} {self.bucket_name}')
        
            def __principal_is_asterisk(self, principals):
                return (True if isinstance(principals, str) and principals == '*' else False)
        
            def get_account_principals_from_bucket_policy_statement(self, statement_principals):
                aws_account_principals = []
                for principal_type, principal in statement_principals.items():
                    if principal_type != 'AWS':
                        continue # not an AWS account
                    aws_account_principals = principal if isinstance(principal, list) else [ principal ]
                return aws_account_principals
        
            def create_explicit_deny_in_bucket_policy(self):
                new_bucket_policy = json.loads(self.bucket_policy)
                deny_statement = DenyStatement(self)
                for statement in new_bucket_policy['Statement']:
                    principals = statement.get('Principal', None)
                    if principals and not self.__principal_is_asterisk(principals):
                        account_principals = self.get_account_principals_from_bucket_policy_statement(copy.deepcopy(principals))
                        deny_statement.add_next_principal_to_deny(account_principals, self.account_id)
        
                if deny_statement.deny_statement_json:
                    new_bucket_policy['Statement'].append(deny_statement.deny_statement_json)
                    self.bucket_policy = json.dumps(new_bucket_policy)
                    return True
        
        class DenyStatement:
            def __init__(self, bucket_object):
                self.bucket_object = bucket_object
                self.initialize_deny_statement()
        
            def initialize_deny_statement(self):
                self.deny_statement_json = {}
                self.deny_statement_json[\\"Effect\\"] = \\"Deny\\"
                self.deny_statement_json[\\"Principal\\"] = {
                    \\"AWS\\": []
                }
                self.deny_statement_json[\\"Action\\"] = self.bucket_object.denylist
                self.deny_statement_json[\\"Resource\\"] = [
                    f'arn:{self.bucket_object.partition}:s3:::{self.bucket_object.bucket_name}',
                    f'arn:{self.bucket_object.partition}:s3:::{self.bucket_object.bucket_name}/*',
                ]
        
            def __str__(self):
                return json.dumps(self.deny_statement_json)
        
            def add_next_principal_to_deny(self, principals_to_deny, bucket_account):
                if len(principals_to_deny) == 0:
                    return
                this_principal = principals_to_deny.pop()
                principal_account = this_principal.split(':')[4]
                if principal_account and principal_account != bucket_account:
                    self.add_deny_principal(this_principal)
        
                self.add_next_principal_to_deny(principals_to_deny, bucket_account)
        
            def add_deny_principal(self, principal_arn):
                if not principal_arn in self.deny_statement_json[\\"Principal\\"][\\"AWS\\"]:
                    self.deny_statement_json[\\"Principal\\"][\\"AWS\\"].append(principal_arn)
        
            def add_deny_resource(self, resource_arn):
                if self.deny_statement_json[\\"Resource\\"] and not resource_arn in self.deny_statement_json.Resource:
                    self.deny_statement_json[\\"Resource\\"].append(resource_arn)
        
        def update_bucket_policy(event, context):
            def __get_bucket_from_event(event):
                bucket = event.get('bucket') or exit('Bucket not specified')
                return bucket
        
            bucket_to_update = BucketToRemediate(__get_bucket_from_event(event))
            bucket_to_update.set_denylist_from_event(event)
            bucket_to_update.set_account_id_from_event(event)
            bucket_to_update.get_current_bucket_policy()
            if bucket_to_update.create_explicit_deny_in_bucket_policy():
                bucket_to_update.update_bucket_policy()
            else:
                exit(f'Unable to create an explicit deny statement for {bucket_to_update.bucket_name}')
        
    outputs:
      - Name: Output
        Selector: $.Payload.output
        Type: StringMap

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-S3BlockDenylist",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARRSetIAMPasswordPolicy": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "description: |
  ### Document name - AWSConfigRemediation-SetIAMPasswordPolicy

  ## What does this document do?
  This document sets the AWS Identity and Access Management (IAM) user password policy for the AWS account using the [UpdateAccountPasswordPolicy](https://docs.aws.amazon.com/IAM/latest/APIReference/API_UpdateAccountPasswordPolicy.html) API.

  ## Input Parameters
  * AllowUsersToChangePassword: (Optional) Allows all IAM users in your account to use the AWS Management Console to change their own passwords.
  * HardExpiry: (Optional) Prevents IAM users from setting a new password after their password has expired.
  * MaxPasswordAge: (Optional) The number of days that an IAM user password is valid.
  * MinimumPasswordLength: (Optional) The minimum number of characters allowed in an IAM user password.
  * PasswordReusePrevention: (Optional) Specifies the number of previous passwords that IAM users are prevented from reusing.
  * RequireLowercaseCharacters: (Optional) Specifies whether IAM user passwords must contain at least one lowercase character from the ISO basic Latin alphabet (a to z).
  * RequireNumbers: (Optional) Specifies whether IAM user passwords must contain at least one numeric character (0 to 9).
  * RequireSymbols: (Optional) pecifies whether IAM user passwords must contain at least one of the following non-alphanumeric characters :! @ \\\\# $ % ^ * ( ) _ + - = [ ] { } | '
  * RequireUppercaseCharacters: (Optional) Specifies whether IAM user passwords must contain at least one uppercase character from the ISO basic Latin alphabet (A to Z).
  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
  ## Output Parameters
  * UpdateAndVerifyIamUserPasswordPolicy.Output
schemaVersion: \\"0.3\\"
assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  AllowUsersToChangePassword:
    type: Boolean
    description: (Optional) Allows all IAM users in your AWS account to use the AWS Management Console to change their own passwords.
    default: false
  HardExpiry:
    type: Boolean
    description: (Optional) Prevents IAM users from setting a new password after their password has expired.
    default: false
  MaxPasswordAge:
    type: Integer
    description: (Optional) The number of days that an IAM user password is valid.
    allowedPattern: ^\\\\d{0,3}$|^10[0-8]\\\\d$|^109[0-5]$
    default: 0
  MinimumPasswordLength:
    type: Integer
    description: (Optional) The minimum number of characters allowed in an IAM user password.
    allowedPattern: ^[6-9]$|^[1-9]\\\\d$|^1[01]\\\\d$|^12[0-8]$
    default: 6
  PasswordReusePrevention:
    type: Integer
    description: (Optional) Specifies the number of previous passwords that IAM users are prevented from reusing.
    allowedPattern: ^\\\\d{0,1}$|^1\\\\d$|^2[0-4]$
    default: 0
  RequireLowercaseCharacters:
    type: Boolean
    description: (Optional) Specifies whether IAM user passwords must contain at least one lowercase character from the ISO basic Latin alphabet (a to z).
    default: false
  RequireNumbers:
    type: Boolean
    description: (Optional) Specifies whether IAM user passwords must contain at least one numeric character (0 to 9).
    default: false
  RequireSymbols:
    type: Boolean
    description: (Optional) Specifies whether IAM user passwords must contain at least one of the following non-alphanumeric characters :! @ \\\\# $ % ^ * ( ) _ + - = [ ] { } | '.
    default: false
  RequireUppercaseCharacters:
    type: Boolean
    description: (Optional) Specifies whether IAM user passwords must contain at least one uppercase character from the ISO basic Latin alphabet (A to Z).
    default: false
outputs:
  - UpdateAndVerifyIamUserPasswordPolicy.Output
mainSteps:
  - name: UpdateAndVerifyIamUserPasswordPolicy
    action: \\"aws:executeScript\\"
    timeoutSeconds: 600
    isEnd: true
    description: |
      ## UpdateAndVerifyIamUserPasswordPolicy
      Sets or updates the AWS account password policy using input parameters using UpdateAccountPasswordPolicy API.
      Verify AWS account password policy using GetAccountPasswordPolicy API.
      ## Outputs
      * Output: Success message with HTTP Response from GetAccountPasswordPolicy API call or failure exception.
    inputs:
      Runtime: python3.8
      Handler: update_and_verify_iam_user_password_policy
      InputPayload:
        AllowUsersToChangePassword: \\"{{ AllowUsersToChangePassword }}\\"
        HardExpiry: \\"{{ HardExpiry }}\\"
        MaxPasswordAge: \\"{{ MaxPasswordAge }}\\"
        MinimumPasswordLength: \\"{{ MinimumPasswordLength }}\\"
        PasswordReusePrevention: \\"{{ PasswordReusePrevention }}\\"
        RequireLowercaseCharacters: \\"{{ RequireLowercaseCharacters }}\\"
        RequireNumbers: \\"{{ RequireNumbers }}\\"
        RequireSymbols: \\"{{ RequireSymbols }}\\"
        RequireUppercaseCharacters: \\"{{ RequireUppercaseCharacters }}\\"
      Script: |-
        import boto3


        def update_and_verify_iam_user_password_policy(event, context):
            iam_client = boto3.client('iam')

            try:
                params = dict()
                params[\\"AllowUsersToChangePassword\\"] = event[\\"AllowUsersToChangePassword\\"]
                if \\"HardExpiry\\" in event:
                    params[\\"HardExpiry\\"] = event[\\"HardExpiry\\"]
                if event[\\"MaxPasswordAge\\"]:
                    params[\\"MaxPasswordAge\\"] = event[\\"MaxPasswordAge\\"]
                if event[\\"PasswordReusePrevention\\"]:
                    params[\\"PasswordReusePrevention\\"] = event[\\"PasswordReusePrevention\\"]
                params[\\"MinimumPasswordLength\\"] = event[\\"MinimumPasswordLength\\"]
                params[\\"RequireLowercaseCharacters\\"] = event[\\"RequireLowercaseCharacters\\"]
                params[\\"RequireNumbers\\"] = event[\\"RequireNumbers\\"]
                params[\\"RequireSymbols\\"] = event[\\"RequireSymbols\\"]
                params[\\"RequireUppercaseCharacters\\"] = event[\\"RequireUppercaseCharacters\\"]

                update_api_response = iam_client.update_account_password_policy(**params)

                # Verifies IAM Password Policy configuration for AWS account using GetAccountPasswordPolicy() api call.
                response = iam_client.get_account_password_policy()
                if all([response[\\"PasswordPolicy\\"][\\"AllowUsersToChangePassword\\"] == event[\\"AllowUsersToChangePassword\\"],
                        response[\\"PasswordPolicy\\"][\\"MinimumPasswordLength\\"] == event[\\"MinimumPasswordLength\\"],
                        response[\\"PasswordPolicy\\"][\\"RequireLowercaseCharacters\\"] == event[\\"RequireLowercaseCharacters\\"],
                        response[\\"PasswordPolicy\\"][\\"RequireNumbers\\"] == event[\\"RequireNumbers\\"],
                        response[\\"PasswordPolicy\\"][\\"RequireUppercaseCharacters\\"] == event[\\"RequireUppercaseCharacters\\"],
                        ((response[\\"PasswordPolicy\\"][\\"HardExpiry\\"] == event[\\"HardExpiry\\"]) if \\"HardExpiry\\" in event else True),
                        ((response[\\"PasswordPolicy\\"][\\"MaxPasswordAge\\"] == event[\\"MaxPasswordAge\\"]) if event[\\"MaxPasswordAge\\"] else True),
                        ((response[\\"PasswordPolicy\\"][\\"PasswordReusePrevention\\"] == event[\\"PasswordReusePrevention\\"]) if event[\\"PasswordReusePrevention\\"] else True)]):
                    return {
                        \\"output\\": {
                            \\"Message\\": \\"AWS Account Password Policy setting is SUCCESSFUL.\\",
                            \\"UpdatePolicyHTTPResponse\\": update_api_response,
                            \\"GetPolicyHTTPResponse\\": response
                        }
                    }
                raise Exception(\\"VERIFICATION FAILED. AWS ACCOUNT PASSWORD POLICY NOT UPDATED.\\")

            except iam_client.exceptions.NoSuchEntityException:
                raise Exception(\\"VERIFICATION FAILED. UNABLE TO UPDATE AWS ACCOUNT PASSWORD POLICY.\\")

    outputs:
      - Name: Output
        Selector: $.Payload.output
        Type: StringMap
",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-SetIAMPasswordPolicy",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
    "SHARRSetSSLBucketPolicy": Object {
      "DeletionPolicy": "Delete",
      "Properties": Object {
        "Content": "schemaVersion: \\"0.3\\"
description: |
  ### Document name - SHARR-SetSSLBucketPolicy

  ## What does this document do?
  This document adds a bucket policy to require transmission over HTTPS for the given S3 bucket by adding a policy statement to the bucket policy.

  ## Input Parameters
  * AutomationAssumeRole: (Required) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf.
  * BucketName: (Required) Name of the bucket to modify.
  * AccountId: (Required) Account to which the bucket belongs

  ## Output Parameters

  * Remediation.Output - stdout messages from the remediation

  ## Security Standards / Controls
  * AFSBP v1.0.0: S3.5
  * CIS v1.2.0:   n/a
  * PCI:          S3.5

assumeRole: \\"{{ AutomationAssumeRole }}\\"
parameters:
  AccountId:
    type: String
    description: Account ID of the account for the finding
    allowedPattern: ^[0-9]{12}$
  AutomationAssumeRole:
    type: String
    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.
    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\\\d{12}:role/[\\\\w+=,.@-]+$'
  BucketName:
    type: String
    description: Name of the bucket to have a policy added
    allowedPattern: (?=^.{3,63}$)(?!^(\\\\d+\\\\.)+\\\\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\\\\-]*[a-z0-9])\\\\.)*([a-z0-9]|[a-z0-9][a-z0-9\\\\-]*[a-z0-9])$)

outputs:
  -  Remediation.Output
mainSteps:
  - name: Remediation
    action: 'aws:executeScript'
    outputs:
      - Name: Output
        Selector: $.Payload.response
        Type: StringMap
    inputs:
      InputPayload:
        accountid: '{{AccountId}}'
        bucket: '{{BucketName}}'
      Runtime: python3.8
      Handler: add_ssl_bucket_policy
      Script: |-
        #!/usr/bin/python
        ###############################################################################
        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #
        #                                                                             #
        #  Licensed under the Apache License Version 2.0 (the \\"License\\"). You may not #
        #  use this file except in compliance with the License. A copy of the License #
        #  is located at                                                              #
        #                                                                             #
        #      http://www.apache.org/licenses/LICENSE-2.0/                            #
        #                                                                             #
        #  or in the \\"license\\" file accompanying this file. This file is distributed  #
        #  on an \\"AS IS\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #
        #  or implied. See the License for the specific language governing permis-    #
        #  sions and limitations under the License.                                   #
        ###############################################################################
        
        import json
        import boto3
        from botocore.config import Config
        from botocore.exceptions import ClientError
        
        boto_config = Config(
            retries = {
                    'mode': 'standard',
                    'max_attempts': 10
                }
            )
        
        def connect_to_s3():
            return boto3.client('s3', config=boto_config)
        
        def policy_to_add(bucket):
            return {
                \\"Sid\\": \\"AllowSSLRequestsOnly\\",
                \\"Action\\": \\"s3:*\\",
                \\"Effect\\": \\"Deny\\",
                \\"Resource\\": [
                    f'arn:aws:s3:::{bucket}',
                    f'arn:aws:s3:::{bucket}/*'
                ],
                \\"Condition\\": {
                    \\"Bool\\": {
                            \\"aws:SecureTransport\\": \\"false\\"
                    }
                },
                \\"Principal\\": \\"*\\"
            }
        def new_policy():
            return {
                \\"Id\\": \\"BucketPolicy\\",
                \\"Version\\": \\"2012-10-17\\",
                \\"Statement\\": []
            }
        
        def add_ssl_bucket_policy(event, context):
            bucket_name = event['bucket']
            account_id = event['accountid']
            s3 = connect_to_s3()
            bucket_policy = {}
            try:
                existing_policy = s3.get_bucket_policy(
                    Bucket=bucket_name,
                    ExpectedBucketOwner=account_id
                )
                bucket_policy = json.loads(existing_policy['Policy'])
            except ClientError as ex:
                exception_type = ex.response['Error']['Code']
                # delivery channel already exists - return
                if exception_type not in [\\"NoSuchBucketPolicy\\"]:
                    exit(f'ERROR: Boto3 s3 ClientError: {exception_type} - {str(ex)}')
            except Exception as e:
                exit(f'ERROR getting bucket policy for {bucket_name}: {str(e)}')
        
            if not bucket_policy:
                bucket_policy = new_policy()
        
            print(f'Existing policy: {bucket_policy}')
            bucket_policy['Statement'].append(policy_to_add(bucket_name))
        
            try:
                result = s3.put_bucket_policy(
                    Bucket=bucket_name,
                    Policy=json.dumps(bucket_policy, indent=4, default=str),
                    ExpectedBucketOwner=account_id
                )
                print(result)
            except ClientError as ex:
                exception_type = ex.response['Error']['Code']
                exit(f'ERROR: Boto3 s3 ClientError: {exception_type} - {str(ex)}')
            except Exception as e:
                exit(f'ERROR putting bucket policy for {bucket_name}: {str(e)}')
        
            print(f'New policy: {bucket_policy}')
        

",
        "DocumentFormat": "YAML",
        "DocumentType": "Automation",
        "Name": "SHARR-SetSSLBucketPolicy",
        "ServiceToken": Object {
          "Fn::Join": Array [
            "",
            Array [
              "arn:",
              Object {
                "Ref": "AWS::Partition",
              },
              ":lambda:",
              Object {
                "Ref": "AWS::Region",
              },
              ":",
              Object {
                "Ref": "AWS::AccountId",
              },
              ":function:SO0111-SHARR-updatableRunbookProvider",
            ],
          ],
        },
      },
      "Type": "Custom::UpdatableRunbook",
      "UpdateReplacePolicy": "Delete",
    },
  },
}
`;
